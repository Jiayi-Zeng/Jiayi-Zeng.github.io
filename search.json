[{"title":"Understanding Namespace and Scope","url":"/docs/Immediate-to-Python-4-Understanding-Namespace-and-Scope/","content":"\n","tags":["Python"],"categories":["Immediate to Python"]},{"title":"10 Clustering","url":"/docs/Predicted-Analytics-8-Clustering/","content":"\n# **Unsupervised Learning**\n\n* Clustering\n  * k-means clustering\n  * Hierarchical Clustering\n* Principal Component Analysis\n\n**Unsupervised Learning in Predictive Analytics**\n\nUnsupervised learning is part of Machine Learning family of methods\n\nAlthough, it may not be as popular as supervised learning, it has a significant footprint in Analytics\n\n**The Challenge of Unsupervised Learning**\n\nModel assessment\n\n* We cannot tell if the model we have built is good\n* Because we do not have the test data with known response variable information\n* We cannot do cross validation\n\n# **Clustering**\n\nCategorize objects into groups (or clusters) so that \n\n* Objects in each group are similar \n* Objects in each group are different from objects in other groups\n\n**Clustering Applications**\n\n* Decrease the size and complexity of problems for other data mining methods\n* Identify outliers in a specific domain\n  * Customer Segmentation\n\n## Clustering Definition\n\n* Suppose ‚Äòn‚Äô observations\n* Let $ùê∂1,ùê∂2,...,ùê∂ùëò$ are sets containing\n* the indices of the observations in each other\n  * $ùê∂1 ‚à™ ùê∂2 ‚à™ ùê∂3 ...‚à™ ùê∂ùëò = 1,...,ùëõ$ . Each observation belongs to at least one of the ‚Äòk‚Äô clusters.\n  * $ùê∂ùëò ‚à© ùê∂ùëò‚Ä≤ = 0$ for all $ùëò‚â†ùëò$‚Ä≤. Clusters are non-overlapping: no observation belongs to more than one cluster.\n\n## Compute the Distance between Clusters\n\n![image-20230303111030606](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230303111030606.png)\n\n## Clustering Assessment\n\nA good cluster should have the within-cluster-variation is as small as possible.\n\n* within - cluster - variation = $W(C_K)$\n* Good cluster: $minimize(\\sum_1^kW(C_k))$$\\hat{i}$  \n* $W(C_K) = \\frac{1}{|C_k|} \\sum_{i,\\hat{i}}\\sum_{j=1}^p(x_{ij}-x_{i^ij})^2$\n\n# **K-Means**\n\n## K-means Algorithm \n\n* Given a K, find a partition of K cluster\n* Each cluster is represented by the center of the cluster and the algorithm converges to stable centers of clusters.\n* the K-means algorithm is carried out in three steps:\n  ![image-20230303095557785](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230303095557785.png)\n\n## Example \n\n![image-20230303095421868](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230303095421868.png)\n\n![image-20230303095038636](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230303095038636.png)\n\n![image-20230303095058835](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230303095058835.png)\n\n![image-20230303095357240](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230303095357240.png)\n\n![image-20230303095344768](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230303095344768.png)\n\n![image-20230303095333733](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230303095333733.png)\n\n![image-20230303095510057](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230303095510057.png)\n\n**Difference between kNN Classifier (k Nearest Neighbor) & k-Means Clustering**\n\n![image-20230303092358992](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230303092358992.png)\n\n## Example Code\n\n### Load the Libraries\n\n```python\nimport numpy as np\nfrom sklearn import datasets\nfrom sklearn.cluster import KMeans\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nstyle.use(\"ggplot\") # grammar of graphic\n```\n\n### Read Data and Show the Scatterplot\n\n```python\nX = np.array([[1, 1],\n            [2, 1],\n            [4, 5],\n            [5, 4]])\n\nprint(X)\nplt.scatter(X[:,0], X[:,1], s=10, linewidth=5)\nplt.show()\n```\n\n**Output:**\n\n```\n[[1 1]\n [2 1]\n [4 5]\n [5 4]]\n```\n\n![download](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/download.png)\n\n### Build Clusters\n\n```python\nclf = KMeans(n_clusters=2)\nclf.fit(X)\n\ncentroids = clf.cluster_centers_\nlabels = clf.labels_\nprint(centroids)\nprint(\"labels=\", labels)\n```\n\n**Output:**\n\n```\n[[1.5 1. ]\n [4.5 4.5]]\nlabels= [0 0 1 1]\n```\n\n### Plot the Clusters\n\n```python\ncolors = [\"g.\",\"r.\",\"c.\",\"b.\",\"k.\",\"g.\"]\n\nfor i in range(len(X)):\n    plt.plot(X[i][0], X[i][1], colors[labels[i]], markersize = 10)\n    \nplt.scatter(centroids[:,0], centroids[:,1], marker='x', s=150, linewidth=5)\nplt.show()\n```\n\n![download (1)](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/download%20(1).png)\n\n## Parameter: `nstart`\n\nClustering algorithm will give slightly different results if we start with different initial values\n\nThe `kmeans` algorithm implemented in R has a parameter `nstart` which indicates multiple random initial assignments\n\nSuppose `nstart` = n\n\n* Algorithm builds ‚Äòn‚Äô clusters and only the best cluster is reported\n* Best cluster is the one which has minimum within-\n  cluster-variation\n\n**Disadvantage of K-means clustering** \n\n* You have specify the number of clusters\n\n# Hierarchical Clustering\n\nHierarchical clustering solves this problem ‚Äì no specification of number of clusters\n\nHierarchical structure also creates a hierarchical structure of data called **Dendrogram**\n\n## Strategy to build Hierarchical Clustering\nBottom-up approach\n\n* Agglomerative clustering\n\nCompute the Euclidean distance between data points\n\n* Shortest distance observations should be in a \n  single cluster\n* Next we compute the distance between cluster \n  that we have created and the next point closets to \n  it\n* Include that point in that cluster\n\n## Hierarchical Clustering Algorithm\n![image-20230303111410608](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230303111410608.png)\n\n## Example code\n\n[Mall_Customers.csv](https://uciunex.instructure.com/courses/16600/files/2324830?wrap=1)\n\n### Load the Libraries\n\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n```\n\n### Read Data\n\n```python\n'''\nSince we are performing clustering\nwe only need X variable\n\nClustering is a unsupervised method, \nthat's why we do NOT need the response variable or the 'y' variable\n'''\ndataset = pd.read_csv(\"Mall_Customers.csv\")\nX = dataset.iloc[:,[3,4]].values\n```\n\n### Plot the Dendrogram\n\n```python\n'''\nPlot the dendrogram\nThe plot will determine how many clusters we should need\n'''\nimport scipy.cluster.hierarchy as sch\n\ndendrogram = sch.dendrogram(sch.linkage(X,method='ward'))\nplt.title('Dendrogram')\nplt.xlabel('Customers')\nplt.ylabel('Eucledian Distance')\n\nplt.show()\n```\n\n![download3](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/download3.png)\n\n```python\n'''\nWe can have 3 clusters as standard\nOr we can have 5 clusters\nFind the longest line which is not crossed by horizontal line\n\nThis shows total number of clusters = 5\n'''\n \nfrom sklearn.cluster import AgglomerativeClustering\nhc = AgglomerativeClustering(n_clusters=5, affinity='euclidean',linkage='average')\n\ny_hc = hc.fit_predict(X)\n```\n\n```python\nplt.scatter(X[y_hc==0,0],X[y_hc==0,1],s=50,c='red',label='Cluster1')\nplt.scatter(X[y_hc==1,0],X[y_hc==1,1],s=50,c='blue',label='Cluster2')\nplt.scatter(X[y_hc==2,0],X[y_hc==2,1],s=50,c='green',label='Cluster3')\nplt.scatter(X[y_hc==3,0],X[y_hc==3,1],s=50,c='cyan',label='Cluster4')\nplt.scatter(X[y_hc==4,0],X[y_hc==4,1],s=50,c='magenta',label='Cluster5')\n\nplt.title('Cluster of the Customers')\nplt.xlabel('Annual Income (K$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\n```\n\n![download4](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/download4.png)\n","tags":["DSBA","Data Mining"],"categories":["Predicted Analytics: Tools & Techniques"]},{"title":"Iterators and Generators","url":"/docs/Immediate-to-Python-3-Iterators-and-Generators/","content":"\n# **Iterators**\n\n## Another look at `range()`\n\nThe `range()` function returns an iterator that will iterate through the values that we specify when we call `range()`.\n\nThe iterator only calculates and yields one value at a time.  It does not calculate or store those numbers in memory up front, it calculates them only when they are needed, one at a time.\n\n```python\nmy_range = range(11, 23)\nfor x in my_range:\n    print(x)\n```\n\n## File Object Are Also Iterators\n\nYou may have remembered from the prerequisite course how we opened files and iterated through the lines one at a time. The main takeaway is that each line is read in (iterated through) one at a time.  The entire file is not read up-front, each line is read into this notebook one at a time, as needed.\n\n```python\nfilepath = os.path.join(os.getcwd(), 'AAA_Fuel_Prices.csv')\ncount = 0\nwith open(filepath, 'r') as my_file:\n    for line in my_file:\n        line = line.strip()\n        print(line)\n        count += 1\n        if count > 10:\n            break\n```\n\n## Iterators Can Also Be Made From Lists (as well as other data types)\n\nIterators can also be made out of lists. This is what happens when we use a list in a for loop.\n\n```python\nmy_list = [1, 2, 3, 4, 5]\nfor x in my_list:\n    print(x)\n```\n\n```python\nmy_list_iterator = iter(my_list)\n\nprint(type(my_list_iterator))\nprint(my_list_iterator.__next__())\nprint(my_list_iterator.__next__())\nprint(my_list_iterator.__next__())\n```\n\n# **Generators**\n\nYou may wonder how can we write functions, like `range()`, that return iterators that we can iterate through. We can!  In order to do so, we must use the keyword `yield` instead of `return`.\n\n## Our Own Version Of Range\n\nLet's write our own version of the `range()` function.  We need to write a function the will yield numbers between a beginning and ending number. Note that when the function reaches the yield keyword, it will return that value (in this case, the value of `i`) and it will cease execution until it is asked for the next value. \n\n```python\ndef my_range(beg, end):\n    \"Generate numbers from start to stop\"\n    i = beg\n    while i < end:\n        yield i\n        i += 1\n```\n\n```python\n# Let's call the function to return a generator that we can iterate through. \nrange_of_nums = my_range(0, 10)\n\n# Now, let's call the __next__() method to get each value is the it is \n# \"yielded\" by the generator\n\n# This executes the code in the generator until it hits the yield statement.  It then stops until __next__() is called again.\nprint(range_of_nums.__next__())\nprint(range_of_nums.__next__())\nprint(range_of_nums.__next__())\n```\n**output:**\n\n```\n0\n1\n2\n```\n\nWe do not usually use the `__next__()` method directly. We are usually looping over the iterator, or passing the iterator to another iterative process (in these case,`__next__()` is still used \"under the hood\", but we are not using it directly as programmers). Below, we simple use `range_of_nums` in a loop, we also use the `my_range()` function directly in a for loop, just like you would use `range()`.\n\n```python\nfor num in my_range(30, 33):\n    print(num)\n```\n\n## **A Fibonacci Series Generator.**\n\nA Fibonacci Series is a series of numbers in which the next number is the sum of the two preceding numbers.  If we start with 0 and 1, then the series is 0, 1, 1, 2, 3, 5, 8, 13, etc.  This is a fun series that is often used in computer science lessons. Let's code a function that will return a generator that iterates through the Fibonacci Series (starting with 0 and 1).\n\n```python\ndef fibonacci_series(N):\n    \"\"\"Generate the Fibonacci series starting at 0 and 1\"\"\"\n    # We start by seeding 0 and 1 as the first two numbers\n    i_prev = 0\n    i = 1\n    yield i_prev  # we yield 0 first\n    # now in the following loop, we yield \"i\" and then calculate i_next by\n    # summing the two previous\n    for _ in range(N-1):\n        yield i \n        i, i_prev = i + i_prev, i\n```\n\n```python\nf_s = fibonacci_series(10)\nfor x in f_s:\n    print(x)\n```\n\n**Iterators Can Only Be Iterated Over Once**\n\nOnce we create an iterator, it can only be iterated over once.  For example, in the above cell we looped over the entirety of `f_s`.  Below, we try to loop over it again, but nothing prints. This is because we have already looped over the iterator to its end.  If we need to iterate again, we will have to create a new iterator.\n\n## File Word Counts\n\nAnother example, which will become more meaningful if you take the course Python Data Structures, Data Mining and Big Data, is producing a word counts from a file, line by line.\n\nLet's write a function that will generate word counts, from a file, line by line.\n\n```python\ndef file_word_count(filepath):\n    \"\"\"Generate word counts from ta file, line by line\"\"\"\n    # First, open the file\n    with open(filepath, 'r') as my_file:\n        # Loop through the lines\n        for line in my_file:\n            line = line.strip()  # strip whitespace from the line\n            words = line.split()  # split the line into words\n            # create a dictionary that we will store the word counts in\n            word_count_dict = {}\n            # loop through the words in the line and tally them in the\n            # dictionary\n            for word in words:\n                if word in word_count_dict:\n                    word_count_dict[word] += 1\n                else:\n                    word_count_dict[word] = 1\n            # now loop through the dictionary and yield up the word counts \n            for word in word_count_dict:\n                yield word, word_count_dict[word]\n```\n\n```python\naesopa10_path = os.path.join(os.getcwd(), 'aesopa10.txt')\ncounter = 0\nfor word, count in file_word_count(aesopa10_path):\n    print(word, count)\n    counter += 1\n    if counter > 2000:\n        break\n```\n\n# **Enumerate and Zip**\n\n## Enumerate\n\nEnumerate takes in an iterable object (like a list, tuple, or some other iterator) and outputs tuples that are enumerated. The first element in the tuple is the number and the second is the value from the original iterable object.\n\n```python\nmy_list = ['a', 'b', 'c']\n\nfor item in enumerate(my_list):\n    print(item)\n```\n\n```\n(0, 'a')\n(1, 'b')\n(2, 'c')\n```\n\n## Zip\n\nZip will take multiple iterable objects as inputs and output tuples that contain items from each iterable, in order. That is the first tuple will contain the first item from each iterable, the second tuple will contain the second items, etc...\n\n```python\ntuple_1 = (2012, 2012, 2012)\ntuple_2 = ('01', '02', '03')\n\nnew_list = []\nfor val1, val2 in zip(tuple_1, tuple_2):\n    print(val1, val2)\n    new_list.append(str(val1) + '_' + val2)\nprint(new_list)\n```\n\n```\n2012 01\n2012 02\n2012 03\n['2012_01', '2012_02', '2012_03']\n```\n\n```py\nfor x in zip(tuple_1, tuple_2):\n    print(x)\n```\n\n```\n(2012, '01')\n(2012, '02')\n(2012, '03')\n```\n\n","tags":["Python"],"categories":["Immediate to Python"]},{"title":"Functions Positional and Keyword Arguments","url":"/docs/Immediate-to-Python-2-Functions-Positional-and-Keyword-Arguments/","content":"\n# Positional Arguments\n\nThese are argument that are assigned based on their position in the function definition.  A example below will make this clear.\n\n```python\ndef print_greeting(username, date):\n    \"\"\"Print a simple greeting\"\"\"\n    greeting = 'Greetings, {}. The date is {}'.format(username, date)\n    print(greeting)\n```\n\n```python\n# test the function\nprint_greeting('Ronda', '2019-01-01')\n```\n\nWhy did the function treat 'Ronda' as the username argument and '2019-01-01' as the date argument? The answer is simple: it is because 'Ronda' was the first argument passed to the function and, in the function definition, username is the first argument in the function signature.\n\nThe arguments are assigned by *position*.\n\n# Keyword Arguments\n\nKeyword arguments are arguments that are passed to a function by the argument name.  For example, when calling the `print_greeting` function we can pass the arguments as shown in the cell below.\n\n```python\nmy_name = \"Will\"\ntoday = \"2019-07-01\"\nprint_greeting(date=today, username=my_name)\n\nprint_greeting(username=\"Padma\", date=\"2019-03-01\")\n```\n\n**Sometimes you can't use keyword to specify arguments, and sometimes you can only use keywords to specify certain arguments.**\n\nMany built in Python function are implemented in C and use a position-only API for processing argument. That means that there are some function with arguments that can not be specified by keyword. \n\n```python\nhelp(sorted)\n```\n\n![image-20230301180010676](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230301180010676.png)\n\nNotice the `/` in the function signature above?  This indicates that all the argument to the left of it can ONLY be specified by position. That is you can not pass the 'iterable' argument by keyword. (You may notice the `*` in the signature as well, we will discuss that in a moment)\n\n```python\nmy_list = [2, 3, 1]\n\n# We incorrectly try to pass the iterable argument by keyword. This will produce an error\n\n# We correctly pass the iterable argument by position\nsorted_list = sorted(my_list)\nprint(sorted_list)\n```\n\nNow, what about the `*` in the function signature? This means that you can ONLY specify the arguments to the right of it by keyword.  For example, in the sorted function, the arguments `key` and `reverse` can only be specified by keywords. See an example below:\n\n```python\nmy_list = ['a_3', 'b_2', 'c_1']\n\nsorted_list = sorted(my_list, key=lambda x: x.split('_')[-1])\n\nprint(sorted_list)\n```\n\n# Introducing *args\n\nNow, take your mind back to positional arguments.  What if you want a function to accept unlimited positional arguments? This is what the `*args` argument can do. By using the `*args` argument in our function definition, all positional arguments will be collected in a **tuple** named `args`. Let's define a function below using the `*args` argument to see how this works\n\n```python\ndef args_example(*args):\n    '''Print the contents of args.'''\n    print(args)\n    \nargs_example('Miguel', 'Mary', 'Paul')\n# Output: ('Miguel', 'Mary', 'Paul')\n```\n\n## Combining \\*args with other positional arguments.\n\nYou can have positional arguments *before* `*args`. `*args` will collect all the extra position arguments passed to the function.\n\n```python\ndef print_all_the_greetings_2(greeting, *args):\n  '''Print \"{greeting}, {name} for the greeting and all the names passed as arguments\n\t'''\n\tfor name in args:\n\t\tprint(\"{}, {}\".format(greeting, name))\n        \nprint_all_the_greetings_2('Good Morning', 'Winston', 'Aarav', 'Julie')\n```\n\n# Introducing \\*\\*kwargs\n\nMuch like `*args` captures extra positional arguments, `**kwargs` captures extra keyword arguments in a dictionary called `kwargs`.\n\n```python\ndef kwargs_example(**kwargs):\n    \"\"\"Print kwargs\"\"\"\n    print(kwargs)\n    \nkwargs_example(name=\"Paloma\", occupation='teacher')\n```\n\n# Mixing Positional and Keyword Arguments.\n\nWhen using both positional and keyword arguments you must specify the positional arguments **first**.\n\n```PYTHON\nprint_greeting(username=\"Padma\", date=\"2019-03-01\")\n\nprint_greeting(\"Padma\", date=\"2019-03-01\")\n```\n\n## Mixing Positional Arguments, \\*args, Keyword Arguments and \\*\\*kwargs\n\n```python\ndef test_arg_and_kwarg(arg1, arg2, *args, kwarg1, kwarg2, **kwargs):\n    print(arg1)\n    print(arg2)\n    print(args)\n    print(kwarg1)\n    print(kwarg2)\n    print(kwargs)\n    return\n\ntest_arg_and_kwarg(1, 2, 'extra_1', 'extra_2', kwarg1='kwarg 1',\n                   kwarg2='kwarg 2', extra_kwarg1='Bonus!',\n                  extra_kwarg2=\"I'm extra!\")\n```\n\n# Default Arguments\n\nSometimes you want to specify a default argument value to one of the arguments in your function. This means that if no value is passed to that specific argument, it will still have a default value and the function will run successfully.\n\nThis is very common. In fact, let's look at the documentation for the built in function `sorted` again.\n\nSee the 'key=None' and the 'reverse=False' in the function signature? This indicates that the default value for key is None, and the default value for reverse is False. This means that if we use the sorted function, these will be the values for these arguments if we do not specify other values.\n\n```python\nhelp(sorted)\n\n# Output:\nHelp on built-in function sorted in module builtins:\n\nsorted(iterable, /, *, key=None, reverse=False)\n    Return a new list containing all items from the iterable in ascending order.\n    \n    A custom key function can be supplied to customize the sort order, and the\n    reverse flag can be set to request the result in descending order.\n```\n\n## You can use \\* and \\*\\* to pass arguments to functions.\n\nJust as we used the \\* and \\*\\* to collection arguments that are passed to a function, you can also use the to pass arguments to a function from a tuple or dictionary.  Let's walk through two examples below.\n\n```python\ndef my_function(x, y):\n    result = x**2-y**(0.5)\n    return result\n    \n# Here we use the function and pass the values directly\nresult1 = my_function(2.1, 0.6)\n\n# Belww, we define a tuple with the values, and then pass those values to the\n# function by indexing them from the tuple.\nvalues = (2.1, 0.6)\nresult2 = my_function(values[0], values[1])\n\n# Here, we just use the '*' to dump the arguments in the values tuple directly\n# to the function\nresult3 = my_function(*values)\n\n# Finally, print all three results so that we ensure all methods give the same\n#result\nprint(result1, result2, result3)\n```\n\n```python\ndef my_greeting(date, greeting):\n    print('{}: {}'.format(date, greeting))\n    \n# Here we use the function and pass the values directly\nmy_greeting('2018-11-07', \"How are you today?\")\n\n# Below, we define a tuple with the values, and then pass those values to the\n# function by indexing them from the tuple.\nmy_greeting(greeting='How are you today?', date='2018-11-07')\n\n# Here, we just use the '*' to dump the arguments in the values tuple directly\n# to the function\nvalues = {'greeting': 'How are you today?', 'date': '2018-11-07'}\nmy_greeting(**values)\n```\n\n# An example of a built-in function that actually uses `args` and `kwargs`!\n\nNow, let's look at a built-in functions that uses both `*args` and `**kwargs`.\n\nThe function is the `format` method of string objects.  Depending on which version of the prerequisite course you have taken, you may have already seen this, but we will do a quick review anyways.\n\n## The .format() method of a string object.\n\nOne of the preferred methods to format strings in Python is to use the format method of string objects. (The latest preferred method is something called 'f strings'). Observe the example below.  First, we define a string and we put `{}` in the string wherever we would like to fill in the string by a variable. We then call the `.format()` method on the string and pass to it the variables we would like to use to fill in the `{}` portions of the string.  The `{}` are filled in by the order we pass the variables to the `.format()` method.\n\n```python \nmy_string = 'Hi, my name is {}. I live in {} and I work at {}'.format('Will', 'California', 'UCI')\nprint(my_string)\n```\n\nThe point here is that `.format()` can accept *any* number of arguments, it just depend how many `{}` we have to fill in in the string.  How does `.format()` do this? It uses the `*args` argument to capture all of the positional arguments passed, and then it fills in the `{}` in the order of the arguments.\n\n## The .format() method also uses kwargs!\n\nFormat also supports keywords, observe the example below:\n\n```python\nmy_string = 'Hi, my name is {name}. I live in {home} and I work at {work}'. \\\n    format(name='Will', home='California', work='UCI')\nprint(my_string)\n```","tags":["Python"],"categories":["Immediate to Python"]},{"title":"6 Regression Quality","url":"/docs/Predicted-Analytics-4-Regression-Quality/","content":"\nMetrics to measure the Quality of Regression \n\n* Correlation between the response variable and predictor variables \n* Root Mean Square Error (RMSE) \n* R-square + Adjusted R-Square \n* p-values of the predictor variables \n* Residuals are normally distributed. \n\n# **Linear Regression**","tags":["DSBA","Data Mining"],"categories":["Predicted Analytics: Tools & Techniques"]},{"title":"8 kNN Model","url":"/docs/Predicted-Analytics-6-kNN-Model.md/","content":"\n\n\n\n\n","tags":["DSBA","Data Mining"],"categories":["Predicted Analytics: Tools & Techniques"]},{"title":"7 Multi Variable Regression","url":"/docs/Predicted-Analytics-5-Multi Variable Regression/","content":"\n\n\n\n","tags":["DSBA","Data Mining"],"categories":["Predicted Analytics: Tools & Techniques"]},{"title":"9 Data Pre Dis","url":"/docs/Predicted-Analytics-7-DataPrep-Discreditization+OneHot Encoding/","content":"\n\n\n\n\n","tags":["DSBA","Data Mining"],"categories":["Predicted Analytics: Tools & Techniques"]},{"title":"5 Linear Regression","url":"/docs/Predicted-Analytics-3.2-Linear-Regression/","content":"\n*Linear regression* *analysis* is a widely used statistical technique used to explore relationships among continuous variables. In addition, this technique can be applied to categorical variables through the use of dummy variables.\n\nThere are many situations where linear regression is useful. For instance,\n\n- A market researcher can use regression to determine which one of several media markets is the best on which to spend their advertising dollars;\n- In business, regression can be used to predict a competitive salary offer for a programmer with a given number of years of experience;\n- In Major League Baseball, regression can be used to predict the salaries of free agents;\n- In social science research, regression can predict a wide range of phenomena‚Äîfrom economic performance to college enrollment.\n\n# **Simple Linear Regression**\n\n*Simple linear regression* refers to the statistical relationship between a dependent continuous variable, say *y*, and a single independent continuous variable, say *x*. This relationship takes the form of an equation that lets us predict values of *y* given values of *x*. Regression equations are useful for estimating new data values or exploring ‚Äúwhat if‚Äù questions.\n\nAs an example of simple linear regression, suppose you survey a group of workers and notice that those who have more years of education tend to have received higher starting salaries when they began working. A linear regression analysis allows you to quantify the relationship between starting salary and years of education through an equation that you can then use to make predictions about starting salaries for other individuals. \n\nLinear regression analysis allows you to (1) determine whether one or more continuous (independent) variables can effectively predict the values of an outcome (dependent) variable and (2) quantify the impact that each independent variable has on that outcome variable.\n\nThe relationship between a dependent variable and a single independent variable can be visualized using a scatter plot, as shown in Figure 1, below. The figure shows a set of data points along with the ‚Äúbest-fit‚Äù line that results from a regression analysis of that data.\n\n![A simple scatter with Fit Line of Cred card debt in the thousands by Household income in thousands showing the relationship between credit card debt and household income.](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/8z2gseSWiCfo4OvgpV_tyZr16er1sl1k6bsCGtrVhCrH8DrIRl3Jz4zaXHG7FmUiUiGqhjLPxpJXNjleOFdQP-8SW78yLrc_XzCSzZKO7wiBI7OFv7z-PCZ9VCRBgqkjM9weT-_CqN1WgquKbimuQA)\n\n*Figure 1: A scatter plot showing the relationship between credit card debt (in thousands) and household income (also in thousands)*\n\nThe line is represented in general form by the equation \n\n$$\ny = bx+a\n$$\n\nwhere *b* is the slope (the change in *y* per unit change in *x*) and *a* is the intercept (the value of *y* when *x* is zero). People are usually more interested in the slope than in the intercept. Also, note that *a* and *b* depend on the unit of measurement of the variables and, as such, do not necessarily indicate anything about the strength of the relationship.\n\nAs you can see, the data points don‚Äôt necessarily fall on this line, so it‚Äôs important to evaluate how well the line actually represents the data. To determine this, we start by looking at the *correlation* between the *x* and *y* values, and calculating a *correlation coefficient, r,* to quantify this relationship. Because the correlation coefficient can take on negative values and we prefer to work with only positive values, we typically square it (*r**2*) and refer to it as *R-squared.* This quantity lies on a scale from 0 (no linear association) to 1 (perfect linear association), and can be interpreted as the proportion of variation in one variable that can be predicted from the other. Thus an R-squared of 0.5 indicates that you can account for 50% of the variance in one variable if you knew the values of the other variable. Think of this value as a measure of the improvement in your ability to predict one variable from the other (or others if there are multiple independent variables).\n\nWhile R-squared provides a good starting point for determining how well your regression equation fits your data, a more rigorous way involves performing *statistical tests* to determine the *statistical significance* of the relationship. A relationship that is statistically significant means that your regression equation can reliably make predictions given new values of the independent variable. In other words, the predictions are more likely to be due to some factor of interest rather than random chance.\n\nReferring to Figure 1, notice that many points fall near the line but some are quite a distance from it. For each point, the difference between the value of the dependent variable and the value predicted by the equation (the value on the line) is called the *residual* (also known as the *error*). Points above the line have positive residuals (the equation under-predicted them), those below the line have negative residuals (the equation over-predicted them), and those points falling on the line have a residual of zero (perfect prediction). Points having relatively large residuals are of interest because they represent instances where the prediction performed poorly. Outliers, or points far from the positions of the other points, are of interest in regression because they can exert a considerable influence on the equation (especially if the sample size is small).\n\nLet‚Äôs apply linear regression analysis to an example in which household income is the independent (predictor) variable and credit card debt is the dependent variable. A standard linear regression analysis generates three tables depicting the relationship between the two variables. Here are several key points about the information appearing in those tables:\n\n- The *model summary table* provides several measures of how well the model fits the data (see Table 1).\n- As discussed above, R-squared, which can range from 0 to 1, is the correlation coefficient squared. It can be interpreted as the proportion of variance of the dependent measure that can be predicted from the independent variable(s).\n- The *adjusted R-squared* represents a technical improvement over R-squared in that it explicitly adjusts for the number of predictor variables relative to the sample size. If the adjusted R-squared and R-squared differ dramatically, it is a sign that you have used too many predictor variables for the sample size.\n- The *standard error of the estimate* is a measure of the standard deviation of the residuals. It represents the amount of variation that is not accounted for by the regression line on the scale of the dependent variable.\n\n![image-20230223222504355](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230223222504355.png)\n\nWhile the goodness-of-fit measures indicate how well you can expect the regression equation to predict the dependent variable, they do not tell whether there is a statistically significant relationship between the dependent and independent variable(s). For this, we turn to an *analysis of variance* (ANOVA) table, which presents technical summaries (i.e., sums of squares and mean square statistics) of the variation accounted for by the prediction equation (Table 2). The main goal is to determine whether there is a statistically significant (non-zero) linear relation between the dependent variable and the independent variable(s).\n\nThe significance (Sig.) column in the ANOVA table provides the probability that there is no relationship between the dependent and independent variable(s). A zero or nearly zero Sig. value means that the relationship is statistically significant and that you should further investigate the results of the regression coefficients appearing in the Coefficients table (Table 3).\n\n![image-20230223222446131](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230223222446131.png)\n\n*Table 2: ANOVA table showing sums of squares, mean squares, and the probability that there is no relationship between dependent and independent variables*\n\nThe first column contains a list of the independent variables plus the intercept (constant). The intercept is the value of the dependent variable when the independent variable is 0‚Äîit is also *a* in the equation $y=bx+a$.\n\n- The column labeled B contains the estimated regression coefficients you would use in a prediction equation. In this example, the coefficient for household income indicates that on average, each additional unit increase in household income is associated with an increase of 0.030 in credit card debt.\n- The Std. Error column contains standard errors of the regression coefficients. The standard errors can be used to calculate a 95% confidence interval above and below the B coefficients. (This means that statistically, the true value of B will fall within this interval 95% of the time.)\n- Betas are standardized regression coefficients used to judge the relative importance of each of several independent variables.\n- The t statistics provide a significance test for each B coefficient, indicating which predictors are statistically significant.\n\n![image-20230223222431472](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230223222431472.png)\n\n*Table 3: A tabulation of statistical information for the coefficients in the regression model relating credit card debt to household income*\n\n# **Multiple Linear Regression**\n\nRegression involving more than one independent variable is called *multiple linear regression* and is a direct extension of simple linear regression. When running a multiple linear regression analysis you are again concerned with fitting a linear model to the data, determining whether any of the variables are significant predictors, and estimating the coefficients of the best-fitting prediction equation. In addition, you are interested in the relative importance of the independent variables in predicting the dependent measure.\n\nContinuing with the previous example, we add age, years with current employer, and having previously defaulted as independent variables to the model, which now explains about 43% of the variance in credit card debt. This is a substantial increase in explanatory power from the 30% we were able to explain with just one predictor variable, namely household income.\n\n![image-20230223222534173](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230223222534173.png)\n\n*Table 4: The model summary table for a multiple linear regression*\n\nNot surprisingly, we still have a statistically significant model as shown in the ANOVA table Table 5).\n\n![image-20230223222555334](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230223222555334.png)\n\n*Table 5: ANOVA table showing sums of squares, mean squares, and the probability that there is no relationship between dependent and independent variables*\n\nFinally, we can see in Table 6 that all of the variables in the model are statistically significant except age, which means that we can remove this variable from the model. We can also see that household income is the most important predictor, followed by previous defaults, and then years with the current employer. We can use the regression equation that resulted from this analysis to predict someone‚Äôs credit card debt as follows:\n\n$$\ncreditCardDebt=0.026(householdIncome)+0.067(yearsWith Employer)+1.627(previouslyDefaulted)-0.721\n$$\n\nNote that ‚Äúpreviously defaulted‚Äù is a categorical variable, which is coded as a dummy variable in which ‚Äúno‚Äù is 0 and ‚Äúyes‚Äù is 1.\n\n![image-20230223222722318](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230223222722318.png)\n\n*Table 6: A tabulation of statistical information for the coefficients in the regression model relating credit card debt to household income, age, years with employer, and previous defaults*\n\n# **Polynomials and Interaction Terms**\n\nThis is an advanced and important topic. It is not true that linear regression can identify only linear relationships. It can handle curvilinear relationships as well if you know how to prepare the data. For instance, if you determined (through visual inspection) that income would predict credit card debt better with a quadratic relationship, you could do the following.\n\n- Create a new variable consisting of income squared\n- Add another coefficient corresponding to the new variable\n\nIt would look like this:\n\n$$\ny=a+b_1x_1+b_2x_1^2\n$$\n\nwhere $x_1$= income and $x_1^2$= income squared.\n\nAnother feature you might uncover through visual inspection is a pair of variables that interact. Here again the solution is to create a new variable. A good indicator that you have an interaction occurring is if the slopes of the regression lines for two groups (e.g., males and females) are different. In our example, this would suggest that the relationship between credit card debt and income is different for people that had previously defaulted on a loan than it is for people that had not previously defaulted on a loan (see Figure 2).\n\nThe resulting regression formula looks like this:\n\n$$\ny=a+b_1x_1+b_2x_2+b_3x_1x_2\n$$\n\nwhere $x_1$= income and $x_2$= previously defaulted. The interaction appears as the product $x_1x_2$.\n\nIf you fail to include the interaction term, the model will mathematically force the lines to be parallel and maintain the same ‚Äú gap‚Äù over the entire income range. Figure 2 makes it clear that this would not be accurate since the gap is clearly more severe at higher levels of income. Polynomials and interaction terms can seem tricky and abstract at first, but they are critical for understanding neural networks, which will be presented in a later module.\n\n![A simple scatter with Fit Line of Cred card debt in the thousands by Household income in the thousands by Previously defaulted showing differing linear regression line slopes for customers that had and had not previously defaulted on a loan](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/Ej3sVrRFTs-bdKkJtOaIiAGX-PEAf5_Qu3oJrL9rB6FV4Ba9qaasgKCZRvvuOfmXwVbQwHnykt_t91faPELw1vPP7Z8UHXUAWMavQhsVs6EH5eqKCsegJRdqbzd7etezFIwh0fLcwoN5-UqvJjIRbw)\n\n*Figure 2: Differing linear regression line slopes for customers that had and had not previously defaulted on a loan*","tags":["ML","DSBA","Data Mining"],"categories":["Predicted Analytics: Tools & Techniques"]},{"title":"4 Introduction to Regression","url":"/docs/Predicted-Analytics-3.1-Introduction-to-Regression/","content":"\n# **Linear Regression ‚Äì Ordinary Least Square (OLS)**\n\n2 variable regression - how a response variable $y$ changes the predictor (explanatory) variable $x$ changes.\n\n$$\ny = \\beta_1x + c\n$$\n\nMultiple regression - how a response variable $y$ changes as the predictor (explanatory) variables $x1$, $x2$, ... $xn$ change\n\n$$\ny = \\beta_1x_1+\\beta_2x_2+\\beta_3x_3+...+\\beta_nx_n+c\n$$\n\n**Single Variable Polynomial Regression: First degree to Fifth Degree**\n\nThe concept can be extended to polynomial regression\n\n$$\n\\begin{align}\ny &= c + a_1x \\\\\ny &= c + a_1x + a_2x^2 \\\\\ny &= c + a_1x + a_2x^2 + a_3x^3 \\\\\ny &= c + a_1x + a_2x^2 + a_3x^3 + a_4x^4 \\\\\ny &= c + a_1x + a_2x^2 + a_3x^3 + a_4x^4 + a_5x^5 \\\\\ny &= c + a_1x + a_2x^2 + a_3x^3 + a_4x^4 + a_5x^5 +a_nx^n\\\\\n\\end{align}\n$$\n\n**Regression Strategy: Ordinary Least Squares (OLS)**\n\n![image-20230222092629577](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230222092629577.png)\n\n# **Nearest Neighbor Regression**\n\nA method for predicting a numerical variable $y$, given a value of $x$:\n\n* Identify the group of points for which the values of $x$ are close to the given value\n* The prediction is the average of the $y$ values for the group\n* ","tags":["ML","DSBA","Data Mining"],"categories":["Predicted Analytics: Tools & Techniques"]},{"title":"3 Modeling Techniques","url":"/docs/Predicted-Analytics-2.2-ML-Techniques/","content":"\n# **Modeling Methods**\n\n| #    | Modeling Methods               | Response Variable: Numerical /Categorical | Supervised or Unsupervised | Strategy                              |\n| ---- | ------------------------------ | ----------------------------------------- | -------------------------- | ------------------------------------- |\n| 1    | Linear & Polynomial Regression | Numerical                                 | Supervised                 | Error Based<br/>Minimizing Error      |\n| 2    | Logistic Regression            | Categorical (Binary)                      | Supervised                 | Maximizing Likelihood                 |\n| 3    | Discriminant Analysis          | Categorical                               | Supervised                 |                                       |\n| 4    | K Nearest Neighbor             | Categorical                               | Supervised                 | Similarity Based                      |\n| 5    | Decision and Regression Trees  | Categorical + Numerical                   | Supervised                 | Information Based                     |\n| 6    | Na√Øve Bayes                    | Categorical                               | Supervised                 | Probability Based                     |\n| 7    | Neural Networks                | Numerical + Categorical                   | Supervised                 | Mimicking Human Brain                 |\n| 8    | Clustering                     |                                           | Unsupervised               |                                       |\n| 9    | Principal Component Analysis   |                                           | Unsupervised               |                                       |\n| 10   | Support Vector Machines        | Categorical                               | Supervised                 | Error Based                           |\n| 11   | ARIMA : Time Series            | Numerical                                 | Supervised                 | Auto Regression & Moving <br/>Average |\n\n# **Estimation or Classification**\n\n**Goals of Machine Learning Application: Estimation or Classification**\n\n* **Estimation** ‚Äì Regression modeling technique is used\n\n  *Output is a number*\n\n  * House price\n  * Product sales for next quarter\n  * GNP growth for the next quarter\n  * Employment\n\n* **Classification** ‚Äì Na√Øve Bayes, Decision Trees etc. modeling techniques are used\n\n  *Output is a categorical variable*\n\n  * Sports team will win or lose\n  * Email is junk or not\n  * Which grade student will get\n  * Tweet is positive or negative\n\n# **Classification of Modeling Methods**\n\n**Response Variable**\n\n* Numerical or Categorical\n\n**Supervised or unsupervised**\n\n**Strategy**\n\n* Error based learning\n* Similarity Based Learning\n* Information Based Learning\n* Probability Based Learning\n* Mimicking the Human Brain\n\n# **Supervised vs. Unsupervised**\n\n**Supervisor learning** is the most common learning type where **there is a target/output variable** (which is also called supervisor)\n\n* Supervisor (target variable) teaches the algorithm how to build/learn the pattern model\n* In PA, supervised learning ‚âà predictive modeling\n\n**Unsupervised learning has NO target variable**\n\n* No supervisor to teach ‚Üí algorithm has to learn by itself\n* In PA, unsupervised learning ‚âà descriptive modeling\n\n![image-20230221112637145](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230221112637145.png)\n\n# **Classifying Based on Strategy to Build a Model**\n\n## Error based learning\n\n* Linear Multi Variable Regression\n* Support Vector Machine\n\nIn error-based machine learning\n\n* We perform a search for a set of parameters for a parameterized model\n* That minimizes the total error across the predictions made by the model\n* With respect to a set of training instances (training data)\n\n![image-20230221113355334](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230221113355334.png)\n\n## Similarity Based Learning\n\n* K Nearest Neighbor\n\nCompute the distance matrices between objects\n\n![image-20230221113427635](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230221113427635.png)\n\n## Information Based Learning\n\n* Decision Trees\n* Regression Trees\n* Split of decision trees are based on the entropy of the tables\n\nLearn by Asking Questions\n\n* The Socratic approach to questioning is based on the practice of disciplined, thoughtful dialogue.\n* Socrates, the early Greek philosopher/teacher, believed that disciplined practice of thoughtful questioning enabled the student to examine ideas logically and to determine the validity of those ideas.\n\n![image-20230221113520227](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230221113520227.png)\n\n## Probability Based Learning\n\n* Na√Øve Bayes\n\nProvides a way to compute *reverse* probability. \n\nGiven $P(B|A)$, we can compute $P(A|B)$\n\n$$\nP(A|B) = P(B|A)P(A)/P(B)\n$$\n\nNa√Øve Assumption: Assuming Variable Independence\n\n## Mimicking the Human Brain: Neural Networks\n\n* Extract linear combinations of the inputs\n* Model the target as the non-linear functions of these features\n\n![image-20230221113814241](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230221113814241.png)\n\n**Deep Learning:** Complex set of Neural Networks with many layers of processing\n\n![image-20230221114146210](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230221114146210.png)\n\n**Main Applications of Deep Learning Neural Networks**\n\n* Image Recognition\n  * Convolution Neural Networks\n* Image Classification\n  * Convolution Neural Networks\n* Hand Writing Identification\n* Speech Recognition\n  * Long Short-Term Memory Networks","tags":["ML","DSBA","Data Mining"],"categories":["Predicted Analytics: Tools & Techniques"]},{"title":"2 Introduction to Predictive Modeling","url":"/docs/Predicted-Analytics-2.1-Introduction-to-Predictive-Modeling/","content":"\nData analysis involves a number of modeling techniques that can be classified as three main types:\n\n- Predictive\n- Clustering\n- Association\n\n# **Predictive Modeling**\n\n*Predictive modeling*, sometimes called ***supervised learning***, focuses on understanding or making predictions about a given variable based on one or more other variables. **The ultimate goal of predictive analysis is accuracy**. For example, you may want to predict which potential customers are more likely to apply for a credit card based on a knowledge of their demographic and financial information. In this scenario, there are two types of variables:\n\n- **The** **dependent variable** **or** **target**: The variable you are trying to predict or understand (i.e., the likelihood of applying for a credit card)\n- **The** **independent variables** **or predictors**: The variables you are using as a basis for predicting or understanding the target variable (i.e., demographic and financial information)\n\nBelow are several additional applications of predictive modeling:\n\n- Determining which students in a class will pass or fail\n- Predicting which parts of a city will experience increasing crime (predictive policing)\n- Forecasting the number of unfilled hotel rooms three months from now\n- Projecting which patients are likely to have a heart attack\n- Estimating how much each customer will purchase when shopping online\n- Classifying shipping containers according to the likelihood that they carry drugs or weapons\n- Identifying IP addresses that are sending unusual amounts of information\n\n# **Cluster Analysis**\n\nCluster analysis, or segmentation, is a type of unsupervised learning problem that is very different from predictive modeling. Cluster analysis is appropriate when you can associate each case in a dataset with other cases that share similar distinct characteristics. You end up with several groups, in which the members of each group are very similar to each other but very different compared to members of other groups.\n\nCluster analysis is often used in marketing campaigns so that customers receive ads tailored for the group to which they belong rather than generic ads. These groups are identified via cluster analysis. In such a scenario, there is no dependent variable; only independent variables are used to segment the cases.\n\nCases in which the variables have similar values are grouped into *clusters* in an attempt to find homogenous subsets. Determining the number of clusters to create is part of the challenge of such techniques. Since clustering is exploratory in nature, the resulting clusters are not necessarily right or wrong. Instead, cluster solutions should be judged by their ability to address the specific business problem you are trying to solve. Applications of cluster analysis include:\n\n- Market research\n- Plant and animal ecology\n- Medical imaging (e.g., PET Scans)\n- Service/product usage pattern identification\n- Social network analysis\n- Crime analysis\n- Anomaly detection\n\n# **Association Modeling**\n\nCompanies like Amazon and Netflix have made *association modeling* commonplace. As consumers, most of us have encountered recommendation engines where a movie is recommended based upon our prior viewing habits or books are recommended based on our prior purchases (or even just our prior browsing behavior). **Association models use transactional data to predict future transactions.** The idea is that you may be able to suggest additional items that a person may want or need based on their previous buying behavior. This results in statements such as, ‚ÄúPeople who bought product A and product B might also like product C‚Äù appearing on their computer screens.\n\nAssociation modeling is often described primarily as a kind of market basket analysis, but while it is strongly associated with retail data, it can also be applied in other areas. For example, in predictive maintenance, a pair of part failures might frequently be associated with the failure of a third part even though that third part doesn‚Äôt show evidence of trouble at the time the first two fail.\n\n**Transactions in association models often occur at the same time.** For instance, many items might be listed on a grocery store receipt, but, there is no indication of which purchases occurred before others. Hot dogs and hot dog buns may be frequently purchased together, but there is no ‚Äúrule‚Äù that indicates which purchase occurred first. In a predictive model, you might say that hot dogs ‚Äúpredict‚Äù buns or that buns predict hot dogs. A further refinement involves ***sequence analysis***, which does take into consideration the order in which events, such as purchases, occur. This can be useful in predictive maintenance or in web mining, where it might be beneficial to know the sequence in which website visitors click on links and buttons on a page or move to other pages in the site.\n\nApplications of association modeling include:\n\n- Market basket analysis\n- Retail data analysis\n- Web usage \n- Insurance claim analysis\n- Service usage\n- Medical procedures\n\n# **Overview of Predictive Models**\n\nThis course covers only some of the most popular predictive models. Specifically, we‚Äôll take a look at the following:\n\n- Statistical models\n- Decision Tree models\n- Machine Learning models\n\n## Statistical Models\n\n***Statistical models* produce equations and *statistical tests* guide predictor selection. These models make certain assumptions whereas *rule induction* and *machine learning* models do not.** Here are several characteristics of statistical predictive models:\n\n- Predictions are expressed as equations.\n- Equations allow users to see the effect of a one-unit change on any field and how this change impacts the outcome variable.\n- Predictive models are based on statistical theory, which involves developing hypotheses and assessing statistical significance. This allows you to easily identify the important variables.\n- Predictive models involve assumptions about the data, which may limit the situations in which some models can be used.\n\nBelow is a list of some statistical models.\n\n- Logistic Regression\n- Discriminant Analysis\n- Linear Regression\n- Generalized Linear Models\n- Cox Regression\n- Time Series\n\n## Decision Tree Models\n\nA *decision tree* or *rule induction model* is an important type of predictive model. It derives a set of rules in relation to a dependent variable. The model‚Äôs output shows the reasoning for each rule and can therefore be used to understand the decision-making process that drives a particular outcome. Models that produce decision trees belong to this class of models. Generally, decision tree predictive models:\n\n- Create segments that are mutually exclusive and exhaustive (identify homogeneous subgroups)\n- Create rules for making predictions about individual cases\n- Can easily handle a large number of predictors\n- Can account for interaction and non-linear relationships\n- Have few assumptions\n- Can create overly complex models that over-fit data (does not generalize)\n\nBelow is a list of several rule induction models:\n\n- CHAID\n- CART\n- C5.0\n- QUEST\n- Decision List\n- MARS\n\n## Machine Learning Models\n\n*Machine learning models* are optimized for learning complex patterns. Unlike traditional statistical techniques, no assumptions are made about the data. Machine learning models do not produce a set of rules like rule induction models, nor do they produce easy-to-understand equations like statistical models. Thus, machine learning models are often said to be ‚Äúblack box‚Äù models. They produce a set of equations, but because there is a hidden layer (possibly several hidden layers), the interpretation of the coefficient weights is not straightforward as it is with traditional statistical models or rule induction models. Machine learning predictive models:\n\n- Are optimized for learning complex patterns\n- Can account for interaction and non-linear relationships\n- Have few assumptions \n- Are essentially ‚Äúblack box‚Äù models‚Äîtheir interpretation is not straight-forward\n- Are used for predictive accuracy but not for understanding the mechanics behind a prediction\n\nBelow is a list of several machine learning models:\n\n- Neural Networks\n- Support Vector Machines\n- Random Forest\n- Na√Øve Bayesian Algorithms\n- Gradient Boosting Algorithms\n- K-Nearest Neighbors\n\n# **Model Validation**\n\nThe process of statistical hypothesis testing, which involves a result‚Äôs statistical significance in the context of certain data distribution assumptions (such as having normally distributed errors), helps us determine when we have found a valid and reliable result. However, most data-mining methods do not depend on specific data distribution assumptions for drawing inferences from the sample to the population. So how is validation achieved? Model validation in data mining is usually done by partitioning the data into training and testing datasets. Models are developed from the training data and then the models‚Äô predictions are tested on the testing data. Validity is established by demonstrating that the model applies to data different from what was used to derive the model. Statisticians often recommend such validation for statistical models, but it is crucial for more general (less distribution-bound) data-mining techniques.\n\n# **How to Choose a Model**\n\nChoosing a model is difficult. Obviously, if you have a variable in the data file that you want to predict, then any of the predictive models (depending on the target variable‚Äôs level of measurement) will perform the task albeit with varying degrees of success. If you want to find groups of individuals that behave similarly on a number of fields in the data, then any of the clustering methods are appropriate. The use of association rules, while not directly giving you the ability to make predictions, are extremely useful as a tool for understanding the various patterns within the data.\n\nHowever, determining which particular prediction technique will work best depends specifically on how the variables you want to predict are related to the predictors. There are suggested guidelines as to when one technique may work better than another, but these are only suggestions and not rules.\n\nFrom the previous discussion, it follows that more than one prediction model can be used to predict an outcome. The business context provides the first deciding factor in selecting a model. For example, if your goal is to extract a set of rules from the model, a rul*e induction model* is the only choice. Alternatively, if the model itself is of no interest but must nevertheless be as accurate as possible, then any of the models could be a candidate for the task. When one class of model is preferred but there are many models within that class, how do you choose a specific model?\n\nEach model has different characteristics when it comes to they way in which:\n\n- Missing values are handled\n- Continuous predictors are handled\n- Categorical predictors are handled\n- Outliers are handled\n- The number of predictors impacts prediction\n- The model scores data\n\nThere are many subtle differences between the models. In the end, however, it is always the business users who balance the pros and cons, and decide which model or combination of models should be used. There is a wide range of possibilities and it is only the business user who can decide what to do.\n\nData analytics and reporting tools such as KNIME provide for simplicity in building models. Machine learning models, rule induction models (decision trees), and statistical models can be built with great ease and speed, and their results compared. You must remember that data mining is an iterative process: models will be built, broken down, and often even combined before the user is satisfied with the results.\n\nOne final yet important point to keep in mind when building models is that software will only find rules or patterns in data if they actually exist. You cannot extract a model with high predictive accuracy if there are no associations between the predictors and dependent variables.\n\n# **Reference** \n\n**Course text:** UCI. (2020). [Introduction to Predictive Modeling. ](https://docs.google.com/document/d/1lQI25BjQD4mNhVDyDWjfn7x1cFlfKfX6NnXl0zUUKIw/edit?usp=sharing)\n\n","tags":["ML","DSBA","Data Mining"],"categories":["Predicted Analytics: Tools & Techniques"]},{"title":"Sysargv, Argparse and Function Docstring","url":"/docs/Immediate-to-Python-1-Sysargv-Argparse-and-Function-Docstring/","content":"\n# **Sysargv**\n\n```python\n'''\nThis is a simple script.\n'''\nimport sys\n\nprint(__doc__)\t# output: docstring\n\nprint(sys.argv)\t# output: System argument vector\n```\n\n# **Argparse**\n\n## Example 1\n\n```python\n'''\nThis is a simple script.\n'''\nimport argparse\n\nparser = argparse.ArgumentParser(description=__doc__)\nparser.add_argument('echo', help=\"the string you want to write to the file\")\nargs = parser.parse_args()\nprint(args.echo)\n```\n\n**Output:**\n\n![image-20230226181135214](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230226181135214.png)\n\n## Example 2\n\n```python\nimport argparse\n\nparser = argparse.ArgumentParser(description=__doc__)\nparser.add_argument('x', help=\"the value for x\", type=int)\nparser.add_argument('y', help=\"the value for y\", type=int)\nparser.add_argument('-f', '--formula', help=\"the formula you'd like to run\",\n                    choices=[\"power\", \"subtract\"], default=\"power\")\n\nargs = parser.parse_args()\n\nif args.formula == \"power\":\n    print(args.x ** args.y)\nelif args.formula == \"subtract\":\n    print(args.x - args.y)\n\n```\n\n**Output:**\n\n![image-20230226183445409](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230226183445409.png)\n\n# **Function Docstring**\n\n## One-line Docstring\n\nThis is a simple function with a simple one-line docstring. Notice how the docstring is written as a command, \"Return the value...\" not a description \"This function returns the value...\"\n\n```py\ndef add_2(num):\n    \"\"\"Return the value of num + 2.\"\"\"\n    return_num = num + 2\n    return num\n```\n\n### Printing Docstrings\n\nWe can print doc strings by printing the **__doc__** attribute of the function.  This is a built-in attribute and all objects have it (even if the value is None).\n\nMany editors and IDEs have special functionality / commands to print docstrings. For example, if you write the '?' key after a function name, in Jupyter Notebook, and then evaluate the cell, it will open a window with the docstrings.  See the example below.\n\n```py\n# Below is an example of printing the docstring directly\nprint(add_2.__doc__)\n```\n\n![image-20230226185514333](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230226185514333.png)\n\n```py\nhelp(add_2)\n```\n\n![image-20230226185537947](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230226185537947.png)\n\n```python\n# Below is an example of using Jupyter Notebooks '?' command\nadd_2?\n```\n\n## Multi-line Docstrings\n\nA multi-line docstring provide more information but it still starts with single line description, followed by a blank line, and then a more detailed description. The more detailed description includes a description of the arguments, the return value(s), exceptions that the function raises, and any side effects.  It may also included references to similar functions and other helpful information.\n\n```py\ndef circle(radius):\n    \"\"\"Return the circumference and area of a circle, given the radius.\n    \n    Parameters\n    ----------\n    radius : float, int\n        the radius of the circle.\n        \n    Returns\n    -------\n    circumference : float\n        the circumference of the circle.\n    \n    area : float\n        the area of the circle.\n    \n    \"\"\"\n    circumference = 2*math.pi*radius\n    area = math.pi*(radius**2)\n    return circumference, area\n```\n\n### Printing Docstrings\n\n```python\n# method 1\nprint(circle.__doc__)\n\n# method 2\ncircle?\n```\n\n![image-20230226191611138](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230226191611138.png)","tags":["Python"],"categories":["Immediate to Python"]},{"title":"1 Introduction to Predictive Analytics","url":"/docs/Predicted-Analytics-1-Introduction-to-Predictive-Analytics/","content":"\n# **The Data Mining Process**\n\n***Data mining* is a general term that encompasses a number of data analysis techniques used to extract meaningful information from (large) data** files without necessarily having preconceived notions about what will be discovered. The useful information often consists of patterns and relationships in the data that were **previously unknown or even unsuspected**.\n\nA common misconception is that data mining involves passing huge amounts of data through intelligent technologies that find patterns and give magical solutions to business problems. This is not true, although data mining does involve more automation than one typically finds in traditional statistical analyses.\n\n**Data mining is an interactive and iterative process.** Business expertise must be used together with advanced technologies to identify underlying relationships and features in the data. A seemingly useless pattern in data discovered by data mining can often be transformed into a valuable piece of actionable information using business experience and expertise.\n\nMany of the techniques used in data mining are referred to as ***modeling*** and require a different approach for model generation and testing compared to standard, traditional statistics. While **traditional statistics focuses on probabilities and hypothesis** testing using data-specific research, **data mining focuses on using historical data** accumulated during the normal course of business. It is then the responsibility of the data miner to select, prepare, and analyze the data to determine whether it is acceptable and likely to generalize to the population of interest. Due to the typically large files involved and the weak assumptions made about the distribution of the data, **data mining tends to be less focused on statistical significance tests and more focused on practical importance.**\n\nData mining has been used in hundreds of applications, including:\n\n- Detecting fraudulent financial activity;\n- Identifying specific purchases that are more likely to lead to additional purchases;\n- Classifying customers into groups based on distinct purchase or usage patterns; and\n- Predicting which page a website visitor will visit next.\n\n# **The Art and Practice of Data Mining**\n\nThis is the definition that Keith McCormick has previously used in books and presentations. \n\n> *Data mining is the selection and analysis of data accumulated during the normal course of business. The goal is to find (and confirm) previously unknown relationships that can be used to develop predictive models that, when applied to new data, can produce valuable insight for making business decisions. Several points are worth emphasizing:*\n>\n> - *The data is not new.*\n> - *The data is not collected solely to perform data mining.*\n> - *The data miner is not testing known relationships (neither hypotheses nor hunches) against the data.*\n> - *The patterns must be verifiable.*\n> - *The resulting models must be capable of something useful.*\n> - *The resulting models must actually work when deployed on new data.*\t\n\nFor additional information on data mining, please visit [https://keithmccormick.com/data mining-defined/](https://keithmccormick.com/data-mining-defined/)\n\n# **Introducing CRISP-DM**\n\nThe typical data mining process can become complicated very quickly. There is much to keep track of‚Äîcomplex business problems, multiple data sources, varying data quality across data sources, an array of data mining techniques, different ways of measuring data mining success, and so on. To stay on track, it helps to have an explicitly defined process model for data mining that can guide you through critical issues and ensure that important points are addressed. This process model can serve as a data mining road map that helps you stay on course as you dig into the complexities of the data.\n\nThe data mining process model we recommend is the ***CRoss-Industry Standard Process for Data Mining* (CRISP-DM)**, which is considered the de facto standard for conducting a data mining project. As you can tell from the name, this model is designed as a general model that can be applied to a wide variety of business problems in just about any industry. The model includes six phases starting with *business understanding*.\n\n![image-20230223173559821](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230223173559821.png)\n\n![image-20230223173655160](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230223173655160.png)\n\n## Business Understanding\n\nThe business objectives and question(s) to be answered, and formulating a concrete plan for proceeding through the data mining process. You need to:\n\n- Identify business objectives and success criteria;\n- Perform a situational assessment (resources, constraints, assumptions, risks, costs, and benefits);\n- Determine the goals of the data mining project;\n- Identify success criteria; and\n- Produce a project plan.\n\n## Data Understanding\n\nOnce the business understanding phase is complete, you‚Äôre ready to begin collecting data and associated relevant information (such as the source of the data and the manner in which it was collected) for use in the project. It is also crucial to meet with subject matter experts (SMEs) to review what you have been collecting to ensure completeness (i.e., that no necessary data is missing) and verify your understanding of the data. It is also important to discuss the data in the context of the business problem you‚Äôre addressing. Sometimes, it may be necessary to return to the business understanding phase before proceeding.\n\nWith data in hand, you can begin exploring it and becoming thoroughly familiar with its characteristics. For each field in your dataset, you should review **the distribution, range (for continuous fields), outliers, anomalies, and missing values (type and amount)**. You can also begin looking for obvious, interesting patterns in the data such as relationships between a predictor and a target field. You‚Äôll need to:\n\n- Understand your data resources;\n- Know the characteristics of the data;\n- Describe the data;\n- Explore the data; and\n- Verify data quality.\n\n## Data Preparation\n\nAfter cataloging your data resources, it‚Äôs time to prepare your data for mining. Data preparation is by far the most time-consuming step in the data mining process. **Various estimates suggest that 70% to 90% of the time spent on a data mining project is allocated to data preparation;** this is because you are using data that was collected for other reasons (for normal business operations, not for data mining). Preparations include:\n\n- Selecting data;\n- Cleaning data;\n- Constructing data;\n- Integrating data; and\n- Formatting data.\n\nThese tasks will likely be performed multiple times and not in any prescribed order. They can be very time-consuming but are critical for the success of the data mining project. In particular, data construction is a critical aspect of data preparation. Models work much better when the variables have been adjusted (e.g., by creating ratios, determining change scores, and calculating total scores) to make patterns appear more clearly. \n\n## Modeling\n\n![image-20230223173722789](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20230223173722789.png)\n\nOnce you have prepared the data, you are ready for modeling, which involves sophisticated analytical methods that can extract information from the data. This phase involves:\n\n- Selecting the modeling technique;\n- Generating a test design;\n- Building the model; and\n- Assessing the model.\n- Validation\n  - Split the data\n    - Training: Build the model\n    - Testing: Test the model with testing dataset and compare the results with observed data\n\nDeveloping a model is an iterative process and you can expect to try several models and modeling techniques before finding the best one. **One feature that separates data mining from other approaches is the use of multiple models to make predictions, building on the strengths of each technique.**\n\nAn important part of model development is ***validating*** the model‚Äôs predictive capability. Briefly, the process involves dividing your dataset into two parts: **a *training dataset* and a *testing dataset***. You develop your model using the training data and then test it by making predictions using the testing data. If the predictions made using the two datasets are in agreement, you can begin applying the model to new data. In summary, you conclude that the model is valid by demonstrating that it applies to (fits) a dataset that is independent of the one used in the model‚Äôs derivation. Statisticians often recommend such validation for statistical models, generally, but it is especially important when employing data mining techniques. \n\n## Evaluation\n\nOnce you have chosen your models, you are ready to **evaluate how the data mining results can help you achieve your business objectives**. At this stage of the project, you have built one or more models that appear to be of high quality from a data analysis perspective. Before writing final reports and deploying the model, however, it is important to more thoroughly evaluate the model and review the steps taken in constructing the model so you can be certain it properly achieves your business objectives. A key aim is to determine if there are any important business issues that have not been sufficiently considered. At the end of this phase, a decision will be made on the use of the data mining results. The evaluation phase tasks are:\n\n- Evaluate results;\n- Review the process; and\n- Determine the next steps.\n\nEvaluation is frequently confused with *model **assessment***‚Äîthe last task of the modeling phase. **Assessing the model focuses on the ‚Äúdata analysis perspective‚Äù** **and includes metrics like model accuracy and stability.** The authors of CRISP-DM considered calling this phase *business evaluation* because it has to be conducted in the language of the business using the metrics of the business as indicators of success. The value of a predictive model arises in two ways (Khabaza, 2010):\n\n1. The model‚Äôs predictions lead to improved (more effective) action; and\n2. The model delivers insight (new knowledge), which leads to improved strategy.\n\nKeep in mind that the value of a predictive model is not determined by any technical measure. Data miners should *not* focus on predictive accuracy, model stability, or any other technical metric for predictive models at the expense of business insight and business fit.\n\n## Deployment\n\nDepending on the business requirements, deployment can be as simple as generating a report or as complex as implementing a repeatable data mining process. **Keep in mind that creating the model is generally not the end of the project.** Even if the purpose of the model is only to increase one‚Äôs knowledge of the data, the knowledge gained will need to be organized and presented in a way that the organization can use for decision-making. So in essentially all projects, a final report will need to be produced and distributed.\n\n**Most critical is the deployment of the model to make predictions or create scores against new data.** This might be relatively simple if done within the data mining software you used, or more complex if the model is to be applied directly against an existing database. Whatever the case, a plan should be developed to monitor the model‚Äôs predictions and success in order to verify that the model is still valid.\n\nIn many projects, It is not unusual for the deployment team to be different from the modeling team; in some situations deployment may be the responsibility of team members having more of an IT focus. The tasks in the deployment phase are:\n\n- Plan the deployment;\n- Plan monitoring and maintenance activities;\n- Produce a final report; and\n- Review the project.\n\nSee also[ https://keithmccormick.com/crispdm](https://keithmccormick.com/crispdm) for additional information about CRISP-DM.\n\n# **Reference**\n\n**Course text:** UCI. (2020). [Introduction to Predictive Analytics.](https://docs.google.com/document/d/1UDqqpr5whycIhD2gle4tcLBDGkkr8ajlixDLqhl28tE/edit?usp=sharing)\n\n","tags":["DSBA","Data Mining"],"categories":["Predicted Analytics: Tools & Techniques"]},{"title":"TO-DO List","url":"/docs/Other-TO-DO-list/","content":"\n# **To Be Continued**\n\n- [ ] Hung-yi Lee's Machine Learning\n\n- [ ] Intermediate to Python\n\n- [ ] Predictive Analytics\n\n- [ ] Introduce to Data Analytics for Business\n\n- [ ] Descriptive Analytics: Visualization  \n\n# **About Website**\n\n- [ ] ÁõÆÂΩï‰∫åÁ∫ßÊ†áÈ¢òÁº©Ëøõ\n\n- [x] Motify `Archives` and `Tags`\n\n- [x] ÂÖ¨ÂºèË∂ÖÂá∫Âç°ÁâáËåÉÂõ¥ [Reference]( https://docs.mathjax.org/en/latest/options/output/index.html#options-common-to-all-output-processors)\n\n- [x] ÂÆûÁé∞ÁõÆÂΩïÂàÜÁ∫ßÊòæÁ§∫ \n\n- [x] Ë∞ÉÊï¥ÂõæÁâáÂ§ßÂ∞è\n\n- [x] ÂõæÁâáÁÇπÂáªÈ¢ÑËßà Fansy Box\n\n- [x] ÊêúÁ¥¢‰ºòÂåñ\n\n- [x] <mark>‰øÆÊîπÈ´ò‰∫ÆÈ¢úËâ≤</mark>\n\n- [x] ‰øÆÊîπ‰ª£Á†ÅÂùóÈ´ò‰∫Æ\n\n- [x] ÂÆûÁé∞tableÂ±Ö‰∏≠ÊòæÁ§∫\n\n- [x] ÊñáÁ´†ÁΩÆÈ°∂\n\n- [x] ÂÆûÁé∞homeÈ°µÈù¢ÂÆΩÂ±èÂ§ßÂõæÁâá\n\n- [x] Ë°®Ê†ºÂÆΩÂ∫¶Ê†πÊçÆÂÜÖÂÆπÂÆΩÂ∫¶ËøõË°åË∞ÉÊï¥\n\n- [x] ÂÆûÁé∞Search\n\n- [x] Emoji :thinking:\n\n- [x] Â≠ó‰ΩìËá™ÈÄÇÂ∫îÁ™óÂè£Â§ßÂ∞è\n\n- [x] ËÆæËÆ°ÊªëÂä®Ê†è\n\n\n\n\n\n\n\n","categories":["Other"]},{"title":"1 Introduction of Deep Learning","url":"/docs/Machine-Learning-1-Introduction-of-Deep-Learning/","content":"\n# **Machine Learning ‚âà Looking for function**\n\n![image-20221206053236150](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206053236150.png)\n\n# **Different Types of functions**\n\n- **Regression**: The function outputs a scalar\n- **Classification**: Given options (classes), the function outputs the correct one.\n- **Structured Learning:** create something with structure (image, document)\n\n![image-20221206053348699](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206053348699.png)\n\n# **How to find a function**\n\nA case study\n\n## The function we want to find ‚Ä¶\n\n![image-20221206053424557](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206053424557.png)\n\n![image-20221208221245405](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208221245405.png)\n\n![image-20221208223257254](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208223257254.png)\n\n![image-20221208223309541](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208223309541.png)\n\n![image-20221208223318275](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208223318275.png)\n\n![image-20221208223349650](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208223349650.png)\n\n![image-20221208223401234](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208223401234.png)\n\n![image-20221208223418427](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208223418427.png)\n\n# **ML Framework**\n\n![image-20221206053857892](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206053857892.png)\n\n## Step1. Model\n\ndepend on domain knowledge\n\n### Linear Models\n\nhave model bias (limitation), \n\n$$\ny = b + \\sum_{j=1}^{n}w_jx_j\n$$\n\n\n![image-20221206054003950](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206054003950.png)\n\n![image-20221206054205148](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206054205148.png)\n\n![image-20221206054210957](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206054210957.png)\n\n### Sigmoid Function\n\n![image-20221206054229272](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206054229272.png)\n\n![image-20221206054237612](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206054237612.png)\n\n$$\ny=b+\\sum_{i}c_isigmoid(b_i+w_ix_i)\n$$\n\n### New Model: More Features\n\n![image-20221206054403705](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206054403705.png)\n\nhyperparameter: \n\n* $i$ : no. of features\n* $j$ : no. of sigmoid\n\n![image-20221206054613829](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206054613829.png)\n\n![image-20221206054619581](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206054619581.png)\n\n### ReLu\n\n![image-20221206054710081](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206054710081.png)\n\n### Deeper Model\n\n![image-20221206054747992](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206054747992.png)\n\n## Step2. Loss\n\n![image-20221206054758334](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206054758334.png)\n\n## Step 3. optimization\n\n![image-20221206054825545](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206054825545.png)\n\n![image-20221206054848495](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206054848495.png)\n\n![image-20221206054855172](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206054855172.png)\n\n# **Deep Learning**\n\n![image-20221206054927207](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221206054927207.png)\n\n![image-20221208223439982](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208223439982.png)\n\n\n\n","tags":["ML"],"categories":["HUNG-YI LEE | MACHINE LEARNING"]},{"title":"Class Intro","url":"/docs/Machine-Learning-0-Course-Intro/","content":"\n# **How to find a function**\n\n## Lecture 1-5: Supervised Learning\n\n![image-20221208230201056](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208230201056.png)\n\n**Limit**: it is not easy to label for every assignments\n\n## Lecture 7: Self-Supervised Learning\n\n![image-20221208230316476](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208230316476.png)\n\n![image-20221208230321680](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208230321680.png)\n\n## Lecture 6: Generative Adversarial Network\n\n![image-20221208230347313](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208230347313.png)\n\n## Lecture 12: Reinforcement Learning\n\n![image-20221208230407336](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208230407336.png)\n\n## Lecture 8: Anomaly Detection\n\n![image-20221208230425964](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208230425964.png)\n\n## Lecture 9: Explainable AI\n\n![image-20221208230443881](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208230443881.png)\n\n## Lecture 10: Model Attack\n\n![image-20221208230457959](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208230457959.png)\n\n## Lecture 11: Domain Adaption\n\n![image-20221208230520016](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208230520016.png)\n\n## Lecture 13: Network Compression\n\n![image-20221208230533994](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208230533994.png)\n\n## Lecture 14: Life-Long Learning\n\n![image-20221208230551887](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208230551887.png)\n\n## Lecture 15: Met Learning\n\n![image-20221208230612831](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221208230612831.png)\n\n","tags":["ML"],"categories":["HUNG-YI LEE | MACHINE LEARNING"]},{"title":"Image Classification | Paper","url":"/docs/Computer-Vision-Image-Classification-Paper/","content":"\n- LeNet http://yann.lecun.com/exdb/lenet/index.html\n\n- AlexNet http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n\n- ZFNet Visualizing and Understanding Convolutional Networks https://arxiv.org/abs/1311.2901\n\n- VGG https://arxiv.org/abs/1409.1556\n\n- GoogLeNet, Inceptionv1(Going deeper with convolutions) https://arxiv.org/abs/1409.4842\n\n- Batch Normalization https://arxiv.org/abs/1502.03167\n\n- Inceptionv3(Rethinking the Inception Architecture for Computer Vision) https://arxiv.org/abs/1512.00567\n\n- Inceptionv4, Inception-ResNet https://arxiv.org/abs/1602.07261\n\n- Xception(Deep Learning with Depthwise Separable Convolutions) https://arxiv.org/abs/1610.02357\n\n- ResNet https://arxiv.org/abs/1512.03385\n\n- ResNeXt https://arxiv.org/abs/1611.05431\n\n- DenseNet https://arxiv.org/abs/1608.06993\n\n- NASNet-A(Learning Transferable Architectures for Scalable Image Recognition) https://arxiv.org/abs/1707.07012\n\n- SENet(Squeeze-and-Excitation Networks) https://arxiv.org/abs/1709.01507\n\n- MobileNet(v1) https://arxiv.org/abs/1704.04861\n\n- MobileNet(v2) https://arxiv.org/abs/1801.04381\n\n- MobileNet(v3) https://arxiv.org/abs/1905.02244\n\n- ShuffleNet(v1) https://arxiv.org/abs/1707.01083\n\n- ShuffleNet(v2) https://arxiv.org/abs/1807.11164\n\n- Bag of Tricks for Image Classification with Convolutional Neural Networks https://arxiv.org/abs/1812.01187\n\n- EfficientNet(v1) https://arxiv.org/abs/1905.11946\n\n- EfficientNet(v2) https://arxiv.org/abs/2104.00298\n\n- CSPNet https://arxiv.org/abs/1911.11929\n\n- RegNet https://arxiv.org/abs/2003.13678\n\n- NFNets(High-Performance Large-Scale Image Recognition Without Normalization) https://arxiv.org/abs/2102.06171\n\n- Vision Transformer https://arxiv.org/abs/2010.11929\n\n- DeiT(Training data-efficient image transformers ) https://arxiv.org/abs/2012.12877\n\n- Swin Transformer https://arxiv.org/abs/2103.14030\n\n- Swin Transformer V2: Scaling Up Capacity and Resolution https://arxiv.org/abs/2111.09883\n\n- BEiT: BERT Pre-Training of Image Transformers https://arxiv.org/abs/2106.08254\n\n- MAE(Masked Autoencoders Are Scalable Vision Learners) https://arxiv.org/abs/2111.06377\n\n- ConvNeXt(A ConvNet for the 2020s) https://arxiv.org/abs/2201.03545","tags":["CV"],"categories":["Computer Vision"]},{"title":"Cross Entropy","url":"/docs/Other-ML-Cross-Entropy/","content":"\n‰∫§ÂèâÁÜµ (Cross Entropy) ÊòØÊ∑±Â∫¶Â≠¶‰π†‰∏≠Â∏∏Áî®ÁöÑ‰∏Ä‰∏™Ê¶ÇÂøµÔºå‰∏ÄËà¨Áî®Êù•Ê±ÇÁõÆÊ†á‰∏éÈ¢ÑÊµãÂÄº‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇ\n\n<!--MORE-->\n\n‰∫§ÂèâÁÜµÊòØ‰ø°ÊÅØËÆ∫‰∏≠ÁöÑ‰∏Ä‰∏™Ê¶ÇÂøµÔºåË¶ÅÊÉ≥‰∫ÜËß£‰∫§ÂèâÁÜµÁöÑÊú¨Ë¥®ÔºåÈúÄË¶ÅÂÖà‰ªéÊúÄÂü∫Êú¨ÁöÑÊ¶ÇÂøµËÆ≤Ëµ∑„ÄÇ\n\n# **1 ‰ø°ÊÅØÈáè**\nÈ¶ñÂÖàÊòØ‰ø°ÊÅØÈáè„ÄÇÂÅáËÆæÊàë‰ª¨Âê¨Âà∞‰∫Ü‰∏§‰ª∂‰∫ãÔºåÂàÜÂà´Â¶Ç‰∏ãÔºö\n\n> ‰∫ã‰ª∂AÔºöÂ∑¥Ë•øÈòüËøõÂÖ•‰∫Ü2018‰∏ñÁïåÊùØÂÜ≥ËµõÂúà„ÄÇ\n> ‰∫ã‰ª∂BÔºö‰∏≠ÂõΩÈòüËøõÂÖ•‰∫Ü2018‰∏ñÁïåÊùØÂÜ≥ËµõÂúà„ÄÇ\n\n‰ªÖÂá≠Áõ¥ËßâÊù•ËØ¥ÔºåÊòæËÄåÊòìËßÅ‰∫ã‰ª∂BÁöÑ‰ø°ÊÅØÈáèÊØî‰∫ã‰ª∂AÁöÑ‰ø°ÊÅØÈáèË¶ÅÂ§ß„ÄÇÁ©∂ÂÖ∂ÂéüÂõ†ÔºåÊòØÂõ†‰∏∫‰∫ã‰ª∂AÂèëÁîüÁöÑÊ¶ÇÁéáÂæàÂ§ßÔºå‰∫ã‰ª∂BÂèëÁîüÁöÑÊ¶ÇÁéáÂæàÂ∞è„ÄÇÊâÄ‰ª•ÂΩìË∂ä‰∏çÂèØËÉΩÁöÑ‰∫ã‰ª∂ÂèëÁîü‰∫ÜÔºåÊàë‰ª¨Ëé∑ÂèñÂà∞ÁöÑ‰ø°ÊÅØÈáèÂ∞±Ë∂äÂ§ß„ÄÇË∂äÂèØËÉΩÂèëÁîüÁöÑ‰∫ã‰ª∂ÂèëÁîü‰∫ÜÔºåÊàë‰ª¨Ëé∑ÂèñÂà∞ÁöÑ‰ø°ÊÅØÈáèÂ∞±Ë∂äÂ∞è„ÄÇÈÇ£‰πà‰ø°ÊÅØÈáèÂ∫îËØ•Âíå‰∫ã‰ª∂ÂèëÁîüÁöÑÊ¶ÇÁéáÊúâÂÖ≥„ÄÇ\n\nÂÅáËÆæ$X$ÊòØ‰∏Ä‰∏™Á¶ªÊï£ÂûãÈöèÊú∫ÂèòÈáèÔºåÂÖ∂ÂèñÂÄºÈõÜÂêà‰∏∫$x$,Ê¶ÇÁéáÂàÜÂ∏ÉÂáΩÊï∞ $p(x)=Pr(X=x)$, $x‚ààœá$ÂàôÂÆö‰πâ‰∫ã‰ª∂$X=x_0$ÁöÑ‰ø°ÊÅØÈáè‰∏∫Ôºö\n\n$$\nI(x_0)=‚àílog(p(x_0))\n$$\n\nÁî±‰∫éÊòØÊ¶ÇÁéáÊâÄ‰ª•$p(x_0)$ÁöÑÂèñÂÄºËåÉÂõ¥ÊòØ $[0,1]$,ÁªòÂà∂‰∏∫ÂõæÂΩ¢Â¶Ç‰∏ãÔºåÂèØËßÅËØ•ÂáΩÊï∞Á¨¶ÂêàÊàë‰ª¨ÂØπ‰ø°ÊÅØÈáèÁöÑÁõ¥Ëßâ„ÄÇ\n\n![image-20221111062251336](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20221111062251336.png)\n\n# **2 ÁÜµ**\n\nËÄÉËôëÂè¶‰∏Ä‰∏™ÈóÆÈ¢òÔºåÂØπ‰∫éÊüê‰∏™‰∫ã‰ª∂ÔºåÊúâ$n$ÁßçÂèØËÉΩÊÄßÔºåÊØè‰∏ÄÁßçÂèØËÉΩÊÄßÈÉΩÊúâ‰∏Ä‰∏™Ê¶ÇÁéá$p(xi)$\nËøôÊ†∑Â∞±ÂèØ‰ª•ËÆ°ÁÆóÂá∫Êüê‰∏ÄÁßçÂèØËÉΩÊÄßÁöÑ‰ø°ÊÅØÈáè„ÄÇ‰∏æ‰∏Ä‰∏™‰æãÂ≠êÔºåÂÅáËÆæ‰Ω†ÊãøÂá∫‰∫Ü‰Ω†ÁöÑÁîµËÑëÔºåÊåâ‰∏ãÂºÄÂÖ≥Ôºå‰ºöÊúâ‰∏âÁßçÂèØËÉΩÊÄßÔºå‰∏ãË°®ÂàóÂá∫‰∫ÜÊØè‰∏ÄÁßçÂèØËÉΩÁöÑÊ¶ÇÁéáÂèäÂÖ∂ÂØπÂ∫îÁöÑ‰ø°ÊÅØÈáè\n\n| Â∫èÂè∑ | ‰∫ã‰ª∂         | Ê¶ÇÁéá $p$ | ‰ø°ÊÅØÈáè $I$         |\n| ---- | ------------ | ----- | ------------------- |\n| A    | ÁîµËÑëÊ≠£Â∏∏ÂºÄÊú∫ | 0.7   | $-log(p(A))=0.36$   |\n| B    | ÁîµËÑëÊó†Ê≥ïÂºÄÊú∫ | 0.2   | $-log(p(B))=1.61$ |\n| C    | ÁîµËÑëÁàÜÁÇ∏‰∫Ü   | 0.1   | $-log(p(C))=2.30$ |\n\n> Ê≥®ÔºöÊñá‰∏≠ÁöÑÂØπÊï∞Âùá‰∏∫Ëá™ÁÑ∂ÂØπÊï∞\n\nÊàë‰ª¨Áé∞Âú®Êúâ‰∫Ü‰ø°ÊÅØÈáèÁöÑÂÆö‰πâÔºåËÄåÁÜµÁî®Êù•Ë°®Á§∫ÊâÄÊúâ‰ø°ÊÅØÈáèÁöÑÊúüÊúõÔºåÂç≥Ôºö\n\n$$\nH(X)=‚àí\\sum_{i=1}^np(x_i)log(p(x_i))\n$$\n\nÂÖ∂‰∏≠$n$‰ª£Ë°®ÊâÄÊúâÁöÑ$n$ÁßçÂèØËÉΩÊÄßÔºåÊâÄ‰ª•‰∏äÈù¢ÁöÑÈóÆÈ¢òÁªìÊûúÂ∞±ÊòØ\n\n$$\n\\begin{aligned}\nH(X) &= ‚àí[p(A)log(p(A))+p(B)log(p(B))+p(C))log(p(C))]\n\\\\&= 0.7√ó0.36+0.2√ó1.61+0.1√ó2.30\n\\\\&= 0.804\n\\end{aligned}\n$$\n\nÁÑ∂ËÄåÊúâ‰∏ÄÁ±ªÊØîËæÉÁâπÊÆäÁöÑÈóÆÈ¢òÔºåÊØîÂ¶ÇÊäïÊé∑Á°¨Â∏ÅÂè™Êúâ‰∏§ÁßçÂèØËÉΩÔºåÂ≠óÊúù‰∏äÊàñËä±Êúù‰∏ä„ÄÇ‰π∞ÂΩ©Á•®Âè™Êúâ‰∏§ÁßçÂèØËÉΩÔºå‰∏≠Â•ñÊàñ‰∏ç‰∏≠Â•ñ„ÄÇÊàë‰ª¨Áß∞‰πã‰∏∫0-1ÂàÜÂ∏ÉÈóÆÈ¢òÔºà‰∫åÈ°πÂàÜÂ∏ÉÁöÑÁâπ‰æãÔºâÔºåÂØπ‰∫éËøôÁ±ªÈóÆÈ¢òÔºåÁÜµÁöÑËÆ°ÁÆóÊñπÊ≥ïÂèØ‰ª•ÁÆÄÂåñ‰∏∫Â¶Ç‰∏ãÁÆóÂºèÔºö\n\n$$\n\\begin{aligned}\nH(X)&=‚àí\\sum_{i=1}^np(xi)log(p(xi))\\\\\n&=‚àíp(x)log(p(x))‚àí(1‚àíp(x))log(1‚àíp(x))\n\\end{aligned}\n$$\n\n# **3 Áõ∏ÂØπÁÜµÔºàKLÊï£Â∫¶Ôºâ**\nÁõ∏ÂØπÁÜµÂèàÁß∞KLÊï£Â∫¶,Â¶ÇÊûúÊàë‰ª¨ÂØπ‰∫éÂêå‰∏Ä‰∏™ÈöèÊú∫ÂèòÈáè $ x $ Êúâ‰∏§‰∏™ÂçïÁã¨ÁöÑÊ¶ÇÁéáÂàÜÂ∏É $ P(x) $ Âíå $ Q(x)$ ÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî® KL Êï£Â∫¶ÔºàKullback-Leibler divergenceÔºâÊù•Ë°°ÈáèËøô‰∏§‰∏™ÂàÜÂ∏ÉÁöÑÂ∑ÆÂºÇ\n\n> Áª¥Âü∫ÁôæÁßëÂØπÁõ∏ÂØπÁÜµÁöÑÂÆö‰πâ\n> In the context of machine learning, $D_{KL}(p‚Äñq) $ is often called the information gain achieved if $P$ is used instead of $Q$.\n\nÂç≥Â¶ÇÊûúÁî® $P$ Êù•ÊèèËø∞ÁõÆÊ†áÈóÆÈ¢òÔºåËÄå‰∏çÊòØÁî®  $ Q$  Êù•ÊèèËø∞ÁõÆÊ†áÈóÆÈ¢òÔºåÂæóÂà∞ÁöÑ‰ø°ÊÅØÂ¢ûÈáè„ÄÇ\n\nÂú®Êú∫Âô®Â≠¶‰π†‰∏≠Ôºå$P$ ÂæÄÂæÄÁî®Êù•Ë°®Á§∫Ê†∑Êú¨ÁöÑÁúüÂÆûÂàÜÂ∏ÉÔºåÊØîÂ¶Ç $[1,0,0]$ Ë°®Á§∫ÂΩìÂâçÊ†∑Êú¨Â±û‰∫éÁ¨¨‰∏ÄÁ±ª„ÄÇ$Q$ Áî®Êù•Ë°®Á§∫Ê®°ÂûãÊâÄÈ¢ÑÊµãÁöÑÂàÜÂ∏ÉÔºåÊØîÂ¶Ç $[0.7,0.2,0.1]$\n\nÁõ¥ËßÇÁöÑÁêÜËß£Â∞±ÊòØÂ¶ÇÊûúÁî® $P$ Êù•ÊèèËø∞Ê†∑Êú¨ÔºåÈÇ£‰πàÂ∞±ÈùûÂ∏∏ÂÆåÁæé„ÄÇËÄåÁî® $Q$ Êù•ÊèèËø∞Ê†∑Êú¨ÔºåËôΩÁÑ∂ÂèØ‰ª•Â§ßËá¥ÊèèËø∞Ôºå‰ΩÜÊòØ‰∏çÊòØÈÇ£‰πàÁöÑÂÆåÁæéÔºå‰ø°ÊÅØÈáè‰∏çË∂≥ÔºåÈúÄË¶ÅÈ¢ùÂ§ñÁöÑ‰∏Ä‰∫õ‚Äú‰ø°ÊÅØÂ¢ûÈáè‚ÄùÊâçËÉΩËææÂà∞Âíå $P$ ‰∏ÄÊ†∑ÂÆåÁæéÁöÑÊèèËø∞„ÄÇÂ¶ÇÊûúÊàë‰ª¨ÁöÑ $Q$ ÈÄöËøáÂèçÂ§çËÆ≠ÁªÉÔºå‰πüËÉΩÂÆåÁæéÁöÑÊèèËø∞Ê†∑Êú¨ÔºåÈÇ£‰πàÂ∞±‰∏çÂÜçÈúÄË¶ÅÈ¢ùÂ§ñÁöÑ‚Äú‰ø°ÊÅØÂ¢ûÈáè‚ÄùÔºå $Q$ Á≠â‰ª∑‰∫é$P$„ÄÇ\n\nKLÊï£Â∫¶ÁöÑËÆ°ÁÆóÂÖ¨ÂºèÔºö\n\n$$\nD_{KL}(p||q)=\\sum_{i=1}^np(x_i)log(\\frac{p(x_i)}{q(x_i)})\n$$\n\n$n$ ‰∏∫‰∫ã‰ª∂ÁöÑÊâÄÊúâÂèØËÉΩÊÄß„ÄÇ\n\n$D_{KL}$ÁöÑÂÄºË∂äÂ∞èÔºåË°®Á§∫ $P$ ÂàÜÂ∏ÉÂíå $Q$ ÂàÜÂ∏ÉË∂äÊé•Ëøë\n\n# **4 ‰∫§ÂèâÁÜµ**\nÂØπÂºè*KLÊï£Â∫¶ÁöÑËÆ°ÁÆóÂÖ¨Âºè*ÂèòÂΩ¢ÂèØ‰ª•ÂæóÂà∞Ôºö\n\n$$\n\\begin{aligned}\nD_{KL}(p||q)&=\\sum_{i=1}^np(xi)log(p(xi))‚àí\\sum_{i=1}^np(xi)log(q(xi))\\\\\n&=‚àíH(p(x))+[‚àí\\sum_{i=1}^np(xi)log(q(xi))]\n\\end{aligned}\n$$\n\nÁ≠âÂºèÁöÑÂâç‰∏ÄÈÉ®ÂàÜÊÅ∞Â∑ßÂ∞±ÊòØ $p$ ÁöÑÁÜµÔºåÁ≠âÂºèÁöÑÂêé‰∏ÄÈÉ®ÂàÜÔºåÂ∞±ÊòØ‰∫§ÂèâÁÜµÔºö\n\n$$\nH(p,q)=‚àí\\sum_{i=1}^np(xi)log(q(xi))\n$$\n\nÂú®Êú∫Âô®Â≠¶‰π†‰∏≠ÔºåÊàë‰ª¨ÈúÄË¶ÅËØÑ‰º∞ `label` Âíå `predicts` ‰πãÈó¥ÁöÑÂ∑ÆË∑ùÔºå‰ΩøÁî®KLÊï£Â∫¶ÂàöÂàöÂ•ΩÔºåÂç≥ $D_{KL}(y||\\hat{y})$ÔºåÁî±‰∫éKLÊï£Â∫¶‰∏≠ÁöÑÂâç‰∏ÄÈÉ®ÂàÜ $‚àíH(y)$ ‰∏çÂèòÔºåÊïÖÂú®‰ºòÂåñËøáÁ®ã‰∏≠ÔºåÂè™ÈúÄË¶ÅÂÖ≥Ê≥®‰∫§ÂèâÁÜµÂ∞±ÂèØ‰ª•‰∫Ü„ÄÇÊâÄ‰ª•‰∏ÄËà¨Âú®Êú∫Âô®Â≠¶‰π†‰∏≠Áõ¥Êé•Áî®Áî®‰∫§ÂèâÁÜµÂÅö`loss`ÔºåËØÑ‰º∞Ê®°Âûã„ÄÇ\n\n# **5 Êú∫Âô®Â≠¶‰π†‰∏≠‰∫§ÂèâÁÜµÁöÑÂ∫îÁî®**\n\n## 5.1 ‰∏∫‰ªÄ‰πàË¶ÅÁî®‰∫§ÂèâÁÜµÂÅölossÂáΩÊï∞Ôºü\n\nÂú®Á∫øÊÄßÂõûÂΩíÈóÆÈ¢ò‰∏≠ÔºåÂ∏∏Â∏∏‰ΩøÁî®MSEÔºàMean Squared ErrorÔºâ‰Ωú‰∏∫lossÂáΩÊï∞ÔºåÊØîÂ¶ÇÔºö\n\n$$\nloss=\\frac{1}{2m}\\sum_{i=1}^m(y_i‚àí\\hat{y_i})^2\n$$\n\nËøôÈáåÁöÑ $ m $  Ë°®Á§∫  $ m $ ‰∏™Ê†∑Êú¨ÁöÑÔºå $ loss $ ‰∏∫ $ m $ ‰∏™Ê†∑Êú¨ÁöÑ $ loss $ ÂùáÂÄº„ÄÇ\n\nMSEÂú®Á∫øÊÄßÂõûÂΩíÈóÆÈ¢ò‰∏≠ÊØîËæÉÂ•ΩÁî®ÔºåÈÇ£‰πàÂú®ÈÄªËæëÂàÜÁ±ªÈóÆÈ¢ò‰∏≠ËøòÊòØÂ¶ÇÊ≠§‰πàÔºü\n\n## 5.2 ‰∫§ÂèâÁÜµÂú®ÂçïÂàÜÁ±ªÈóÆÈ¢ò‰∏≠ÁöÑ‰ΩøÁî®\nËøôÈáåÁöÑÂçïÁ±ªÂà´ÊòØÊåáÔºåÊØè‰∏ÄÂº†ÂõæÂÉèÊ†∑Êú¨Âè™ËÉΩÊúâ‰∏Ä‰∏™Á±ªÂà´ÔºåÊØîÂ¶ÇÂè™ËÉΩÊòØÁãóÊàñÂè™ËÉΩÊòØÁå´„ÄÇ\n\n‰∫§ÂèâÁÜµÂú®ÂçïÂàÜÁ±ªÈóÆÈ¢ò‰∏äÂü∫Êú¨ÊòØÊ†áÈÖçÁöÑÊñπÊ≥ï\n\n$$\nloss=‚àí\\sum_{i=1}^ny_ilog(\\hat{y_i})\n$$\n\n‰∏äÂºè‰∏∫‰∏ÄÂº†Ê†∑Êú¨ÁöÑ  $ loss  $ ËÆ°ÁÆóÊñπÊ≥ï„ÄÇÂºè‰∏≠ $ n  $ ‰ª£Ë°®ÁùÄ $ n $ ÁßçÁ±ªÂà´„ÄÇ\n\n‰∏æ‰æãËØ¥ÊòéÔºåÊØîÂ¶ÇÊúâÂ¶Ç‰∏ãÊ†∑Êú¨Ôºö\n\n![SouthEast-16489642743263](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/SouthEast-16489642743263.png)\n\nÂØπÂ∫îÁöÑÊ†áÁ≠æÂíåÈ¢ÑÊµãÂÄº\n\n|       | Áå´   | ÈùíËõô | ËÄÅÈº† |\n| ----- | ---- | ---- | ---- |\n| Label | 0    | 1    | 0    |\n| Pred  | 0.3  | 0.6  | 0.1  |\n\nÈÇ£‰πà\n\n$$\n\\begin{aligned}\nloss&=‚àí(0√ólog(0.3)+1√ólog(0.6)+0√ólog(0.1)\\\\&=‚àílog(0.6)\n\\end{aligned}\n$$\n\nÂØπÂ∫î‰∏Ä‰∏™batchÁöÑ $ loss $ Â∞±ÊòØ\n\n$$\nloss=‚àí\\frac1m\\sum_{j=1}^m\\sum_{i=1}^ny_{ji}log(\\hat{y_{ji}})\n$$\n\n $ m $ ‰∏∫ÂΩìÂâç $ batch $ ÁöÑÊ†∑Êú¨Êï∞\n\n## 5.3 ‰∫§ÂèâÁÜµÂú®Â§öÂàÜÁ±ªÈóÆÈ¢ò‰∏≠ÁöÑ‰ΩøÁî®\n\nËøôÈáåÁöÑÂ§öÁ±ªÂà´ÊòØÊåáÔºåÊØè‰∏ÄÂº†ÂõæÂÉèÊ†∑Êú¨ÂèØ‰ª•ÊúâÂ§ö‰∏™Á±ªÂà´ÔºåÊØîÂ¶ÇÂêåÊó∂ÂåÖÂê´‰∏ÄÂè™Áå´Âíå‰∏ÄÂè™Áãó\n\nÂíåÂçïÂàÜÁ±ªÈóÆÈ¢òÁöÑÊ†áÁ≠æ‰∏çÂêåÔºåÂ§öÂàÜÁ±ªÁöÑÊ†áÁ≠æÊòØ**n-hot**„ÄÇ\n\nÊØîÂ¶Ç‰∏ãÈù¢ËøôÂº†Ê†∑Êú¨ÂõæÔºåÂç≥ÊúâÈùíËõôÔºåÂèàÊúâËÄÅÈº†ÔºåÊâÄ‰ª•ÊòØ‰∏Ä‰∏™Â§öÂàÜÁ±ªÈóÆÈ¢ò„ÄÇ\n\n![SouthEast-16489643649396](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/SouthEast-16489643649396.png)\n\nÂØπÂ∫îÁöÑÊ†áÁ≠æÂíåÈ¢ÑÊµãÂÄºÔºö\n\n|       | Áå´   | ÈùíËõô | ËÄÅÈº† |\n| ----- | ---- | ---- | ---- |\n| Label | 0    | 1    | 1    |\n| Pred  | 0.1  | 0.7  | 0.8  |\n\n\nÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåËøôÈáåÁöÑ `Pred` ‰∏çÂÜçÊòØÈÄöËøá `softmax` ËÆ°ÁÆóÁöÑ‰∫ÜÔºåËøôÈáåÈááÁî®ÁöÑÊòØ**sigmoid**„ÄÇÂ∞ÜÊØè‰∏Ä‰∏™ËäÇÁÇπÁöÑËæìÂá∫ÂΩí‰∏ÄÂåñÂà∞ $ [0,1] $ ‰πãÈó¥„ÄÇÊâÄÊúâ `Pred` ÂÄºÁöÑÂíå‰πü‰∏çÂÜç‰∏∫1„ÄÇÊç¢Âè•ËØùËØ¥ÔºåÂ∞±ÊòØÊØè‰∏Ä‰∏™ `Label` ÈÉΩÊòØÁã¨Á´ãÂàÜÂ∏ÉÁöÑÔºåÁõ∏‰∫í‰πãÈó¥Ê≤°ÊúâÂΩ±Âìç„ÄÇÊâÄ‰ª•‰∫§ÂèâÁÜµÂú®ËøôÈáåÊòØÂçïÁã¨ÂØπÊØè‰∏Ä‰∏™ËäÇÁÇπËøõË°åËÆ°ÁÆóÔºåÊØè‰∏Ä‰∏™ËäÇÁÇπÂè™Êúâ‰∏§ÁßçÂèØËÉΩÂÄºÔºåÊâÄ‰ª•ÊòØ‰∏Ä‰∏™‰∫åÈ°πÂàÜÂ∏É„ÄÇÂâçÈù¢ËØ¥ËøáÂØπ‰∫é‰∫åÈ°πÂàÜÂ∏ÉËøôÁßçÁâπÊÆäÁöÑÂàÜÂ∏ÉÔºåÁÜµÁöÑËÆ°ÁÆóÂèØ‰ª•ËøõË°åÁÆÄÂåñ„ÄÇ\n\nÂêåÊ†∑ÁöÑÔºå‰∫§ÂèâÁÜµÁöÑËÆ°ÁÆó‰πüÂèØ‰ª•ÁÆÄÂåñÔºåÂç≥\n\n$$\nloss=‚àíylog(\\hat{y})‚àí(1‚àíy)log(1‚àí\\hat{y})\n$$\n\nÊ≥®ÊÑèÔºå‰∏äÂºèÂè™ÊòØÈíàÂØπ‰∏Ä‰∏™ËäÇÁÇπÁöÑËÆ°ÁÆóÂÖ¨Âºè„ÄÇËøô‰∏ÄÁÇπ‰∏ÄÂÆöË¶ÅÂíåÂçïÂàÜÁ±ª $ loss $ Âå∫ÂàÜÂºÄÊù•„ÄÇ\n\n‰æãÂ≠ê‰∏≠ÂèØ‰ª•ËÆ°ÁÆó‰∏∫Ôºö\n\n$$\n\\begin{aligned}\nloss_{cat}&=‚àí0√ólog(0.1)‚àí(1‚àí0)log(1‚àí0.1)=‚àílog(0.9)\\\\\nloss_{frog}&=‚àí1√ólog(0.7)‚àí(1‚àí1)log(1‚àí0.7)=‚àílog(0.7)\\\\\nloss_{mouse}&=‚àí1√ólog(0.8)‚àí(1‚àí1)log(1‚àí0.8)=‚àílog(0.8)\n\\end{aligned}\n$$\n\nÂçïÂº†Ê†∑Êú¨ÁöÑ $ loss $ Âç≥‰∏∫$loss=loss_{cat}+loss_{frog}+loss_{mouse}$\n\nÊØè‰∏Ä‰∏™batchÁöÑlossÂ∞±ÊòØÔºö\n\n$$\nloss=\\sum_{j=1}^m\\sum_{i=1}^n‚àíy_{ji}log(\\hat{y_{ji}})‚àí(1‚àíy_{ji})log(1‚àí\\hat{y_{ji}})\n$$\n\nÂºè‰∏≠ $ m $ ‰∏∫ÂΩìÂâçbatch‰∏≠ÁöÑÊ†∑Êú¨ÈáèÔºå $ n $ ‰∏∫Á±ªÂà´Êï∞„ÄÇ\n\n# **Reference**\n\nhttps://blog.csdn.net/tsyccnh/article/details/79163834\n","tags":["ML"],"categories":["Other"]},{"title":"Basic Knowledge of CNN","url":"/docs/Computer-Vision-The-Basic-Info-of-CNN/","content":"\nÁÆÄÂçï‰ªãÁªçÂç∑ÁßØÁ•ûÁªèÁΩëÁªú‰∏≠Â∏∏ËßÅÁöÑÂÖ®ËøûÊé•Â±ÇÔºåÂç∑ÁßØÂ±Ç„ÄÅÊ±†ÂåñÂ±Ç‰ª•ÂèäËØØÂ∑ÆÂèçÂêë‰º†Êí≠ËøáÁ®ãÂíåËÆ≠ÁªÉ‰ºòÂåñÂô®ÁöÑÂéüÁêÜ„ÄÇ\n\n<!--more-->\n\n# **1 Âç∑ÁßØÁ•ûÁªèÁΩëÁªú CNN**\n\n* Âç∑ÁßØÁ•ûÁªèÁΩëÁªúÔºåÂç≥ÂåÖÂê´Âç∑ÁßØÂ±ÇÁöÑÁ•ûÁªèÁΩëÁªú„ÄÇ\n* Á¨¨‰∏Ä‰∏™Âç∑ÁßØÁ•ûÁªèÁΩëË∑ØÔºöLeCunÁöÑLeNetÔºà1998ÔºâÁΩëÁªúÁªìÊûÑ\n\n![Net_LeNet](https://github.com/Jiayi-Zeng/Jiayi-Zeng.github.io/blob/pic/img/Net_LeNet_covoer.png?raw=true)\n\n## 1.1 CNNÁöÑÂèëÂ±ï\n\n![](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220327213127062.png)\n\n## 1.2 CNNÁöÑÂ∫îÁî®\n\nÂõæÂÉèÊ£ÄÊµã„ÄÅÂõæÂÉèÊ£ÄÁ¥¢„ÄÅÂõæÂÉèÊ£ÄÊµã„ÄÅÂõæÂÉèÂàÜÂâ≤„ÄÅÊó†‰∫∫È©æÈ©∂„ÄÅGPU„ÄÅÂõæÂÉèËøÅÁßª\n\n![image-20220327213228684](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220327213228684.png)\n\n![image-20220327213244394](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220327213244394.png)\n\n![image-20220327213324662](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220327213324662.png)\n\n# **2 Á•ûÁªèÂÖÉ**\n\n![image-20220403112023201](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220403112023201.png)\n\n$$\ny=f(x_1¬∑w_1+x_2¬∑w_2+x_3¬∑w_3-1)\n$$\n\nÂÖ∂‰∏≠Ôºå$x$‰∏∫ÊøÄÂä±Ôºå$w$‰∏∫Á•ûÁªèÂÖÉËøûÊé•ÊùÉÂÄºÔºå$-1$‰∏∫ÂÅèÁΩÆÔºå$f(x)$‰∏∫ÊøÄÊ¥ªÂáΩÊï∞„ÄÇ\n\n# **3 ÂÖ®ËøûÊé•Â±Ç**\n\n![image-20220403113627551](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220403113627551.png)\n\n# **4 BPÁ•ûÁªèÁΩëÁªú**\n\n## 4.1 BPÁ•ûÁªèÁΩëÁªúÁÆÄ‰ªã\n\n**BPÔºàBack PropagationÔºâÁÆóÊ≥ïÂåÖÊã¨‰ø°Âè∑ÁöÑÂâçÂêë‰º†Êí≠ÂíåËØØÂ∑ÆÁöÑÂèçÂêë‰º†Êí≠‰∏§‰∏™ËøáÁ®ã**ÔºåÂç≥ËÆ°ÁÆóËØØÂ∑ÆËæìÂá∫Êó∂Êåâ‰ªéËæìÂÖ•Âà∞ËæìÂá∫ÁöÑÊñπÂêëËøõË°åÔºåËÄåË∞ÉÊï¥ÊùÉÂÄºÂíåÈòàÂÄºÂàô‰ªéËæìÂá∫Âà∞ËæìÂÖ•ÁöÑÊñπÂêëËøõË°å„ÄÇ\n\n## 4.2 BPÁ•ûÁªèÁΩëÁªúÂÆû‰æã\n\n### 1.ËæìÂÖ•Â±Ç\n\n1. ÂΩ©Ëâ≤RGBÂõæÂÉè --> ÁÅ∞Â∫¶Âåñ--> ÁÅ∞Â∫¶ÂõæÂÉè --> ‰∫åÂÄºÂåñ--> ‰∫åÂÄºÂõæÂÉè\n\n![image-20220327214232774](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220327214232774.png)\n\n2. Á™óÂè£ÊªëÂä®ÔºöËÆ°ÁÆóÁôΩËâ≤ÂÉèÁ¥†Âç†Êï¥‰∏™Ê°ÜÂÉèÁ¥†ÁöÑÊØî‰æã\n\n![image-20220327214413416](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220327214413416.png)\n\n3. ÊåâË°åÂ±ïÂºÄÔºåÊãºÊé•Êàê**Ë°åÂêëÈáèÔºàÁ•ûÁªèÁΩëÁªúËæìÂÖ•Â±ÇÔºâ**\n\n![image-20220327214508874](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220327214508874.png)\n\n### 2. ËæìÂá∫Â±Ç\n\n**one-hotÁºñÁ†Å**\n\n![image-20220327214704028](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220327214704028.png)\n\n### 3. Á•ûÁªèÁΩëÁªú\n\n![image-20220327214728420](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220327214728420.png)\n\n# **5 Âç∑ÁßØÂ±Ç**\n\n**ÁõÆÁöÑÔºö**ËøõË°åÂõæÂÉèÁâπÂæÅÊèêÂèñ\n\n**ÁâπÊÄßÔºö**Êã•ÊúâÂ±ÄÈÉ®ÊÑüÁü•Êú∫Âà∂ÔºåÊùÉÂÄºÂÖ±‰∫´ÔºàÂáèÂ∞ëÂèÇÊï∞Ôºâ\n\n> **ÊùÉÂÄºÂÖ±‰∫´**\n>\n> ![image-20220327215001204](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220327215001204.png)\n\n## 5.1 Âç∑ÁßØËøáÁ®ã\n\n![SouthEast](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/SouthEast.gif)\n\n![image-20220327215117151](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220327215117151.png)\n\nÈÄöËøáËßÇÂØüÂèØ‰ª•ÂèëÁé∞Ôºö\n\n* **`Âç∑ÁßØÊ†∏channel`‰∏é`ËæìÂÖ•Â±ÇÁöÑchannel`Áõ∏Âêå**\n* **ËæìÂá∫ÁöÑ`ÁâπÂæÅÁü©Èòµchannel`‰∏é`Âç∑ÁßØÊ†∏‰∏™Êï∞`Áõ∏Âêå**\n\n## 5.2 ÊøÄÊ¥ªÂáΩÊï∞\n\nÁõÆÁöÑÔºö**ÂºïÂÖ•ÈùûÁ∫øÊÄßÂõ†Á¥†Ôºå‰ΩøÂÖ∂ÂÖ∑Â§áËß£ÂÜ≥ÈùûÁ∫øÊÄßÈóÆÈ¢òÁöÑËÉΩÂäõ„ÄÇ**\n\n1. **`Sigmoid`ÊøÄÊ¥ªÂáΩÊï∞**\n\n* È•±ÂíåÊó∂Ê¢ØÂ∫¶ÈùûÂ∏∏Â∞èÔºåÊïÖÁΩëÁªúÂ±ÇÊï∞ËæÉÊ∑±Êó∂ÊòìÂá∫Áé∞Ê¢ØÂ∫¶Ê∂àÂ§±„ÄÇ\n* ËÆ°ÁÆóÂ§öÁ±ªÊçüÂ§±ÊúÄÂêé‰ΩøÁî®`softmax`ÊøÄÊ¥ªÂáΩÊï∞ÔºåÁªèËøá`softmax`Â§ÑÁêÜÂêéÊâÄÊúâËæìÂá∫ËäÇÁÇπÊ¶ÇÁéáÂíå‰∏∫1„ÄÇ\n\n$$\no_1=\\frac{e^{y_1}}{e^{y_1}+e^{y_2}}\\\\\no_2=\\frac{e^{y_2}}{e^{y_1}+e^{y_2}}\n$$\n\n2. **ReLUÊøÄÊ¥ªÂáΩÊï∞**\n\n* Áº∫ÁÇπÂú®‰∫éÂΩìÂèçÂêë‰º†Êí≠ÁöÑËøáÁ®ã‰∏≠Êúâ‰∏Ä‰∏™ÈùûÂ∏∏Â§ßÁöÑÊ¢ØÂ∫¶ÁªèËøáÊó∂ÔºåÂèçÂêë‰º†Êí≠Êõ¥Êñ∞ÂêéÂèØËÉΩÂØºËá¥ÊùÉÈáçÂàÜÂ∏É‰∏≠ÂøÉÂ∞è‰∫é0ÔºåÂØºËá¥ËØ•Â§ÑÁöÑÂÄíÊï∞ÂßãÁªà‰∏∫0ÔºåÂèçÂêë‰º†Êí≠Êó†Ê≥ïÊõ¥Êñ∞ÊùÉÈáçÔºåÂç≥ËøõÂÖ•Â§±Ê¥ªÁä∂ÊÄÅ„ÄÇ\n* Â§±Ê¥ªÂêéÊó†Ê≥ï‚ÄúÂ§çÊ¥ª‚Äù„ÄÇÂª∫ËÆÆ‰∏ÄÂºÄÂßã‰∏ç‰ΩøÁî®ËæÉÂ§ßÂ≠¶‰π†ÁéáÔºåÂê¶ÂàôÂ§ßÂ§öÊï∞Á•ûÁªèÂÖÉÂÆπÊòìÂ§±Ê¥ª„ÄÇ\n\n![image-20220327215434274](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220327215434274.png)\n\n## 5.3 Ë∂äÁïåÊÉÖÂÜµ\n\nÂà©Áî®**padding**Ë°•Èõ∂ÔºåÁªèÂç∑ÁßØÂêéÁöÑÁü©ÈòµÂ∞∫ÂØ∏Â§ßÂ∞èËÆ°ÁÆóÂÖ¨Âºè‰∏∫Ôºö\n\n$$\nN=(W-F+2P)/S+1\n$$\n\nÂÖ∂‰∏≠ÔºåËæìÂÖ•ÂõæÁâáÂ§ßÂ∞è‰∏∫$W√óW$Ôºå`Filter`Â§ßÂ∞è‰∏∫$F√óF$ÔºåÊ≠•Èïø‰∏∫$S$Ôºå`padding`ÁöÑÂÉèÁ¥†Êï∞‰∏∫$P$.\n\n# **6 Ê±†ÂåñÂ±Ç**\n\nÁõÆÁöÑÔºöÂØπÁâπÂæÅÂõæËøõË°åÁ®ÄÁñèÂ§ÑÁêÜÔºåÂáèÂ∞ëÊï∞ÊçÆËøêÁÆóÈáè\n\n* Ê≤°ÊúâËÆ≠ÁªÉÂèÇÊï∞\n* Âè™ÊîπÂèòÁâπÂæÅÁü©Èòµ`W`Âíå`h`Ôºå‰∏çÊîπÂèò`channel`\n* ‰∏ÄËà¨`pool size`Âíå`stride`Áõ∏Âêå\n\n1. **MaxPooling ‰∏ãÈááÊ†∑Â±Ç**\n\n![image-20220403114548879](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220403114548879.png)\n\n2. **AveragePooling ‰∏ãÈááÊ†∑Â±Ç**\n\n![image-20220403114623086](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220403114623086.png)\n\n# **7 ÂèçÂêë‰º†Êí≠**\n\n## 7.1 ËØØÂ∑ÆËÆ°ÁÆó\n\n**Cross Entropy Loss ‰∫§ÂèâÁÜµÊçüÂ§±**\n\n1. ÈíàÂØπ**Â§öÂàÜÁ±ª**ÈóÆÈ¢òÔºàÊúÄÂêé‰∏ÄÂ±Ç‰∏∫**softmax**ËæìÂá∫ÔºåÊâÄÊúâËæìÂá∫Ê¶ÇÁéáÂíå‰∏∫1Ôºâ\n\n$$\nH=-\\sum_io^*log(o_i)\n$$\n\n2. ÈíàÂØπ**‰∫åÂàÜÁ±ª**ÈóÆÈ¢òÔºàÊúÄÂêé‰∏ÄÂ±Ç‰∏∫**sigmoid**ËæìÂá∫ÔºåËæìÂá∫ËäÇÁÇπ‰πãÈó¥Áõ∏‰∫í‰∏çÁõ∏Âπ≤Ôºâ\n\n$$\nH=-\\frac{1}{N}\\sum_{i=1}^N[o_i^*log(o_i)+(1-o_i^*)log(1-[o_i)]\n$$\n\nÂÖ∂‰∏≠Ôºå$o_i^*$‰∏∫ÁúüÂÆûÊ†áÁ≠æÂÄºÔºå$o_i$‰∏∫È¢ÑÊµãÂÄºÔºåÈªòËÆ§$log$=$ln$\n\n## 7.2 ËØØÂ∑ÆÁöÑÂèçÂêë‰º†Êí≠\n\n![image-20220328221513797](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220328221513797.png)\n\n![image-20220328221543152](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220328221543152.png)\n\n![image-20220328221622680](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220328221622680.png)\n\n## 7.3 ÊùÉÈáçÁöÑÊõ¥Êñ∞\n\n![image-20220328221732785](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220328221732785.png)\n\n![image-20220328221848547](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220328221848547.png)\n\n# **8 ‰ºòÂåñÂô® optimizer**\n\n![image-20220328222050506](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220328222050506.png)\n\n## 8.1 SGD\n\n![image-20220328222130228](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220328222130228.png)\n\n## 8.2 SGD+Momentum‰ºòÂåñÂô®\n\n![image-20220328222335145](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220328222335145.png)\n\n## 8.3 Adagrad‰ºòÂåñÂô®ÔºàËá™ÈÄÇÂ∫îÂ≠¶‰π†ÁéáÔºâ\n\n![image-20220328222425119](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220328222425119.png)\n\n## 8.4 RMSProp‰ºòÂåñÂô®\n\n![image-20220328222528324](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220328222528324.png)\n\n## 8.5 Adam‰ºòÂåñÂô®ÔºàËá™ÈÄÇÂ∫îÂ≠¶‰π†ÁéáÔºâ\n\n![image-20220328222551419](https://raw.githubusercontent.com/Jiayi-Zeng/Jiayi-Zeng.github.io/pic/img/image-20220328222551419.png)","tags":["CV"],"categories":["Computer Vision"]},{"title":"Real-Time Rendering & DLSS 2.0","url":"/docs/Other-Real-time-Rendering-and-DLSS-2.0/","content":"\nÊú¨ÊñáÊòØÂú®ËÆ°ÁÆóÊú∫ÂõæÂΩ¢Â≠¶ÊúüÊú´ËÄÉÂØüÁöÑËÉåÊôØ‰∏ãÔºåÈÄöËøá‰∏ÄÂë®ÁöÑË∞ÉÊü•Âπ∂Êåâ‰∏™‰∫∫ÁêÜËß£Êï¥ÁêÜÂæóÂá∫ÁöÑ„ÄÇËôΩËØ¥ÊñáÁ´†‰πüÊòØÊÄªÁªìÁöÑÁ≤æÂçéÔºå‰ΩÜ‰∏™‰∫∫‰ª•‰∏∫ËøòÈ¢áÊúâÁ≤óÁ≥ô‰πãÂ§ÑÔºàÂ¶ÇÊúâÈîôËØØÊ¨¢ËøéÊåáÊ≠£Ôºâ„ÄÇÂú®Ê≠§ÔºåÁ¨îËÄÖÊääÂèÇËÄÉËµÑÊ∫êÊîæ‰∫éÊñáÁ´†‰πãÂâç‚Äî‚ÄîÁõ∏ÊØî‰∫éÊú¨ÊñáÔºåÂèÇËÄÉËµÑÊñôÂú®Â≠¶ÊúØ‰∏äÊõ¥ÂáÜÁ°ÆÔºåÂÜÖÂÆπÊ∑±ÂàªÔºåË°®ËææÂæó‰ΩìÔºõÂè¶‰∏ÄÊñπÈù¢‰πüÊòØÂ∏åÊúõÂ§ßÂÆ∂‰ºòÂÖà‰ªéÂèÇËÄÉËµÑÊñô‰∏ãÊâãÔºå‰ªé‰∏≠ÂæóÂá∫Ëá™Â∑±ÁöÑÊÄùËÄÉÔºåÂÜçÊù•Á¨ëÁúãËøôÁØáÂ§öÊñπÂÄüÈâ¥ÁöÑÊÄªÁªì„ÄÇ\n\n<!--more-->\n\n# **Reference**\n\n* Â¶ÇÊûúÊÉ≥Ë¶ÅÂÖ•Èó®ÊàñËÄÖÂø´ÈÄü‰∫ÜËß£‰∏Ä‰∏ãÂèØ‰ª•ÂÖàÁúãBÁ´ôÁöÑÁßëÊôÆËßÜÈ¢ëÔºåÂèØ‰ª•Â§ßËá¥‰∫ÜËß£DLSSÊòØ‰ªÄ‰πàÔºå‰∏∫‰ªÄ‰πàÔºåÊÄé‰πàÂÅö„ÄÇÁúãÂÆåËßÜÈ¢ëÊñπ‰æø‰Ω†Ëøõ‰∏ÄÊ≠•ÊèêÂá∫ÈóÆÈ¢òÔºåÊü•ÊâæËµÑÊñô„ÄÇ\n\t*  [BÁ´ôÔºöDLSSÂà∞Â∫ïÊòØ‰ªÄ‰πàÊäÄÊúØÔºü‰∏∫‰ΩïËÉΩÊèêÂçáÊ∏∏ÊàèÊÄßËÉΩÔºüÊúâ‰ª£‰ª∑ÂêóÔºü](https://www.bilibili.com/video/BV1Dy4y117BM?spm_id_from=333.999.0.0),\n\t* [BÁ´ôÔºö„ÄêÁ°¨‰ª∂ÁßëÊôÆ„ÄëÂÖçË¥πÊèêÂçáÁîªË¥®ÂíåÂ∏ßÊï∞ÔºüËØ¶Ëß£DLSS2.0ÁöÑÂ∑•‰ΩúÂéüÁêÜ‰∏é‰ΩúÁî®](https://www.bilibili.com/video/BV1PA41187g2?spm_id_from=333.999.0.0)\n* NVIDIAÂÆòÁΩë‰ªãÁªçÔºö[NVIDIAÔºöDLSS 2.0](https://www.nvidia.com/en-us/geforce/news/nvidia-dlss-2-0-a-big-leap-in-ai-rendering/)\nÊ≠§Â§ñÔºåNVIDAËøòÂú®GTC‰∏äÁªôÂá∫‰∫ÜÁõ∏Â∫îÁöÑTalkÔºåÂÖ∂‰∏≠‰ªãÁªç‰∫ÜDLSS 2.0„ÄÅÈíàÂØπ‰∫éÊ∏∏ÊàèÁöÑÂõæÂÉèË∂ÖÂàÜËæ®ÁéáÁöÑÊåëÊàò‰ª•ÂèäDLSS 2.0ÂºïÊìéÈõÜÊàêÔºöNVIDA's TalkÔºö[GTC 2020: DLSS 2.0 - Image Reconstruction for Real-time Rendering with Deep Learning](https://www.youtube.com/watch?v=d5knHzv0IQE)ÔºàËøôÊòØÊ≤πÁÆ°‰∏äÈù¢ÁöÑÔºåËã±ËØ≠Âê¨ÂäõokÁöÑÂèØ‰ª•Áõ¥Êé•ÂÜ≤ÔºåËã±ËØ≠‰∏çÂ§™Ë°åÁöÑÂèØ‰ª•ÂºÄ‰∏≠ÊñáÂ≠óÊØç„ÄÇÂ•ΩÂÉèbÁ´ô‰πü‰∏äÁ∫ø‰∫ÜÔºå‰ΩÜËøòÊ≤°ÁÇπËøõÂéªËøáÔºå‰∏çÁü•ÈÅìÊúâÊ≤°ÊúâÁøªËØëÔºâÊú¨ÊñáÊúâÂÖ≥‰∫éDLSS 2.0ÁöÑ‰ªãÁªçÂ§ßÊäµ‰∏ä‰πüÂá∫Ëá™Ëøô‰∏™Talk.\n* ÂêåÊó∂ÔºåDLSSÂõ¢ÈòüÊàêÂëò[ÊñáÂàÄÁßã‰∫å](https://www.zhihu.com/people/edliu/posts)‰πüÊòØËøô‰∏™TalkÁöÑÊ±áÊä•‰∫∫Âú®Áü•‰πé‰∏ä‰πüÂØπTalkËøõË°å‰∫ÜÊÄªÁªìÔºåËØ¶ËßÅÔºö[DLSS 2.0 - Âü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÂÆûÊó∂Ê∏≤ÊüìÂõæÂÉèÈáçÂª∫](https://zhuanlan.zhihu.com/p/123642175)\n* [Beyond3D: Diving into Anti-Aliasing](https://www.beyond3d.com/content/news/798)‰∏™‰∫∫ËßâÂæóÊòØÂæàÂÖ®Èù¢ÂæàÊúâÈÄªËæëÁöÑÊäóÈîØÈΩøÁöÑ‰ªãÁªç„ÄÇÊúâÈúÄË¶ÅÁöÑÊúãÂèãÂèØ‰ª•Ëá™ÂèñÔºÅ\n* ‰π¶Á±çÔºö[Real time rendering](https://www.taylorfrancis.com/books/mono/10.1201/9781315365459/real-time-rendering-tomas-akenine-mo%CC%88ller-eric-haines-naty-hoffman) Âú®ÂÆûÊó∂Ê∏≤ÊüìÂíåËÆ°ÁÆóÊú∫ÂõæÂΩ¢Â≠¶È¢ÜÂüüÔºå„ÄäReal-Time Rendering„ÄãËøôÊú¨‰π¶‰∏ÄÁõ¥Â§áÂèóÊé®Â¥á„ÄÇÊúâ‰∫∫ËØ¥ÔºåÂÆÉÂÆûÊó∂Ê∏≤ÊüìÁöÑÂú£Áªè„ÄÇ‰πüÊúâ‰∫∫ËØ¥ÔºåÂÆÉÊòØÁªù‰∏ñÊ≠¶ÂäüÁöÑÁõÆÂΩï„ÄÇËøôÊ¨°Ë∞ÉÊü•‰∏ªË¶ÅÈòÖËØª‰∫ÜÊú¨‰π¶ÂÖ≥‰∫éÊäóÈîØÈΩøÊñπÈù¢ÁöÑ‰ªãÁªç„ÄÇÂ¶ÇÊúâÊú∫‰ºöÂèØ‰ª•ËøõÂÜõÁõ∏ÂÖ≥È¢ÜÂüüÔºåËøòÊòØÂæàÊúüÂæÖÂèØ‰ª•ÊääËøôÊú¨‰π¶ËØª‰∏Ä‰∏ãÁöÑ„ÄÇÂΩìÁÑ∂ÊØõÊòü‰∫ë‰πüÂú®CSDN‰∏äÂèëÂ∏É‰∫ÜËøôÊú¨‰π¶Á¨¨‰∏âÁâàÊèêÁÇºÊÄªÁªìÁöÑ‰∏ìÊ†èÔºö[„Äê„ÄäReal-Time Rendering 3rd„ÄãÊèêÁÇºÊÄªÁªì„Äë](https://blog.csdn.net/poem_qianmo/category_9269285.html?spm=1001.2014.3001.5482)Ôºå‰∏§ËÄÖÂèØ‰ª•ÈÖçÂêàÈ£üÁî®„ÄÇ\n* ‰∏ÄÁØá2021Âπ¥7ÊúàÁöÑÊúüÂàäÔºö[An overview of current deep learned rendering technologies](https://www.webofscience.com/wos/alldb/full-record/INSPEC:20799965) ÁùÄÈáçËÆ®ËÆ∫ÂÆûÊó∂Ê∏≤ÊüìÂíåÊ∑±Â∫¶Â≠¶‰π†Ê∏≤Êüì„ÄÇÂÖ∂‰∏≠‰ªãÁªç‰∫ÜÂÆûÊó∂Ê∏≤ÊüìÊäÄÊúØ‰∏≠ÁöÑÊäóÈîØÈΩøÂíåË∂ÖÂàÜËæ®ÁéáÔºåÊ∑±Â∫¶Â≠¶‰π†Ê∏≤ÊüìÊäÄÊúØ‰∏≠ÁöÑDLSSÂíåNSSÊ®°ÂûãÔºåÂπ∂‰∏î‰ªãÁªç‰∫ÜDLSRÊäÄÊúØÈù¢‰∏¥ÁöÑÊåëÊàò„ÄÇÊú¨ÊñáÁöÑÊÄùË∑Ø‰πü‰ªéËøôÁØáÊúüÂàäËÄåÊù•„ÄÇ\n\n# **1 ÂâçË®Ä**\n\nÈÄö‰øóËÆ≤Ôºå**Ê∏≤Êüì**ÔºàRender)ÊòØÂ§ÑÁêÜÂô®Â∞ÜÈúÄË¶ÅËÆ°ÁÆóÁöÑÁîªÈù¢‰ø°ÊÅØÔºåËÆ°ÁÆóÂπ∂‚ÄúÁªòÂà∂‚ÄùÂú®ÊòæÁ§∫Â±èÂπï‰∏äÁöÑËøáÁ®ã„ÄÇÈöèÁùÄÊòæÁ§∫ÊäÄÊúØÁöÑËøõÊ≠•ÔºåÊ∏≤ÊüìÊäÄÊúØ‰πüÊÖ¢ÊÖ¢Âú∞Âá∫Áé∞‰∫Ü‰∏§Êù°‰∏ªÊµÅÂàÜÊîØÔºö‰∏ÄÁßçÁî®‰∫éËßÜÈ¢ëÊ∏∏ÊàèÊäÄÊúØÔºåÂè¶‰∏ÄÁßçÂàôÊòØÁî®‰∫éÂΩ±ËßÜÊäÄÊúØ„ÄÇËøô‰∏§Á±ªÈúÄÊ±ÇÂØπÂ∫îÁöÑÊ∏≤ÊüìÊäÄÊúØÂàÜÂà´‰∏∫Ôºö**ÂÆûÊó∂Ê∏≤Êüì‰∏éÁ¶ªÁ∫øÊ∏≤Êüì**„ÄÇ\n\n**ÂÆûÊó∂Ê∏≤Êüì**ÔºàReal-time renderingÔºâÊåáÁöÑÊòØÂú®ËÆ°ÁÆóÊú∫‰∏äÂø´ÈÄüÁîüÊàêÂõæÂÉè„ÄÇÂÆÉÊòØËÆ°ÁÆóÊú∫ÂõæÂΩ¢Â≠¶‰∏≠ÊúÄÂÖ∑‰∫§‰∫íÊÄßÁöÑÈ¢ÜÂüü„ÄÇÈ¶ñÂÖà‰∏ÄÂπÖÂõæÂÉèÊòæÁ§∫Âú®Â±èÂπï‰∏äÔºåÁÑ∂ÂêéËßÇÂØüËÄÖÂÅöÂá∫Âä®‰Ωú‰∏éÂèçÂ∫îÔºåÂπ∂‰∏îÂÖ∂Âä®‰ΩúÂèçÈ¶à‰ºöÂΩ±ÂìçÊé•‰∏ãÊù•ÁöÑÁîüÊàêÂÜÖÂÆπ„ÄÇÁî±‰∫éËøôÁßçÂèçÈ¶à„ÄÅÊ∏≤ÊüìÁöÑÂæ™ÁéØÈÄüÂ∫¶Ë∂≥Â§üÂø´ÔºåËßÇÂØüËÄÖÂ∞±‰∏ç‰ºöÂè™ÁúãÂà∞Áã¨Á´ãÁöÑÂõæÂÉèÔºåËÄåÊòØ‰ºöÊ≤âÊµ∏Âú®ËøôÁßçÂä®ÊÄÅËøáÁ®ã‰∏≠„ÄÇ\n\nÁî±‰∫éËøΩÊ±ÇÈ´òÂàÜËæ®ÁéáÂíåÈ´òÂ∏ßÁéáÁöÑÁúüÂÆûÊÄß‰ΩìÈ™åÔºåRTRÊäÄÊúØÈöæÂ∫¶ÂëàÊåáÊï∞Âûã‰∏äÂçá„ÄÇÊòæÁ§∫ËÆæÂ§áÁöÑÊõ¥Êñ∞Êç¢‰ª£‰ª•ÂèäÁâ©ÁêÜÁùÄËâ≤„ÄÅÂÖâÁ∫øËøΩË∏™„ÄÅÁ≤æÁ°ÆÁâ©ÁêÜÂºïÊìé„ÄÅÊõ¥È´òË¥®ÈáèÁöÑÁ∫πÁêÜÊ®°ÂûãÁöÑÂÆûÁé∞‰ΩøÊúÄÊñ∞‰∏Ä‰ª£ GPU ‰πüÈöæ‰ª•Âú®‰∏çÂΩ±ÂìçÂ∏ßÁéáÁöÑÊÉÖÂÜµ‰∏ã‰ª•ÂéüÂßãÂàÜËæ®ÁéáÊ∏≤ÊüìÂõæÂÉè„ÄÇÊ≠§Êó∂Ôºå**‰ΩéÂàÜËæ®ÁéáÁöÑÊÄßËÉΩÂºÄÈîÄÂÆûÁé∞È´òÂàÜËæ®ÁéáÁöÑÁîªÈù¢**Êàê‰∏∫Â§ßÂäøÊâÄË∂ã„ÄÇ\n\n<center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/f5622c6950d64a19b46d2bd8a9a10748.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_11,color_FFFFFF,t_70,g_se,x_16#pic_center\"><br>\n    <div style=\"color: #999;\">Âõæ1 RTX</div>\n</center>\n\nÂÄüÂä©‰∫éÊ∑±Â∫¶Â≠¶‰π†Ë∂ÖÈááÊ†∑ÔºåNVIDIAÊé®Âá∫DLSS 2.0„ÄÇÂÖ∂ÂÆûÁé∞‰∫ÜÈÄöËøáÊ∏≤ÊüìÊõ¥Â∞ëÁöÑÂÉèÁ¥†Ôºå‰ΩøÁî® AI ÊûÑÂª∫Ê∏ÖÊô∞„ÄÅÂàÜËæ®ÁéáÊõ¥È´òÁöÑÂõæÂÉè„ÄÇ DLSS2.0Áî±GeForce RTX GPU‰∏äÁöÑ‰∏ìÁî® AI Â§ÑÁêÜÂô®Tensor Cores Êèê‰æõÊîØÊåÅÔºåÊòØ‰∏ÄÁßçÁªèËøáÊîπËøõÁöÑÂÖ®Êñ∞Ê∑±Â∫¶Â≠¶‰π†Á•ûÁªèÁΩëÁªúÔºåÂèØÂú®ÁîüÊàêÁ≤æÁæé„ÄÅÊ∏ÖÊô∞ÁöÑÊ∏∏ÊàèÂõæÂÉèÁöÑÂêåÊó∂ÊèêÈ´òÂ∏ßÈÄü„ÄÇÂÆÉ‰∏∫Ê∏∏ÊàèÁé©ÂÆ∂Êèê‰æõ‰∫ÜÊúÄÂ§ßÂåñÂÖâÁ∫øËøΩË∏™ËÆæÁΩÆÂíåÊèêÈ´òËæìÂá∫ÂàÜËæ®ÁéáÁöÑÊÄßËÉΩÁ©∫Èó¥„ÄÇ \n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/809cd174ff5a4637bbe8dfa58f3c55fa.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_20,color_FFFFFF,t_70,g_se,x_16\"> <br>\n    <div style=\"color: #999\">Âõæ2 NVIDIAÊé®Âá∫DLSSÊäÄÊúØ</div>\n</center>\n\nÊú¨ÊñáÊó®Âú®‰ªãÁªçÂÆûÊó∂Ê∏≤ÊüìÂõæÂÉèÈáçÂª∫ÊäÄÊúØÈÉ®ÂàÜÂü∫Á°ÄÔºåÂêåÊó∂ÁùÄÈáç‰∫éËÆ®ËÆ∫Êñ∞ÂÖ¥ÁöÑÂü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÂÆûÊó∂Ê∏≤ÊüìÈáçÂª∫DLSS 2.0„ÄÇÊñáÁ´†ÁªìÊûÑÂ¶Ç‰∏ãÔºö**Á¨¨‰∏ÄÈÉ®ÂàÜËÆ®ËÆ∫‰∫ÜÂÆûÊó∂Ê∏≤ÊüìÈáçÂª∫ÊäÄÊúØÂü∫Á°ÄÔºåÂåÖÊã¨ÊäóÈîØÈΩøÂíåË∂ÖÂàÜËæ®ÁéáÈááÊ†∑‰∏§‰∏™ÊñπÂêëÔºõÁ¨¨‰∫åÈÉ®ÂàÜÁùÄÈáçËÆ®ËÆ∫DLSS 2.0ÊäÄÊúØÁöÑÁêÜËÆ∫„ÄÅÂ∑•‰ΩúÂéüÁêÜÂíåÂÆûÁé∞ÊïàÊûúÔºõÁ¨¨‰∏âÈÉ®ÂàÜÂàÜÊûêDLSS 2.0ÁöÑ‰ºòÁÇπÂíåÁº∫ÁÇπÔºåÂπ∂ËÆ®ËÆ∫‰∫ÜDLSRÊäÄÊúØÈù¢‰∏¥ÁöÑÊåëÊàòÂíåÂ±ïÊúõ„ÄÇ**\n\n# **2 ÂÆûÊó∂Ê∏≤ÊüìÂõæÂÉèÈáçÂª∫ÊäÄÊúØÂü∫Á°Ä**\n\n## 2.1 ÊäóÈîØÈΩøÊäÄÊúØ\n\n**Aliasing**ÔºàÈîØÈΩøÔºâËøô‰∏™ÊúØËØ≠ÊúÄÊó©Âá∫Áé∞Âú®‰ø°Âè∑Â§ÑÁêÜËøôÈó®Â≠¶Áßë‰∏≠ÔºåÊåáÁöÑÊòØÂΩì‰∏Ä‰∏™ËøûÁª≠‰ø°Âè∑Ë¢´ÈááÊ†∑ÂêéÂíåÂÖ∂‰ªñÈùû‰∏ÄËá¥‰ø°Âè∑Ê∑∑Ê∑ÜÁöÑÁé∞Ë±°„ÄÇÂú®3DÊ∏≤Êüì‰∏≠ÔºåËøô‰∏™ÊúØËØ≠ÊúâÁùÄÊõ¥ÁâπÊÆäÁöÑÊÑèÊÄù‚Äî‚ÄîÂÆÉÊ∂µÁõñ‰∫ÜÊâÄÊúâ3DÊ∏≤ÊüìÂÖâÊ†ÖÂåñÂêé‰∫ßÁîüÁöÑÁîªÈù¢ÁëïÁñµ„ÄÇ3DÂú∫ÊôØÊ∏≤ÊüìÂú®ÂÖâÊ†ÖÂåñ‰πãÂâçÊòØËøûÁª≠‰ø°Âè∑Ôºå‰ΩÜÂú®ËøõË°åÂÉèÁ¥†Ê∏≤ÊüìÔºàÂØπÊØè‰∏™ÂÉèÁ¥†ÁîüÊàêÁõ∏Â∫îÁöÑËâ≤ÂΩ©ÂÄºÔºâÁöÑÊó∂ÂÄôÂ∞±‰∏çÂæó‰∏çÂØπËøûÁª≠‰ø°Âè∑ËøõË°åÈááÊ†∑‰ª•Ëé∑ÂæóËÉΩÂ§üËæìÂá∫Âà∞ÊòæÁ§∫Âô®ÁöÑÁªìÊûú„ÄÇÂèçÈîØÈΩøÁöÑÁõÆÊ†áÂ∞±Âú®‰∫éËÆ©ÊúÄÁªàËæìÂá∫ÁöÑÁîªÈù¢ÂíåÂéüÁîüÂú∫ÊôØÂ∞ΩÂèØËÉΩÊé•ËøëÔºå‰øÆÂ§çÊ∏≤ÊüìÁëïÁñµ„ÄÇ\n\n**ÊâÄÊúâÁöÑÊ∏≤ÊüìÂ§±ÁúüÈÉΩÂèØ‰ª•ÂΩíÂõ†‰∫éÈááÊ†∑ÈóÆÈ¢ò**ÔºàÁî®ÊúâÈôêÁöÑÂÉèÁ¥†Â±ïÁ§∫Êó†ÈôêÁöÑÁªÜËäÇÔºâÔºå‰ΩøÁî®Âì™ÁßçÂèçÈîØÈΩøÊâãÊÆµ‰∏éÈîØÈΩøÊàêÂõ†ÊÅØÊÅØÁõ∏ÂÖ≥„ÄÇÂõ†Ê≠§Ôºå‰∏∫‰∫ÜÊé¢ËÆ®‰∏çÂêåÂèçÈîØÈΩøÊâãÊÆµÁöÑ‰ºòÂäøÂíåÂä£ÂäøÔºåÊàë‰ª¨ÂÖàÂ∞Ü3DÊ∏≤ÊüìÁöÑÁëïÁñµÊ†πÊçÆÂÖ∂ÊàêÂõ†ÁÆÄÂçïÂΩíÁ∫≥‰∏∫6‰∏™Á±ªÂà´Ôºö**Âá†‰ΩïÂ§±Áúü„ÄÅÈÄèÊòéÂ§±Áúü„ÄÅÂ≠êÂÉèÁ¥†Â§±Áúü„ÄÅÁ∫πÁêÜÂ§±Áúü„ÄÅÊ∏≤ÊüìÂ§±Áúü„ÄÅÈó™ÁÉÅÊÉÖÂΩ¢ÔºàÊó∂Èó¥ÊÄßÈîØÈΩøÔºâ**„ÄÇ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/6501b6475d9644f79dc48c0d99094aec.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_12,color_FFFFFF,t_70,g_se,x_16\"><br>\n    <div style=\"color: #999;\">Âõæ 3 ÂêÑÁßçÁ±ªÂûãÁöÑÂ§±Áúü„ÄÇÂàÜÂà´‰∏∫Ôºö<br>ÈÄèÊòéÂ§±Áúü„ÄÅÂá†‰ΩïÂ§±ÁúüÔºà2DÔºâ„ÄÅÂ≠êÂÉèÁ¥†Â§±Áúü„ÄÅ<br>Âá†‰ΩïÂ§±ÁúüÔºà3DÔºâ„ÄÅÁ∫πÁêÜÂ§±Áúü„ÄÅÊ∏≤ÊüìÂ§±Áúü</div>\n</center>\n\nÁé∞Â¶Ç‰ªäÁöÑÊäóÈîØÈΩøÊäÄÊúØÂèØ‰ª•ÂàÜ‰∏∫‰∏§Á±ªÔºö**‰∏ÄÁ±ªÊòØÈÄöËøáÊèêÈ´òÈááÊ†∑Ë¥®ÈáèÊù•ÂáèÂ∞ëÊ∏≤ÊüìÊó∂ÈîØÈΩøÔºåÂè¶‰∏ÄÁ±ªÂàôÊòØÈÄöËøáÂØπÂ∑≤Ê∏≤ÊüìÂ•ΩÁöÑÂõæÁâáÂàÜÊûêÂíåÂêéÂ§ÑÁêÜÊù•ÂáèÂ∞ëÈîØÈΩø„ÄÇ**\n\n### 2.1.1 Âü∫‰∫éÈááÊ†∑ÁöÑÊäóÈîØÈΩøÊäÄÊúØ\n\nÈ¶ñÂÖàËÆ®ËÆ∫Âü∫‰∫éÈááÊ†∑ÁöÑÂèçÈîØÈΩøÊäÄÊúØÔºåÂÖ∂ÂÆûË¥®ÂàôÊòØÈÄöËøáÊ∏≤ÊüìÊØîÂ±èÂπïÂàÜËæ®ÁéáÊõ¥È´òÁöÑÁîªÈù¢ËÄåÂêéÂÜçÈôçÈááÊ†∑Ëá≥Â±èÂπïÁ©∫Èó¥ÂàÜËæ®Áéá„ÄÇÊ†∑Êú¨Êï∞ÈáèÔºåÊ†∑Êú¨‰ΩçÁΩÆ„ÄÅÈááÊ†∑Ê®°ÂºèÂíåÊ†∑Êú¨ËûçÂêàÊñπÂºèÈÉΩ‰ºöÂΩ±ÂìçÊúÄÁªàÁöÑÁîªÈù¢Ë¥®Èáè„ÄÇ\n\n#### Ê†∑Êú¨Êï∞Èáè\n\nÊòæËÄåÊòìËßÅÔºåÂÄòËã•ÁîüÊàê‰∏Ä‰∏™ÂÉèÁ¥†ÁöÑÈááÊ†∑ÁÇπË∂ãËøë‰∫éÊó†Á©∑Â§öÔºåÈÇ£‰πàÊúÄÁªàÁöÑÊïàÊûúÂ∞±‰ºöÊó†ÈôêË∂ãËøë‚ÄúÂÆåÁæé‚ÄùÁöÑÂÖâÊ†ÖÂåñÊïàÊûú„ÄÇÂõ†Ê≠§ÔºåÊäóÈîØÈΩøÁöÑÊïàÊûúÂíåÊ†∑Êú¨Êï∞ÈáèÂØÜÂàáÁõ∏ÂÖ≥„ÄÇÂΩìÁÑ∂Ê†∑Êú¨Êï∞Èáè‰πüÂÖ≥Á≥ªÂà∞ËÆæÂ§áÊÄßËÉΩÔºöÈÄöÂ∏∏Âú®Ê∏∏Êàè‰∏≠ÊØè‰∏™ÂÉèÁ¥†‰ºö‰ΩøÁî®2‰∏™Êàñ4‰∏™ÈááÊ†∑ÁÇπÔºåËÄåÂú®È´òÁ´ØÊòæÁ§∫Âô®‰∏≠ÂèØËÉΩ‰ºö‰ΩøÁî®Âà∞8‰∏™Âèä‰ª•‰∏äÁöÑÈááÊ†∑ÁÇπ„ÄÇ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/3bbef153efc74eeebc26a7bf68b36446.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_20,color_FFFFFF,t_70,g_se,x_16\"><br>\n    <div style=\"color: #999;\">Âõæ 4 ‰∏âËßíÂΩ¢ÂÖâÊ†ÖÂåñÔºåÊØè‰∏™ÂÉèÁ¥†Êúâ4‰∏™ÊúâÂ∫èÊ†∑Êú¨</div>\n</center>\n\n#### Ê†∑Êú¨‰ΩçÁΩÆ\n\n1. **È°∫Â∫èÊ†ÖÊ†ºË∂ÖÁ∫ßÈááÊ†∑ (Ordered Grid Super-SamplingÔºåOGSS)**\n\nÊ†∑Êú¨‰ΩçÁΩÆÁöÑÈÄâÂèñÂØπÊúÄÁªàÁîªÈù¢Ë¥®ÈáèÊúâÁùÄËá≥ÂÖ≥ÈáçË¶ÅÁöÑÂΩ±Âìç„ÄÇÁâπÂà´ÊòØÂú®Ê∏∏ÊàèÊ∏≤Êüì‰∏≠ÔºåÁî±‰∫éÈááÊ†∑ÁÇπÊï∞ÈáèÂ∞ëÔºåÊ†∑Êú¨‰ΩçÁΩÆÂ∞±Êõ¥‰∏∫ÈáçË¶Å„ÄÇÁî±‰∫éÊ†∑Êú¨‰ΩçÁΩÆÂëàÊúâÂ∫èÁÇπÊéíÂàóÔºåËøôÁßçÊäóÈîØÈΩø‰πüË¢´Áß∞‰ΩúÈ°∫Â∫èÊ†ÖÊ†ºË∂ÖÁ∫ßÈááÊ†∑„ÄÇ\n\n2. **ÊóãËΩ¨Ê†ÖÊ†ºË∂ÖÁ∫ßÈááÊ†∑ (Rotated Grid Super-SamplingÔºåRGSS)**\n\nÁÑ∂ËÄåÔºåÂØπ‰∫éÊé•ËøëÂûÇÁõ¥ÊàñÊé•ËøëÊ∞¥Âπ≥ÁöÑÁ∫øËÄåË®ÄÔºå‰ΩøÁî®ÊéíÂàóÊúâÂ∫èÁöÑÈááÊ†∑ÁΩëÊ†ºÊïàÊûúÂæÄÂæÄ‰∏ç‰Ω≥„ÄÇÊ≠§Êó∂ÔºåÈááÁî®ÊóãËΩ¨Ê†ÖÊ†ºË∂ÖÁ∫ßÈááÊ†∑ÂèØ‰ª•Ëé∑ÂæóÊõ¥Â•ΩÁöÑÁªìÊûú„ÄÇ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/349d5e3fd91d4f06bbb93e08706fdb10.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_15,color_FFFFFF,t_70,g_se,x_16\"><br>\n    <div style=\"color: #999;\">Âõæ 5 ËøëÂûÇÁõ¥Á∫øÂú∫ÊôØ„ÄÅÂÆåÁæéÊäóÈîØÈΩøÂÖâÊ†ÖÂåñ„ÄÅ4‰∏™ÊúâÂ∫èÊ†∑Êú¨ÁöÑÂÖâÊ†ÖÂåñ„ÄÅ4‰∏™Á®ÄÁñèÊ†ÖÊ†ºÊ†∑Êú¨ÁöÑÊäóÈîØÈΩø</div>\n</center> \n\n‰∏∫‰∫ÜÁºìËß£Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨‰πüÂèØ‰ª•Â∞ÜÈááÊ†∑ÁÇπÁ®ÄÁñèÊëÜÊîæÂú®‰∏çÂêåÁöÑÂàó„ÄÇÂØπ‰∫éÊäóÈîØÈΩøÊù•ËØ¥ÔºåÁêÜÊÉ≥ÁöÑÊëÜÊîæÂ∫îÂΩìÊòØÁ®ÄÁñèÁöÑ„ÄÇÊç¢Âè•ËØùËØ¥ÔºåÂØπ‰∫éN‰∏™ÈááÊ†∑ÁÇπÔºå‰ªªÊÑè‰∏§‰∏™ÈááÊ†∑ÁÇπ‰∏ç‰ºöÂú®‰∏Ä‰∏™$N\\times N$ÁΩëÊ†ºÁöÑÂêå‰∏ÄÂàó„ÄÅË°å‰ª•ÂèäÂØπËßíÁ∫ø‰∏ä„ÄÇÈÄöËøáÂØπNÁöáÂêéÈóÆÈ¢òÊ±ÇËß£ÂèØÂæóÂà∞Êª°Ë∂≥ËøôÁßçÊù°‰ª∂ÁöÑÈááÊ†∑ÁÇπÊëÜÊîæÊñπÂºèÔºåÂú®Ê≠§‰∏çÂÜçËµòËø∞„ÄÇËøôÁßçÁ®ÄÁñèÊëÜÊîæÈááÊ†∑ÁÇπÁöÑÊäóÈîØÈΩø‰πüË¢´Áß∞‰Ωú**Á®ÄÁñèÊ†ÖÊ†ºÊäóÈîØÈΩøÔºàSparse Grid Anti-aliasingÔºåSGAAÔºâ**„ÄÇ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/2d6763203ca54651992b293a2164e1ed.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_18,color_FFFFFF,t_70,g_se,x_16\"><br>\n    <div style=\"color: #999;\">Âõæ 6  Â∑¶ÂõæÔºöÊúâÂ∫èÈááÊ†∑ÁÇπ Âè≥ÂõæÔºöNÁöáÂêéÈááÊ†∑</div>\n</center> \n\n#### ÈááÊ†∑Á±ªÂûã\n\n1. **Ë∂ÖÈááÊ†∑ÊäóÈîØÈΩøÔºàSuper-sampling Anti-aliasingÔºåSSAAÔºâ**\n\n   Âü∫‰∫éÈááÊ†∑ÁöÑÊäóÈîØÈΩøÊñπÊ≥ïÂØπÊØè‰∏™ÈááÊ†∑ÁÇπÈÉΩËøõË°å‰∫ÜËøêÁÆó„ÄÇËôΩÁÑ∂ËøôÊ†∑ÁöÑÈááÊ†∑ÊñπÂºèÂèØ‰ª•Ê∂àÈô§ÂêÑÁ±ªÊ∏≤ÊüìÂ§±ÁúüÔºå‰ΩÜ‰πüÈùûÂ∏∏ËÄóË¥πËµÑÊ∫ê„ÄÇ‰∏æ‰∏™‰æãÂ≠êÔºåNÂÄçÈááÊ†∑Â∞Ü‰ºöÁªôÂÉèÁ¥†Ê∏≤Êüì„ÄÅÂÖâÊ†ÖÂçïÂÖÉ„ÄÅÂÜÖÂ≠òÂ∏¶ÂÆΩ‰ª•ÂèäÂÜÖÂ≠òÂÆπÈáèÊñΩÂä†NÂÄçÁöÑËÆ°ÁÆóÂéãÂäõ„ÄÇËøôÁßçÂØπÊØè‰∏™ÈááÊ†∑ÁÇπÈÉΩËøõË°åÁã¨Á´ãËÆ°ÁÆóÁöÑÈááÊ†∑‰πüË¢´Áß∞‰∏∫Ë∂ÖÈááÊ†∑ÊäóÈîØÈΩø„ÄÇ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/778a6c9f6e7947c9afff4a06b76f34b4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_12,color_FFFFFF,t_70,g_se,x_16\"><br>\n    <div style=\"color: #999;\">Âõæ 7 2 x SGSSAA</div>\n</center> \n\n\n2. **Â§öÈáçÈááÊ†∑ÊäóÈîØÈΩøÔºàmulti-sample anti-aliasingÔºåMSAAÔºâ**\n\n   Âú®ËøõÂÖ•21‰∏ñÁ∫™ÂêéÔºåÂ§öÈáçÈááÊ†∑ÊäóÈîØÈΩøÂºÄÂßã‰Ωú‰∏∫SSAAÁöÑ‰∏ÄÁßç‰ºòÂåñËß£Ë¢´ÂπøÊ≥õÂ∫îÁî®„ÄÇMSAAÂÆûË¥®ÊòØÂè™ÂØπ Z ÁºìÂ≠òÔºàZ-BufferÔºâÂíåÊ®°ÊùøÁºìÂ≠ò ÔºàStencil BufferÔºâ‰∏≠ÁöÑÊï∞ÊçÆËøõË°åË∂ÖÁ∫ßÈááÊ†∑ÊäóÈîØÈΩøÁöÑÂ§ÑÁêÜ„ÄÇÂèØ‰ª•ÁêÜËß£‰∏∫Âè™ÂØπËæπÁºòËøõË°åÊäóÈîØÈΩøÂ§ÑÁêÜ„ÄÇÂΩìÁ°¨‰ª∂ÊîØÊåÅZÁºìÂ≠òÂíåÊ®°ÊùøÁºìÂ≠òÊó∂ÔºàËÄåÁé∞‰ªäÂ§ßÈÉ®ÂàÜGPUÈÉΩÂ∑≤ÁªèÊîØÊåÅËøô‰∫õÁâπÊÄßÔºâÔºåMSAAÂ∏¶Êù•ÁöÑÂÜÖÂ≠òÂ∏¶ÂÆΩÂºÄÈîÄ‰ºöËøõ‰∏ÄÊ≠•Áº©Â∞è„ÄÇÁõ∏ÊØîSSAAÂØπÁîªÈù¢‰∏≠ÊâÄÊúâÊï∞ÊçÆËøõË°åÂ§ÑÁêÜÔºåMSAAÂ§ßÂ§ßÂáèÂº±ÂØπËµÑÊ∫êÁöÑÊ∂àËÄó„ÄÇ‰ΩÜÁî±‰∫éMSAA‰ªÖÈíàÂØπÂá†‰Ωï‰ΩìËæπÁºòËøõË°åÊäóÈîØÈΩøÔºåÂÖ∂‰ªñÁ±ªÂà´ÁöÑÂ§±ÁúüÔºàÈÄèÊòéÂ§±Áúü„ÄÅÁ∫πÁêÜÂ§±ÁúüÂíåÊ∏≤ÊüìÂ§±ÁúüÁ≠âÔºâÈÉΩÊó†Ê≥ïË¢´Ê∂àÈô§„ÄÇ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/81d2caa0a8c64832b54dd7ce81f1c227.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_19,color_FFFFFF,t_70,g_se,x_16\">\n    <br><div style=\"color: #999;\">Âõæ 8 MSAA‰ø°ÊÅØÂ≠òÂÇ®ÂíåÁõ∏Â∫îÁöÑEQAA</div>\n</center> \n\n\n<center>\n   <img style=\"border-radius: 0.3125em;\n   box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n   src=\"https://img-blog.csdnimg.cn/b7046a4f52b44e188e241173ba2c5966.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_12,color_FFFFFF,t_70,g_se,x_16\">\n   <br><div style=\"color: #999;\">\n   Âõæ 9 2xMSAA</div>\n</center> \n\n3. **Ë¶ÜÁõñÈááÊ†∑ÊäóÈîØÈΩøÔºàcoverage sampling anti-aliasingÔºåCSAAÔºâ**\n\n   Á¨¨‰∏âÁßçÈááÊ†∑Á±ªÂûãÂàôÊòØNVIDIAÂú®2006Âπ¥ÂºïÂÖ•ÁöÑË¶ÜÁõñÈááÊ†∑ÊäóÈîØÈΩø„ÄÇCSAAÂú®MSAAÁöÑÂü∫Á°Ä‰∏äËøòÂ¢ûÂä†‰∫ÜË¶ÜÁõñÈááÊ†∑(Coverage Sample)„ÄÇÁÆÄÂçïËØ¥ CSAA Â∞±ÊòØÂ∞ÜËæπÁºòÂ§öËæπÂΩ¢ÈáåÈúÄË¶ÅÂèñÊ†∑ÁöÑÂ≠êÂÉèÁ¥†ÂùêÊ†áË¶ÜÁõñÊéâÔºåÊääÂéüÂÉèÁ¥†ÂùêÊ†áÂº∫Âà∂ÂÆâÁΩÆÂú®Á°¨‰ª∂ÂíåÈ©±Âä®Á®ãÂ∫èÈ¢ÑÂÖàÁÆóÂ•ΩÁöÑÂùêÊ†á‰∏≠„ÄÇËøôÂ∞±Â•ΩÊØîÂèñÊ†∑Ê†áÂáÜÁªü‰∏ÄÁöÑMSAAÔºåËÉΩÂ§üÊúÄÈ´òÊïàÁéáÁöÑÊâßË°åËæπÁºòÂèñÊ†∑ÔºåÊïàËÉΩÊèêÂçáÈùûÂ∏∏ÁöÑÊòæËëó„ÄÇÊØîÊñπËØ¥16xCSAAÂèñÊ†∑ÊÄßËÉΩ‰∏ãÈôçÂπÖÂ∫¶‰ªÖÊØî4xMSAAÁï•È´ò‰∏ÄÁÇπÔºåÂ§ÑÁêÜÊïàÊûúÂç¥Âá†‰πéÂíå 8xMSAA‰∏ÄÊ†∑„ÄÇ8xCSAAÊúâÁùÄ4xMSAAÁöÑÂ§ÑÁêÜÊïàÊûúÔºåÊÄßËÉΩÊ∂àËÄóÂç¥Âíå2xMSAAÁõ∏Âêå„ÄÇ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/81052231830a4a5f9159826f0fb92178.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_12,color_FFFFFF,t_70,g_se,x_16\">\n    <br><div style=\"color: #999;\">\n    Âõæ 10  8x MSAA + alpha-to-coverage</div>\n</center> \n\n#### Ê†∑Êú¨ËûçÂêàÊñπÂºè\n\nÂΩ±ÂìçÈááÊ†∑ÊäóÈîØÈΩøË¥®ÈáèÁöÑÊúÄÂêé‰∏Ä‰∏™Ë¶ÅÁ¥†Â∞±ÊòØÊ†∑Êú¨ËûçÂêàÊ®°ÂºèÔºåÂç≥Â¶Ç‰ΩïÂ∞ÜÈááÊ†∑ÁÇπÂä†ÊùÉËÆ°ÁÆóÂá∫‰∏Ä‰∏™ÂÉèÁ¥†ÂÄº„ÄÇ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/34d90a7c43744fd5aae46040bd69f5c1.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_20,color_FFFFFF,t_70,g_se,x_16\">\n    <br><div style=\"color: #999;\">\n    Âõæ 11 Â∑¶ÂõæÔºöÁõíÂºèËøáÊª§Âô®Ôºå‰∏≠Èó¥ÔºöÈ´òÂàÜËæ®ÁéáÊäóÈîØÈΩøÊñπÊ≥ï Âè≥ÂõæÔºöTent filterÊäóÈîØÈΩø. ÊúÄÂ∏∏ËßÅÁöÑÊ∑∑ÂêàÊñπÊ≥ïÊòØ‰ª•Áõ∏ÂêåÊùÉÈáçÊ∑∑ÂêàÊØè‰∏™ÈááÊ†∑ÁÇπÔºåËøôË¢´Áß∞‰ΩúBox FilterÔºå‰πüÊòØÊâÄÊúâ‰º†ÁªüMSAAÊâÄÈááÁî®ÁöÑÊ®°Âºè„ÄÇ</div>\n</center> \n\n1. **È´òÂàÜËæ®ÁéáÊäóÈîØÈΩøÊñπÊ≥ï (High Resolution Anti-AliasingÔºåHRAA)**\n\n‰∏ÄÁßçÊîπËøõÁöÑËûçÂêàÊñπÊ≥ïË¢´Áß∞‰ΩúÈ´òÂàÜËæ®ÁéáÊäóÈîØÈΩøÊñπÊ≥ï‰πüÁß∞ Quincunx ÊñπÊ≥ïÔºåÂá∫Ëá™ NVIDIA ÂÖ¨Âè∏„ÄÇQuincunxÊåáÁöÑÊòØ5‰∏™Áâ©‰ΩìÁöÑÊéíÂàóÊñπÂºèÔºöÂÖ∂‰∏≠ 4 ‰∏™Âú®Ê≠£ÊñπÂΩ¢Ëßí‰∏äÔºåÁ¨¨‰∫î‰∏™Âú®Ê≠£ÊñπÂΩ¢‰∏≠ÂøÉÔºå‰πüÂ∞±ÊòØÊ¢ÖËä±ÂΩ¢ÔºåÂæàÂÉèÂÖ≠ËæπÊ®°Âûã‰∏äÁöÑ‰∫îÁÇπÂõæÊ°àÊ®°Âºè„ÄÇËøô‰ΩøÂæóÈááÊ†∑ÁÇπ‰∏™Êï∞‰∏çÂ§öÁöÑÊÉÖÂÜµ‰∏ãÁöÑÊäóÈîØÈΩøÊïàÊûúÊòéÊòæÂ¢ûÂº∫Ôºå‰ΩÜÁî±‰∫é‰∏Ä‰∏™ÂÉèÁ¥†ÁÇπËøáÂ§öÂú∞Ê∑∑Âêà‰∫ÜÂë®ËæπÁöÑÈááÊ†∑ÁÇπ‰ø°ÊÅØËÄå‰ΩøÂõæÂÉèËæπÁºòÂèòÂæóÊ®°Á≥äÔºåÂ∏¶Êù•‰∫ÜÁîªÈù¢ÈîêÂ∫¶Èôç‰ΩéÁöÑÈóÆÈ¢ò„ÄÇ\n\n2. **ÂèØÁºñÁ®ãËøáÊª§ÊäóÈîØÈΩøÔºàCustom Filter Anti-AliasingÔºåCFAAÔºâ**\n\n‰∏ÄÁßçÊõ¥ÁÅµÊ¥ªÁöÑÊñπÊ≥ïÂàôÂá∫Áé∞‰∫é2007Âπ¥AMDÁöÑHD2900Á≥ªÂàóÊòæÂç°‰∏≠ÔºåÂÖ∂Áß∞‰∏∫**Tent Filter**„ÄÇHD2900Á≥ªÂàóÊèê‰æõ‰∫ÜÂèØÁºñÁ®ãÁöÑÊ∑∑ÂêàËÉΩÂäõÔºå‰πüÁß∞‰∏∫ÂèØÁºñÁ®ãËøáÊª§ÊäóÈîØÈΩøÔºåÂπ∂ÂÄüËøôÁßçÂ∑•ÂÖ∑ÂÆûÁé∞‰∫ÜNarrow TentÂíåWide Tent‰∏§ÁßçÊ®°Âºè„ÄÇÂ¶ÇÂõæ9ÊâÄÁ§∫ÔºåËøô‰∏§ÁßçÊñ∞ÂûãÈááÊ†∑Ê®°ÂºèÂú®Ê∑∑ÂêàÈááÊ†∑ÁÇπÊó∂Âπ∂Ê≤°Êúâ‰ΩøÁî®Áõ∏ÂêåÊùÉÈáçÔºåËÄåÊòØÊ†πÊçÆÈááÊ†∑ÁÇπÁ¶ªÂÉèÁ¥†‰∏≠ÂøÉÁöÑË∑ùÁ¶ªÂÜ≥ÂÆöÁõ∏Â∫îÁöÑÊ∑∑ÂêàÊùÉÈáç„ÄÇNarrowÂíåWide‰∏§ÁßçÊ∑∑ÂêàÊ®°ÂºèÁöÑÂå∫Âà´‰ªÖÂú®‰∫éÂÖ∂‰ΩøÁî®ÁöÑËøáÊª§Ê†∏ÂøÉ(Filter Kernel)ÁöÑÂ§ßÂ∞è‰∏ä„ÄÇËøôÁßçÊ∑∑ÂêàÊ®°ÂºèÂèØ‰ª•Ê†πÊçÆÈúÄË¶Å‰ΩøÁî®‰∏çÂêåÊ†∑Êú¨Êï∞Èáè„ÄÇÁõ∏ËæÉ‰∫éQuincunxÊñπÊ≥ïÔºåËøôÁßçÊäóÈîØÈΩøÊ®°ÂºèÂèØ‰ª•ËØ¥ÊòØÂπ≥Ë°°‰∫ÜÁîªÈù¢ÈîêÂ∫¶ÂíåÊäóÈîØÈΩøÂäõÂ∫¶„ÄÇ\n\n<center>\n   <img style=\"border-radius: 0.3125em;\n   box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n   src=\"https://img-blog.csdnimg.cn/f9c56223eb1f490b9521a50c7dfc8697.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_20,color_FFFFFF,t_70,g_se,x_16\">\n   <br><div style=\"color: #999;\">\n   Âõæ 12 6x Narrow Tent | 6x Wide Tent</div>\n</center> \n\n### 2.1.2 ÂêéÂ§ÑÁêÜÊäóÈîØÈΩøÊäÄÊúØ\n\nËôΩÁÑ∂Âü∫‰∫éÈááÊ†∑ÁöÑÊäóÈîØÈΩøÁÆóÊ≥ï‰∏ç‰ªÖÂéüÁêÜÁÆÄÂçïÔºåÂú®ÈááÊ†∑ÁÇπË∂≥Â§üÁöÑÊÉÖÂÜµ‰∏ã‰πüÊúâÂæà‰ºòÁßÄÁöÑÊïàÊûúÔºå‰ΩÜÂú®ÊÄßËÉΩÊñπÈù¢‰ªçÁÑ∂‰ºöÂ∏¶Êù•Â∑®Â§ßÁöÑÂºÄÈîÄ„ÄÇÊ≠§Â§ñÂü∫‰∫éÈááÊ†∑ÁöÑÊäóÈîØÈΩøÂú®ËøëÊúüÊµÅË°åÁöÑÊ∏≤ÊüìÊ®°Âºè‰∏≠Ôºà‰æãÂ¶ÇÂª∂ËøüÊ∏≤ÊüìÔºâÂü∫‰∫éÂêÑÁßçÂéüÂõ†Êõ¥ÈöæË¢´ÂÆûÁé∞„ÄÇÁî±Ê≠§ËØûÁîü‰∫ÜÂè¶‰∏ÄÁßçÈùûÂü∫‰∫éÈááÊ†∑ÁöÑÊäóÈîØÈΩøÊñπÊ≥ï‚Äî‚ÄîÂêéÂ§ÑÁêÜÊäóÈîØÈΩø„ÄÇËøô‰∏™ÊñπÊ≥ïÊ∏≤ÊüìÂá∫Êú™‰ΩøÁî®ÊäóÈîØÈΩøÁöÑÂéüÁîüÁîªÈù¢ÔºàÊó†‰ªª‰ΩïÈááÊ†∑ÂíåÁº©ÊîæÔºâÔºåÈöèÂêéÂ∞ùËØïÈÄöËøáÂØπÊàêÂìÅÁîªÈù¢ÁöÑÂàÜÊûêÊù•ÂáèÂ∞ëÈîØÈΩøÂíåÂ§±Áúü„ÄÇ\n\nÊÄª‰ΩìËÄåË®ÄÔºåÊâÄÊúâÁöÑÂêéÂ§ÑÁêÜÊäóÈîØÈΩøÈÉΩÂåÖÂê´‰∫Ü‰ª•‰∏ã‰∏â‰∏™Ê≠•È™§ÔºåËÄå‰∏çÂêåÁöÑÂêéÂ§ÑÁêÜÊäóÈîØÈΩø‰∏ªË¶ÅÂå∫Âà´Â∞±Âú®Ëøô‰∏â‰∏™Ê≠•È™§ÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÊñπÊ≥ï‰∏ä„ÄÇ\n\n1. **Ê£ÄÊµãÂõæÂÉè‰∏≠‰∏çËøûÁª≠ÁöÑÈÉ®ÂàÜÔºåÂç≥Ê£ÄÊµãËæπÁºò‰ø°ÊÅØ**\n2. **ÈÄöËøáËøô‰∫õ‰∏çËøûÁª≠ÈÉ®ÂàÜÁöÑ‰ø°ÊÅØÈáçÂª∫ÂéüÂßãËæπÁºò‰ø°ÊÅØ**\n3. **ÂØπ‰º∞ÊµãËæπÁºò‰∏äÁöÑÂÉèÁ¥†ËøõË°åÈáçÁùÄËâ≤**\n\n**ÂΩ¢ÊÄÅÊäóÈîØÈΩøÔºàMorphological Anti-AliasingÔºåÁÆÄÁß∞ MLAAÔºâ**ÔºåÊòØ AMD Êé®Âá∫ÁöÑÂÆåÂÖ®Âü∫‰∫é CPU Â§ÑÁêÜÁöÑÊäóÈîØÈΩøËß£ÂÜ≥ÊñπÊ°à„ÄÇ‰æãÂ¶ÇÂõæ10Â±ïÁ§∫‰∫ÜMLAAÂØπËæπÁºòÁöÑËØÜÂà´ÂíåÈáçÂª∫ÊñπÂºè„ÄÇÂ∑¶‰æßÊòØËµ∞Ê†∑ÂõæÂÉè„ÄÇÊàë‰ª¨ÁöÑÁõÆÁöÑÊòØÁ°ÆÂÆöËæπÁºòÁöÑÂèØËÉΩÊñπÂêë„ÄÇ‰∏≠Èó¥ÂõæÂ±ïÁ§∫‰∫ÜÁÆóÊ≥ïÈÄöËøáÊ£ÄÊü•Áõ∏ÈÇªÂÉèÁ¥†Êù•ËÆ∞ÂΩïÂÖ∂‰∏∫ËæπÁºòÁöÑÂèØËÉΩÊÄßÔºåÂõæ‰∏≠ÊòæÁ§∫‰∫Ü‰∏§‰∏™ÂèØËÉΩÁöÑËæπÁºò‰ΩçÁΩÆ„ÄÇÂè≥‰æßÂõæÂàôÂ±ïÁ§∫‰ΩøÁî®‰∫ÜÊúÄ‰Ω≥ÁöÑÊé®ÊµãËæπÁºòÂêéÔºåÂ∞ÜÁõ∏ÈÇªÁöÑÈ¢úËâ≤‰∏é‰º∞ËÆ°ÁöÑË¶ÜÁõñÁéáÊàêÊØî‰æãÂú∞Ê∑∑ÂêàÂà∞‰∏≠ÂøÉÂÉèÁ¥†‰∏≠„ÄÇ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/083100ab8f5d45f99fc4717e34186570.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_20,color_FFFFFF,t_70,g_se,x_16\">\n    <br><div style=\"color: #999;\">\n    Âõæ 13 ÂΩ¢ÊÄÅÂ≠¶ÊäóÈîØÈΩø</div>\n</center> \n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/ffee10ce178c4057b5427684ed580f76.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_16,color_FFFFFF,t_70,g_se,x_16\">\n<br><div style=\"color: #999;\">Âõæ 14 Â∑¶ÂõæÔºöMLAA Ê®°ÂºèÂèäÂÖ∂ÈáçÂª∫ËæπÁºòÔºåÂè≥ÂõæÔºöMLAA ‰∏≠‰ΩøÁî®ÁöÑ‰∏çËøûÁª≠Ê®°Âºè</div></center> \n\n### 2.1.3 Ê∑∑ÂêàÊäóÈîØÈΩøÁÆóÊ≥ï\n\n‰∫ÜËß£‰∫Ü‰∏§Â§ßÁ±ªÊäóÈîØÈΩøÊäÄÊúØÊñπÂêëÂêéÔºåÊàë‰ª¨‰ºöÂéªÊÄùËÄÉÁé∞ÊúâÊµÅË°åÁöÑÊäóÈîØÈΩøÊäÄÊúØÊòØÂ¶Ç‰ΩïÂº•Ë°•‰º†ÁªüÁÆóÊ≥ïÁöÑÈÅóÊÜæ„ÄÇ\n\n**‰∏ÄÁßçÂèØË°åÁöÑËß£ÂÜ≥ÊñπÊ°àÊòØÂ∞ÜÂü∫‰∫éÈááÊ†∑ÁöÑÊäóÈîØÈΩøÁÆóÊ≥ïÂíåÂêéÊúüÂ§ÑÁêÜÊäóÈîØÈΩøÊäÄÊúØÁªìÂêàËµ∑Êù•„ÄÇ**ËøôÁßçÊñ∞ÁöÑÊ∑∑ÂêàÊäóÈîØÈΩøÁÆóÊ≥ïÂú®ÂØπÁîªÈù¢ËøõË°åÂ§öÊ¨°ÈááÊ†∑ÁöÑÂêåÊó∂Ôºå‰ºöÁªìÂêàÂêéÊúüÂ§ÑÁêÜÊäóÈîØÈΩøÁÆóÊ≥ï‰ª•ËæìÂá∫ÊúÄÁªàÁîªÈù¢„ÄÇËøôÊ†∑ÂÅöÁöÑÂ•ΩÂ§ÑÊòØÊòæËÄåÊòìËßÅÁöÑÔºöÊñ∞ÁÆóÊ≥ïÊó¢ÈÅøÂÖç‰∫ÜÁ∫ØÂêéÊúüÂ§ÑÁêÜÊäóÈîØÈΩøÁöÑÁßçÁßçÁº∫ÁÇπ(ÊØîÂ¶ÇËØ¥‰∏çËÉΩÂ§ÑÁêÜÂ≠êÂÉèÁ¥†Â§±ÁúüÂíåÈÄ†ÊàêËæπÁºòÈó™ÁÉÅÁöÑÈóÆÈ¢ò)ÔºåÂú®ÂêåÊ†∑ÁöÑÊÄßËÉΩÊçüÂ§±‰∏ãÔºåÂØπ‰∫éÂá†‰ΩïÂ§±ÁúüÁöÑÂ§ÑÁêÜÁªìÊûúÂèàÊØîÁ∫ØÁ≤πÂü∫‰∫éÈááÊ†∑ÁöÑÊäóÈîØÈΩøÁÆóÊ≥ïÂ•ΩÂæóÂ§ö„ÄÇ\n\n1. **Âø´ÈÄüËøë‰ººÊäóÈîØÈΩøÔºàFast Approximate Anti-AliasingÔºåFXAAÔºâ**\n\n  Âø´ÈÄüËøë‰ººÊäóÈîØÈΩøÊòØ‰º†Áªü MSAAÊïàÊûúÁöÑ‰∏ÄÁßçÈ´òÊÄßËÉΩËøë‰ºº„ÄÇÂÆÉÊòØ‰∏ÄÁßçÂçïÁ®ãÂÉèÁ¥†ÁùÄËâ≤Âô®ÔºåÂíå MLAA‰∏ÄÊ†∑ËøêË°å‰∫éÁõÆÊ†áÊ∏∏ÊàèÊ∏≤ÊüìÁÆ°Á∫øÁöÑÂêéÊúüÂ§ÑÁêÜÈò∂ÊÆµÔºå‰ΩÜ‰∏çÂÉèÂêéËÄÖÈÇ£Ê†∑‰ΩøÁî® DirectComputeÔºåËÄåÂè™ÊòØÂçïÁ∫ØÁöÑÂêéÊúüÂ§ÑÁêÜÁùÄËâ≤Âô®Ôºå‰∏ç‰æùËµñ‰∫é‰ªª‰ΩïGPUËÆ°ÁÆó API„ÄÇÊ≠£Âõ†‰∏∫Â¶ÇÊ≠§ÔºåFXAAÊäÄÊúØÂØπÊòæÂç°Ê≤°ÊúâÁâπÊÆäË¶ÅÊ±ÇÔºåÂÆåÂÖ®ÂÖºÂÆπ NVIDIA„ÄÅAMD ÁöÑ‰∏çÂêåÊòæÂç°(MLAA‰ªÖÊîØÊåÅAMD)Âíå DirectX 9.0„ÄÅDirectX 10„ÄÅDirectX 11„ÄÇ\n\n2. **Êó∂Èó¥ÊÄßÊäóÈîØÈΩøÔºàTemporal Anti-AliasingÔºåTXAAÔºâ**\n\n  Êó∂Èó¥ÊÄßÊäóÈîØÈΩøÂ∞ÜMSAA„ÄÅÊó∂Èó¥Êª§Ê≥¢‰ª•ÂèäÂêéÊúüÂ§ÑÁêÜÁõ∏ÁªìÂêàÔºåÁî®‰∫éÂëàÁé∞Êõ¥È´òÁöÑËßÜËßâ‰øùÁúüÂ∫¶„ÄÇ‰∏éCGÁîµÂΩ±‰∏≠ÊâÄÈááÁî®ÁöÑÊäÄÊúØÁ±ª‰ººÔºåTXAAÈõÜMSAAÁöÑÂº∫Â§ßÂäüËÉΩ‰∏éÂ§çÊùÇÁöÑËß£ÊûêÊª§Èïú‰∫é‰∏ÄË∫´ÔºåÂèØÂëàÁé∞Âá∫Êõ¥Âä†Âπ≥ÊªëÁöÑÂõæÂÉèÊïàÊûú„ÄÇÊ≠§Â§ñÔºåTXAAËøòËÉΩÂ§üÂØπÂ∏ß‰πãÈó¥ÁöÑÊï¥‰∏™Âú∫ÊôØËøõË°åÊäñÂä®ÈááÊ†∑Ôºå‰ª•ÂáèÂ∞ëÈó™ÁÉÅÊÉÖÂΩ¢ÔºàÊó∂Èó¥ÊÄßÈîØÈΩøÔºâ„ÄÇÁõÆÂâçÔºåTXAAÊúâ‰∏§ÁßçÊ®°ÂºèÔºöTXAA 2XÂíå TXAA 4X„ÄÇTXAA 2XÂèØÊèê‰æõÂ†™ÊØî8X MSAAÁöÑËßÜËßâ‰øùÁúüÂ∫¶ÔºåÁÑ∂ËÄåÊâÄÈúÄÊÄßËÉΩÂç¥‰∏é 2X MSAAÁõ∏Á±ª‰ººÔºõTXAA4XÁöÑÂõæÂÉè‰øùÁúüÂ∫¶ËÉúËøá8XMSAAÔºåÊâÄÈúÄÊÄßËÉΩ‰ªÖ‰ªÖ‰∏é4X MSAAÁõ∏ÂΩì„ÄÇ\n\n3. **Â§öÂ∏ßÈááÊ†∑ÊäóÈîØÈΩøÔºàMulti-Frame Sampled Anti-AliasingÔºåMFAAÔºâ**\n\n  Â§öÂ∏ßÈááÊ†∑ÊäóÈîØÈΩøÔºàMulti-Frame Sampled Anti-AliasingÔºåMFAAÔºâÊòØNVIDIAÂÖ¨Âè∏Ê†πÊçÆMSAA ÊîπËøõÂá∫ÁöÑ‰∏ÄÁßçÊäóÈîØÈΩøÊäÄÊúØ„ÄÇÁõÆÂâç‰ªÖÊê≠ËΩΩMaxwellÊû∂ÊûÑGPUÁöÑÊòæÂç°ÊâçËÉΩ‰ΩøÁî®„ÄÇÂèØ‰ª•Â∞ÜMFAAÁêÜËß£‰∏∫MSAAÁöÑ‰ºòÂåñÁâàÔºåËÉΩÂ§üÂú®ÂæóÂà∞Âá†‰πéÁõ∏ÂêåÊïàÊûúÁöÑÂêåÊó∂ÊèêÂçáÊÄßËÉΩ‰∏äÁöÑË°®Áé∞„ÄÇMFAA‰∏éMSAAÊúÄÂ§ßÁöÑÂ∑ÆÂà´Â∞±Âú®‰∫éÂú®ÂêåÊ†∑ÂºÄÂêØ4ÂÄçÊïàÊûúÁöÑÊó∂ÂÄôMSAAÊòØÁúüÊ≠£ÁöÑÈíàÂØπÊØè‰∏™ËæπÁºòÂÉèÁ¥†Âë®Âõ¥ÁöÑ 4 ‰∏™ÂÉèÁ¥†ËøõË°åÈááÊ†∑ÔºåMFAAÂàôÊòØ‰ªÖ‰ªÖÂè™ÊòØÈááÁî®‰∫§ÈîôÁöÑÊñπÂºèÈááÊ†∑ËæπÁºòÊüê‰∏™ÂÉèÁ¥†Âë®Âõ¥ÁöÑ‰∏§‰∏™ÂÉèÁ¥†„ÄÇ\n\nÂè¶‰∏ÄÁßçÂèØË°åÁöÑÊñπÊ°àËøòÊú™Ë¢´ÂπøÊ≥õÂ∫îÁî®Ôºö**Âú®Ê∏≤ÊüìÊó∂ËÆ∞ÂΩïÈ¢ùÂ§ñÁöÑÂá†‰Ωï‰ø°ÊÅØÔºå‰ª•‰æõÂêéÂ§ÑÁêÜÊäóÈîØÈΩø‰ΩøÁî®„ÄÇ**ÁõÆÂâçÁöÑÂÆûÁé∞ÊúâGPAA (Geometric Post-process Anti-Aliasing) ‰ª•ÂèäGBAA(Geometry Buffer Anti-Aliasing)Á≠â„ÄÇ\n\n## 2.2 Ë∂ÖÂàÜËæ®ÁéáÊäÄÊúØ\n\nÂõæÂÉèÂàÜËæ®Áéá‰ΩìÁé∞‰∫ÜÁ≥ªÁªüÂÆûÈôÖÊâÄËÉΩÂèçÊò†Áâ©‰ΩìÁªÜËäÇ‰ø°ÊÅØÁöÑËÉΩÂäõ„ÄÇÁõ∏ËæÉ‰∫é‰ΩéÂàÜËæ®ÁéáÂõæÂÉèÔºåÈ´òÂàÜËæ®ÁéáÂõæÂÉèÈÄöÂ∏∏ÂåÖÂê´Êõ¥Â§ßÁöÑÂÉèÁ¥†ÂØÜÂ∫¶„ÄÅÊõ¥‰∏∞ÂØåÁöÑÁ∫πÁêÜÁªÜËäÇÂèäÊõ¥È´òÁöÑÂèØ‰ø°ËµñÂ∫¶„ÄÇÁî±Ê≠§Ôºå‰ªéËΩØ‰ª∂ÂíåÁÆóÊ≥ïÁöÑËßíÂ∫¶ÁùÄÊâãÔºåÂÆûÁé∞ÂõæÂÉèË∂ÖÂàÜËæ®ÁéáÈáçÂª∫ÁöÑÊäÄÊúØÊàê‰∏∫‰∫ÜÂõæÂÉèÂ§ÑÁêÜÂíåËÆ°ÁÆóÊú∫ËßÜËßâÁ≠âÂ§ö‰∏™È¢ÜÂüüÁöÑÁÉ≠ÁÇπÁ†îÁ©∂ËØæÈ¢ò„ÄÇ\n\nÂõæÂÉèÁöÑË∂ÖÂàÜËæ®ÁéáÈáçÂª∫ÊäÄÊúØÊåáÁöÑÊòØÂ∞ÜÁªôÂÆöÁöÑ‰ΩéÂàÜËæ®ÁéáÂõæÂÉèÈÄöËøáÁâπÂÆöÁöÑÁÆóÊ≥ïÊÅ¢Â§çÊàêÁõ∏Â∫îÁöÑÈ´òÂàÜËæ®ÁéáÂõæÂÉè„ÄÇË∂ÖÂàÜËæ®ÁéáÊñπÊ≥ïÈÄöÂ∏∏ÂàÜ‰∏∫**ÂçïÂ∏ßË∂ÖÂàÜËæ®ÁéáÔºàSingle Image SuperresolutionÔºåSISRÔºâÂíåÂ§öÂ∏ßË∂ÖÂàÜËæ®ÁéáÔºàMulti-image SuperresolutionÔºåMISRÔºâ„ÄÅÊó∂ÂüüË∂ÖÈááÊ†∑ÔºàTemporal Super SamplingÔºâ**„ÄÇ\n\n### 2.2.1 ÂçïÂ∏ßË∂ÖÂàÜËæ®Áéá\n\nÂçïÂ∏ßË∂ÖÂàÜËæ®ÁéáÊòØÂíåDLSSÈùûÂ∏∏Áõ∏ÂÖ≥ÁöÑ‰∏Ä‰∏™Á†îÁ©∂ÊñπÂêë„ÄÇÂ∞§ÂÖ∂ÊòØË∑üÁùÄËøô‰∏§Âπ¥Ê∑±Â∫¶Â≠¶‰π†ÁöÑÂ∫îÁî®ÁöÑÁÉ≠Â∫¶ÔºåËøô‰∏™ÈóÆÈ¢òÁöÑstate of the art‰πüÊèêÈ´ò‰∫ÜÂæàÂ§öÔºåËøô‰∏™ÊñπÂêëÁöÑÁ†îÁ©∂‰πüÁªèÂ∏∏‰∏äÂõΩÂÜÖÂÖ¨‰ºóÂè∑ÁöÑÂ§¥Êù°Ôºå‰æãÂ¶ÇSRCNNÔºåSRGANÔºåESRGANÁ≠âÁ≠â„ÄÇ\n\nÂèØÊòØÂçïÂ∏ßË∂ÖÂàÜËæ®ÁéáÂÖ∂ÂÆûÊòØ‰∏™ÈùûÂ∏∏Âõ∞ÈöæÁöÑÈóÆÈ¢òÔºåÂõ†‰∏∫Êú¨Ë¥®‰∏äÈúÄË¶ÅÁîüÊàê‰ΩéÂàÜËæ®ÁéáÂõæÂÉè‰∏≠ÂÆåÂÖ®‰∏çÂ≠òÂú®ÁöÑ‰ø°ÊÅØ„ÄÇÁî®Á•ûÁªèÁΩëÁªúËß£ÂÜ≥Ëøô‰∏ÄÁ±ªÈóÆÈ¢òÔºå**Êú¨Ë¥®‰∏äÂ∞±ÊòØÂú®ËÆ≠ÁªÉÈõÜ‰∏≠Â≠¶‰π†Âà∞ÂêÑÁßç‰ΩéÂàÜËæ®ÁéáÁöÑÂÉèÁ¥†ÂíåÈ´òÂàÜËæ®ÁéáÂÉèÁ¥†ÁöÑ‰∏Ä‰∏™ÂØπÂ∫îÂÖ≥Á≥ª„ÄÇ**Êúâ‰∫ÜËøô‰∏™Êò†Â∞ÑÂêéÔºåÁ•ûÁªèÁΩëÁªúËÉΩÂÅöÂà∞ÊØî‰∏ÄËà¨ÁöÑÂü∫‰∫éÊèíÂÄºÔºàinterpolationÔºâÁöÑÊñπÊ≥ïÊõ¥Â•ΩÁöÑÊïàÊûú„ÄÇ\n\n<center>\n   <img style=\"border-radius: 0.3125em;\n   box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n   src=\"https://img-blog.csdnimg.cn/a89f7614853a4ff7aa2ecff3c609bc9b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_20,color_FFFFFF,t_70,g_se,x_16\">\n   <br><div style=\"color: #999;\">Âõæ 15 ÂçïÂ∏ßË∂ÖÂàÜËæ®Áéá</div></center> \n\n**‰ΩÜÂ∞ΩÁÆ°Â¶ÇÊ≠§ÔºåËøôÊ†∑ÁîüÊàêÂá∫Êù•ÁöÑ‰ø°ÊÅØÂÖ∂ÂÆûÊòØÂÆåÂÖ®Âü∫‰∫éËÆ≠ÁªÉÈõÜÂõæÁâá‰∏≠ÁöÑÊï∞ÊçÆÂàÜÂ∏ÉÔºåËÄåÂπ∂‰∏çÊòØÂØπÊàë‰ª¨ÂÆûÈôÖÊ≠£Âú®Ê∏≤ÊüìÁöÑÂú∫ÊôØÁöÑÈááÊ†∑„ÄÇ**ÊâÄ‰ª•ÂçïÂ∏ßË∂ÖÂàÜËæ®ÁéáÁöÑÁªìÊûúÁªèÂ∏∏‰ºöÂíåÂéüÁîüÂàÜËæ®ÁéáÊ∏≤ÊüìÂú®È£éÊ†ºÂíåÊ†∑Âºè‰∏ä‰∏ç‰∏ÄËá¥„ÄÇÂØπ‰∫éDLSSÊù•ËØ¥ÔºåÊàë‰ª¨ÁöÑÁõÆÊ†áÊòØÈáçÂª∫Âá∫ÂíåÈ´òÂàÜËæ®ÁéáÊ∏≤Êüì‰∏ÄÊ®°‰∏ÄÊ†∑ÁöÑÁªìÊûúÔºåÊâÄ‰ª•ÂçïÂ∏ßË∂ÖÂàÜËæ®Áéá‰∏ÄÁ±ªÁöÑÂ∑•‰ΩúÂØπÂÆûÊó∂Ê∏≤ÊüìÊù•ËØ¥ÂæàÈöæÈÄÇÁî®„ÄÇ\n\n### 2.2.2 Â§öÂ∏ßË∂ÖÂàÜËæ®Áéá\n\nÂè¶‰∏ÄÁ±ªË∂ÖÈááÊ†∑ÁöÑÂ∑•‰ΩúÂàôÊòØÈíàÂØπËßÜÈ¢ëÔºåÊàñËÄÖÊâãÊú∫ÊëÑÂΩ±ÁöÑÂ§öÂ∏ßË∂ÖÂàÜËæ®Áéá„ÄÇÂ§öÂ∏ßË∂ÖÂàÜËæ®ÁéáÂπ∂‰∏çÂÉèÂçïÂ∏ßË∂ÖÂàÜËæ®ÁéáÈÇ£‰πàÁöÑÂõ∞ÈöæÔºåÂõ†‰∏∫Êàë‰ª¨‰∏çÂÆåÂÖ®ÈúÄË¶ÅÂ°´Ë°•ÂéüÊú¨‰∏çÂ≠òÂú®ÁöÑ‰ø°ÊÅØ„ÄÇÊúâÂ§ö‰∏™‰ΩéÂàÜËæ®ÁéáÂõæÁâáÁöÑÊÉÖÂÜµ‰∏ãÔºåËøô‰∏™ÈóÆÈ¢ò‰ºöÂèØÊéßÂæàÂ§öÔºåÂ§öÂ∏ßÂêàÊàêÁöÑÈ´òÂàÜËæ®ÁéáÂõæÁâáÂæÄÂæÄÂú®ÂÖâÂ≠¶ÁªÜËäÇ‰∏äÁöÑËøòÂéüÁöÑË¥®Èáè‰∏ä‰ºöÊØîÂçïÂ∏ßË∂ÖÂàÜËæ®ÁéáÁöÑÈ´òËÆ∏Â§ö„ÄÇ\n\nÁÑ∂ËÄåÈíàÂØπËßÜÈ¢ëÊàñËÄÖÊëÑÂΩ±ÁöÑÁÆóÊ≥ï‰πüÂπ∂‰∏çÂ§™ËÉΩÁõ¥Êé•Êê¨ËøáÊù•Áî®‰∫éÂÆûÊó∂Ê∏≤ÊüìÔºåÂéüÂõ†ÊúâËÆ∏Â§ö„ÄÇ\n\n1. Âú®Ê∏≤Êüì‰∏≠ÔºåÊàë‰ª¨ÂèØ‰ª•Áî®Âà∞ÁöÑÊï∞ÊçÆÊòØÊØîËßÜÈ¢ëÂ§öÂæàÂ§öÁöÑÔºåÊàë‰ª¨ÂèØ‰ª•ËÆ°ÁÆóÊØè‰∏™ÂÉèÁ¥†Á≤æÁ°ÆÁöÑËøêÂä®ÂêëÈáèÔºåÊàë‰ª¨‰πüÂèØ‰ª•ÊúâÂú∫ÊôØÂáΩÊï∞ÁöÑÁ≤æÁ°ÆÈááÊ†∑ÔºåÊúâHDRÈ¢úËâ≤ÔºåÁîöËá≥ÂÉèÁ¥†ÁöÑÁ≤æÁ°ÆÊ∑±Â∫¶„ÄÇ**‰∏çÂà©Áî®Ëøô‰∫õ‰ø°ÊÅØÔºåËÆæËÆ°Âá∫Êù•ÁöÑÁÆóÊ≥ïÂú®ÊïàÁéáÂíåË¥®Èáè‰∏äÈÉΩ‰∏ç‰ºöÊòØÊúÄ‰ºòÁöÑ„ÄÇ**\n\n2. ËÆ∏Â§öËßÜÈ¢ëË∂ÖÂàÜËæ®ÁéáÁöÑÂ∑•‰ΩúÊòØÈúÄË¶Å**Áî®Êó∂Â∫è‰∏äÊú™Êù•ÁöÑÂõæÁâáÊù•ÈáçÂª∫ÂΩìÂâçÂ∏ßÁöÑÂõæÁâáÁöÑ**„ÄÇÂõ†‰∏∫ÂÆûÊó∂Ê∏≤ÊüìÂØπÂª∂ËøüÁöÑË¶ÅÊ±ÇÔºåËøô‰πüÊòæÁÑ∂‰∏çÈÄÇÁî®„ÄÇ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/c7ba067031a4440baefb6e0d02c61e5e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_20,color_FFFFFF,t_70,g_se,x_16\">\n    <br><div style=\"color: #999;\">Âõæ 16 Â§öÂ∏ßË∂ÖÂàÜËæ®Áéá</div></center> \n\n### 2.2.3 Êó∂ÂüüË∂ÖÈááÊ†∑\n\nÂà©Áî®ÊääÊ∏≤ÊüìÁöÑÊ†∑Êú¨ÂàÜÂ∏ÉÂú®Â§ö‰∏™Â∏ß‰∏äÔºåÂπ∂‰∏îÁî®Ëøô‰∫õÂ§öÂ∏ßÂ§çÂêàÁöÑÊ†∑Êú¨ÈáçÂª∫Âá∫ÊúÄÁªàÊ∏≤ÊüìÁöÑÂõæÁâáÔºåËøôÂú®ÂÆûÊó∂Ê∏≤ÊüìÈ¢ÜÂüüÂ§™Âè∏Á©∫ËßÅÊÉØ‰∫Ü„ÄÇÂá†‰πéÊâÄÊúâÂºïÊìéÈÉΩÂú®Áî®ÁöÑTemporal Antialiasing(TAA)ÔºåÊàñËÄÖÊ∏∏Êàè‰∏ªÊú∫‰∏äÈùûÂ∏∏ÊµÅË°åÁöÑCheckerboard RenderingÈÉΩÊòØËøô‰πà‰∏Ä‰∏™ÊÄùË∑Ø„ÄÇ\n\n<center>\n   <img style=\"border-radius: 0.3125em;\n   box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n   src=\"https://img-blog.csdnimg.cn/3dae0dd648e44c07b6eeaa4da296d74f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_20,color_FFFFFF,t_70,g_se,x_16\">\n   <br><div style=\"color: #999;\"> Âõæ 17 Ê£ãÁõòÊ∏≤Êüì</div>\n</center> \n\nËøô‰∏ÄÁ±ªÁÆóÊ≥ïÂà©Áî®‰∫ÜÊ∏≤ÊüìÂõæÁâáÁöÑ**Êó∂ÂüüËøûË¥ØÊÄßÔºàTemporal coherencyÔºâ**ÔºåÊó¢Ê∏≤ÊüìÁªìÊûúÁöÑÂ∏ß‰∏éÂ∏ß‰πãÈó¥Â§ß‰ΩìÊòØËøûÁª≠ÁöÑÔºåÂèëÁîüÈ´òÈ¢ëÂèòÂåñÁöÑÊ¶ÇÁéá‰∏çÈ´ò„ÄÇ‰πüÂ∞±ÊòØËØ¥ÔºåÊàë‰ª¨ÂèØ‰ª•ÂÅáËÆæÈúÄË¶ÅÊ∏≤ÊüìÁöÑÂú∫ÊôØÂú®‰∏ä‰∏ÄÂ∏ßÂíåÂΩìÂâçÂ∏ßÂá†‰πé‰∏ÄÊ†∑„ÄÇÂ¶ÇÊûúËøô‰∏™ÂÅáËÆæÊàêÁ´ãÁöÑËØùÔºåÊàë‰ª¨Â§ßÂèØ‰ª•‰πãÈó¥Â§çÁî®ËøáÂéªÂ∏ß‰∏äÂØπÂú∫ÊôØÈááÊ†∑ÁöÑÊ†∑Êú¨Êù•ÈáçÂª∫ÂΩìÂâçÂ∏ß„ÄÇ\n\n<center>\n   <img style=\"border-radius: 0.3125em;\n   box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n   src=\"https://img-blog.csdnimg.cn/50ae89e4ff2f4e0d86364167110377af.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_17,color_FFFFFF,t_70,g_se,x_16\">\n   <br><div style=\"color: #999;\">Âõæ 18 TAA</div>\n</center> \n\nËøôÊ†∑ÂÅöÁöÑÂ•ΩÂ§ÑÊòØÔºåÊØè‰∏ÄÂ∏ßÁöÑÈááÊ†∑ÁéáÈùûÂ∏∏‰ΩéÔºåÊâÄ‰ª•Ê∏≤ÊüìÊÄßËÉΩ‰ºöÊúâÂæàÂ§ßÁöÑÊèêÂçáÔºåÁÑ∂ËÄåÈáçÂª∫ÂõæÂÉèÊó∂ÁöÑÊ†∑Êú¨ËøòÈÉΩÁ°ÆÂÆûÊòØÂØπ‰∫éÂú∫ÊôØÂáΩÊï∞ÁöÑÊó†ÂÅèÈááÊ†∑ÔºåÊâÄ‰ª•ÊúÄÁªàÈáçÂª∫ÁöÑÂõæÂÉèË¥®Èáè‰πü‰ºöÂíåÂéüÁîüÂàÜËæ®ÁéáÊ∏≤ÊüìÈùûÂ∏∏‰∏ÄËá¥„ÄÇ\n\nÁÑ∂ËÄåÂ§©‰∏ãÂì™ÊúâËøôÁ≠âÂ•Ω‰∫ãÔºåÂÆûÊó∂Ê∏≤ÊüìÊàñËÄÖÊ∏∏ÊàèÁöÑÂõæÁâáÂ∫èÂàó‰∏≠Âá†‰πéÊØè‰∏ÄÂ∏ßÈÉΩÊúâÊàñÂ§öÊàñÂ∞ëÁöÑÂèòÂåñÔºå‰ªéËßíËâ≤Âä®ÁîªÔºåÂà∞Âä®ÊÄÅÂÖâÂΩ±ÔºåÂà∞Á≤íÂ≠êÁâπÊïà„ÄÇÁõ¥Êé•Â§çÁî®ËøáÂéªÂ∏ßÁöÑÊ†∑Êú¨Êù•ÈáçÂª∫ÂΩìÂâçÂ∏ßÁöÑÂõæÁâá‰ºö‰ΩøÈáçÂª∫ÁöÑÁªìÊûú‰∏≠‰∫ßÁîüÂæàÂ§ßÁöÑÈîôËØØ„ÄÇ**ËøôÁßçÈîôËØØÂú®Ê∏≤ÊüìÂõæÁâá‰∏≠‰ºö‰ª•Âª∂ËøüÔºåÊàñËÄÖÈ¨ºÂΩ±ÔºàghostingÔºâÁöÑÂΩ¢ÂºèÂëàÁé∞Âá∫Êù•„ÄÇ**Ëøô‰πüÊòØ‰∏∫‰ªÄ‰πàÔºåÊâÄÊúâÂÆûÊó∂Ê∏≤Êüì‰∏≠ÁöÑÊó∂ÂüüË∂ÖÈááÊ†∑ÁÆóÊ≥ïÔºå‰æãÂ¶ÇTAAÔºåÈÉΩÊúâÈùûÂ∏∏ÈáçË¶ÅÁöÑ‰∏ÄÊ≠•Âéª‚ÄúÁ∫†Ê≠£‚ÄùËøáÂéªÂ∏ß‰∏≠Ê†∑Êú¨ÁöÑÈîôËØØ„ÄÇ\n\n<center>\n   <img style=\"border-radius: 0.3125em;\n   box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n   src=\"https://img-blog.csdnimg.cn/8395216147f04632a142ba5f02cfcb52.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_14,color_FFFFFF,t_70,g_se,x_16\">\n   <br><div style=\"color: #999;\">Âõæ 19 È¨ºÂΩ±Áé∞Ë±°</div>\n</center> \n\nËøô‰∏ÄÁ±ªÁÆóÊ≥ïÈúÄË¶ÅÈ¶ñÂÖàÊ£ÄÊµãËøáÂéªÂ∏ßÂíåÂΩìÂâçÂ∏ßÂõ†‰∏∫Âú∫ÊôØÁöÑÂèòÂåñÂØºËá¥ÁöÑÊ†∑Êú¨ÈîôËØØÔºåÁÑ∂ÂêéÂú®‰∏çÂΩ±ÂìçÁîªË¥®Â§™Â§öÁöÑÊÉÖÂÜµ‰∏ãÔºå‚ÄúÂêàÁêÜ‚ÄùÁöÑÁ∫†Ê≠£ÈÇ£‰∫õÈîôËØØÁöÑÊ†∑Êú¨„ÄÇ‰πç‰∏ÄÁúãËøôÁÆÄÁõ¥ÊòØ‰∏™ËÆ°ÁÆóÊú∫ËßÜËßâÈóÆÈ¢òÔºåÁÑ∂ËÄåÂú®ÂÆûÊó∂Ê∏≤Êüì‰∏≠Ëøô‰∏ÄÊ≠•ÈúÄË¶ÅÈùûÂ∏∏È´òÊïàÁöÑÂÆåÊàê„ÄÇÊâÄ‰ª•ËøáÂéªÂçÅÂá†Âπ¥ÔºåÊ∏∏ÊàèÂºÄÂèëËÄÖÁªûÂ∞ΩËÑëÊ±ÅÁöÑÂèëÊòé‰∫ÜÂêÑÁßç**‚ÄúÂêØÂèëÂºè‚ÄùÁöÑÊñπÊ≥ïÔºàHeuristicsÔºâ**„ÄÇ\n\nÁõÆÂâçËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÊïàÊûúÊúÄÂ•ΩÔºå‰πüÊúÄÂ∏∏Áî®ÁöÑHeuristicÔºåÂè´ÂÅö**Neighborhood Clamping**ÔºåÊòØEpicÁöÑBrian KarisÂú®14Âπ¥ÁöÑSIGGRAPHÁöÑ‰∏Ä‰∏™ÂÆûÊó∂Ê∏≤ÊüìËÆ≤Â∫ßÈáåÊúÄÂÖàÊèêÂà∞ÁöÑ„ÄÇÊÄùË∑ØÂÖ∂ÂÆûÂæàÁÆÄÂçïÔºåÂ∞±ÊòØÊääËøáÂéªÂ∏ßÈááÊ†∑ÁöÑÊ†∑Êú¨ÁöÑÂÄºÁöÑËåÉÂõ¥ÔºåÈôêÂà∂Âú®ÂΩìÂâçÂ∏ßÂÉèÁ¥†Âë®Âõ¥3x3Â§ßÂ∞èÁöÑLocal neighborhoodÁöÑÊâÄÊúâÊ†∑Êú¨ÁöÑÂÄºÁöÑËåÉÂõ¥ÂÜÖ„ÄÇ\n\n# **3 DLSS 2.0ÊäÄÊúØ‰ªãÁªç**\n\n## 3.1 DLSS 2.0ÂéüÁêÜ‰∏éÊÄùË∑Ø\n\nDLSS 2.0È¶ñÂÖà‰πüÊòØ‰∏Ä‰∏™Âü∫‰∫éÂ§öÂ∏ßÁöÑÂõæÂÉèÈáçÂª∫ÊäÄÊúØ„ÄÇÂõ†‰∏∫Êàë‰ª¨ÁöÑÁõÆÊ†áÊòØÈáçÂª∫Âá∫ÂíåÂéüÁîüÊ∏≤Êüì‰∏ÄËá¥ÁöÑÁîªÈù¢ÔºåÊâÄ‰ª•Âü∫‰∫éÁî®ÂçïÂ∏ßÁöÑÁÆóÊ≥ïÂéª‚ÄúÊÉ≥Ë±°‚Äù‰∏çÂ≠òÂú®ÁöÑ‰ø°ÊÅØÊòØ‰∏çÈÄÇÁî®ÁöÑ„ÄÇ\n\nÈÇ£DLSS 2.0ÂíåÁé∞ÊúâÁöÑÂÆûÊó∂Ê∏≤Êüì‰∏≠ÁöÑÊó∂ÂüüË∂ÖÈááÊ†∑Êúâ‰ªÄ‰πàÂå∫Âà´Âë¢ÔºüDLSS 2.0ÊäõÂºÉ‰∫Ü‰∫∫ËÇâÊâãË∞ÉÁöÑÂêØÂèëÂºèÁÆóÊ≥ïÔºåÁî®‰∏Ä‰∏™Âú®Ë∂ÖÁ∫ßËÆ°ÁÆóÊú∫‰∏äÊï∞‰∏áÂº†Ë∂ÖÈ´òË¥®ÈáèÂõæÁâáËÆ≠ÁªÉÁöÑÁ•ûÁªèÁΩëÁªúÊù•‰ª£ÊõøËøô‰∫õHeuristics„ÄÇÂ∞±ÂÉèÊ∑±Â∫¶Â≠¶‰π†Âú®Âá†Âπ¥ÂâçÂú®ËÆ°ÁÆóÊú∫ËßÜËßâÈ¢ÜÂüüË∂ÖË∂ä‰∫ÜÂêÑÁßçÊâãË∞ÉÁöÑÁâπÂæÅÊèêÂèñÁÆóÊ≥ï‰∏ÄÊ†∑ÔºåÊ∑±Â∫¶Â≠¶‰π†Á¨¨‰∏ÄÊ¨°Âú®ÂÆûÊó∂Ê∏≤Êüì‰∏≠‰πüÈùûÂ∏∏ÂêàÁêÜÁöÑË∑ëËµ¢‰∫ÜÂõæÂΩ¢È¢ÜÂüüÁöÑÊâãË∞ÉÁÆóÊ≥ï„ÄÇ\n\nÁî®DLSS 2.0ÈáçÂª∫ÁöÑÊ∏≤ÊüìÂõæÂÉèÂ∫èÂàóËææÂà∞‰∫ÜÈùûÂ∏∏È´òÁöÑÂ§öÂ∏ßÊ†∑Êú¨Âà©Áî®ÁéáÔºåËøô‰πüÊòØ‰∏∫‰ªÄ‰πàÂè™Áî®ÂõõÂàÜ‰πã‰∏ÄÁöÑÊ†∑Êú¨Â∞±ÂèØ‰ª•ÈáçÂª∫Âá∫Â™≤ÁæéÂéüÁîüÂàÜËæ®ÁéáÊ∏≤ÊüìÁöÑÂõæÂÉèË¥®ÈáèÁöÑÂéüÂõ†„ÄÇ\n\n<center>\n   <img style=\"border-radius: 0.3125em;\n   box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n   src=\"https://img-blog.csdnimg.cn/02404b8cfec84daab16a1f45208ebbd8.png\">\n   <br><div style=\"color: #999;\">Âõæ 20 DLSSÈáçÂª∫ÊñπÊ≥ï</div>\n</center> \n\n‰∏ãÂõæÊòØDLSS 2.0ÁöÑÁ≤óÁï•Êû∂ÊûÑÔºö\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/cbb1df0e4c1c4ce1a9eef04f984b5a88.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_20,color_FFFFFF,t_70,g_se,x_16\">\n    <br><div style=\"color: #999;\">Âõæ 21 DLSS 2.0Êû∂ÊûÑÂõæ</div></center> \n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/ea9e3becdfcc4a36aab12011303e20c4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_17,color_FFFFFF,t_70,g_se,x_16\">\n    <br><div style=\"color: #999;\">Âõæ 22 DLSS 2.0 Á•ûÁªèÁΩëÁªú ËæìÂÖ•ÂèäËæìÂá∫</div></center> \n\n\n## 3.2 DLSS 2.0ÂºïÊìéÈõÜÊàê\n\nDLSS 2.0Âπ∂‰∏çÊòØ‰∏Ä‰∏™ÂçïÁ∫ØÁöÑÂõæÂÉèË∂ÖÂàÜËæ®ÁéáÁÆóÊ≥ï„ÄÇÂÆÉÊòØ‰∏Ä‰∏™‰∏ìÈó®ÈíàÂØπÂÆûÊó∂Ê∏≤ÊüìÂ∫îÁî®ÁöÑÁÆóÊ≥ï„ÄÇÊâÄ‰ª•ÂºïÊìéË¶ÅÈõÜÊàêDLSS 2.0ÔºåÈúÄË¶ÅÈÖçÂêàÁöÑ‰ΩúÂá∫Áõ∏Â∫îÁöÑÊîπÂä®„ÄÇ‰ΩÜÊâÄÂπ∏ÊîπÂä®ÁöÑÂπÖÂ∫¶ËøúÊØîÁ±ª‰ººCheckerboard renderingÁÆÄÂçï„ÄÇ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/d9402c34f41d477583a316ff71201788.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_20,color_FFFFFF,t_70,g_se,x_16\">\n    <br><div style=\"color: #999;\">Âõæ 23 DLSSÂºïÊìéÈõÜÊàê</div></center> \n\n\n**È¶ñÂÖàÂΩìÁÑ∂ÊòØÂºïÊìéË¶ÅÊääÊâÄÊúâÁöÑÂÉèÁ¥†ÁùÄËâ≤Â∑•‰ΩúÂú®‰ΩéÂàÜËæ®ÁéáÊâßË°åÔºå**ÈÄöÂ∏∏Ëøô‰∫õÂåÖÊã¨GBufferÊ∏≤ÊüìÔºåÂä®ÊÄÅÂÖâÂΩ±ÔºåÂ±èÂπïÁâπÊïàÔºåÂÖâÁ∫øËøΩË∏™Á≠â„ÄÇ\n\n**ÂÖ∂Ê¨°ÔºåDLSS 2.0ÊòØ‰∏Ä‰∏™ËûçÂêà‰∫ÜÊäóÈîØÈΩøÂíåË∂ÖÈááÊ†∑ÁöÑÁÆóÊ≥ï**„ÄÇÂºïÊìéÁé∞ÊúâÁöÑÊäóÈîØÈΩøËß£ÂÜ≥ÊñπÊ°à‰æãÂ¶ÇTAAÈúÄË¶ÅË¢´ÁßªÈô§ÔºåÁÑ∂ÂêéDLSSÈúÄË¶ÅË¢´ÊèíÂÖ•Âú®ÂêéÂ§ÑÁêÜÔºàpost processingÔºâ‰πãÂâçÔºåËøôÊ†∑ÂêéÂ§ÑÁêÜÂèØ‰ª•Â§ÑÁêÜÊäóÈîØÈΩøÂêéÁöÑÂπ≥ÊªëÂõæÁâá‰ª•ÈÅøÂÖçÂêÑÁßçartifact„ÄÇ\n\nDLSSÁöÑËæìÂá∫‰ºöÊòØ‰∏Ä‰∏™È´òÂàÜËæ®ÁéáÁöÑÂõæÁâáÔºåÊâÄ‰ª•**ÂºïÊìéÈúÄË¶ÅË∂ÖÈááÊ†∑ÂêéÁöÑÂàÜËæ®Áéá‰∏ãËÆ°ÁÆóÂêÑÁßçÂêéÂ§ÑÁêÜÁâπÊïà**Ôºå‰æãÂ¶ÇÊôØÊ∑±ÔºåÂä®ÊÄÅÊ®°Á≥äÔºåtonemapping‰ª•ÂèäÊ∏≤ÊüìUI„ÄÇ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/da4bfb6c94204f45bf40e13979f0e309.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_18,color_FFFFFF,t_70,g_se,x_16\">\n    <br><div style=\"color: #999;\">Âõæ 24 DLSS 2.0 Ê∏≤ÊüìÊ≠•È™§</div></center> \n\n## 3.3 DLSS 2.0Ê∏≤ÊüìÂä†ÈÄü\n\nDLSS 2.0Âä†ÈÄüÊ∏≤ÊüìÁöÑÂéüÁêÜÂæàÁÆÄÂçï„ÄÇÂºÄÂêØDLSSÂêéÔºåÂºïÊìéÁöÑÊ∏≤Êüì‰ºöÂú®1/2Âà∞1/4ÂÉèÁ¥†ÁöÑ‰ΩéÂàÜËæ®Áéá‰∏ãËøêË°å„ÄÇËøôÊÑèÂë≥ÁùÄÔºå‰∏ÄÂ§ßÂçäÁöÑÂÉèÁ¥†Á∫ßÂà´ÁöÑËÆ°ÁÆóÁõ¥Êé•Ë¢´Á≤óÊö¥ÁöÑÁ†çÊéâ‰∫Ü„ÄÇÂÉèÁ¥†Á∫ßÂà´ÁöÑËÆ°ÁÆóÈÄöÂ∏∏ÂåÖÊã¨GBufferÁöÑÊ∏≤ÊüìÔºåÂä®ÊÄÅÂÖâÊ∫ê„ÄÅÈò¥ÂΩ±ÁöÑËÆ°ÁÆóÔºåÂ±èÂπïÁ©∫Èó¥ÁöÑÁâπÊïà‰æãÂ¶ÇÂ±èÂπïÁ©∫Èó¥ÁéØÂ¢ÉÈÅÆÊå°ÔºàSSAOÔºâ„ÄÅÂ±èÂπïÁ©∫Èó¥ÂèçÂ∞ÑÔºàSSRÔºâÔºåÁîöËá≥ÂÆûÊó∂ÂÖâÁ∫øËøΩË∏™„ÄÇËøô‰∫õËÆ°ÁÆóÈÄöÂ∏∏‰πüÊòØ‰∏ÄÂ∏ßÈáåÈù¢ÊúÄËÄóË¥πÊÄßËÉΩÁöÑÈÉ®ÂàÜ„ÄÅÊØïÁ´üÂ§ßÈÉ®ÂàÜÁöÑÁîªÈù¢Âá∫Ëâ≤ÁöÑÊ∏∏ÊàèÔºåÂÉèÁ¥†ËÆ°ÁÆóÊòØÁªùÂØπÁöÑÁì∂È¢àÔºàpixel boundÔºâ„ÄÇ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/fc5f475f3afa49e6b7a553aa3b5f58c1.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_20,color_FFFFFF,t_70,g_se,x_16\">\n    <br><div style=\"color: #999;\"> Âõæ 25 DLSS Ê∏≤ÊüìÂä†ÈÄü</div></center> \n\n\nÊâÄ‰ª•DLSS 2.0ÁöÑÂä†ÈÄüÂ§öÂ∞ëÔºå‰πü**Áõ¥Êé•ÂèñÂÜ≥‰∫éÂÉèÁ¥†ËÆ°ÁÆóÂú®Â§öÂ§ßÁ®ãÂ∫¶‰∏äÊòØÊÄßËÉΩÁì∂È¢à„ÄÇ**ÈÄöÂ∏∏Êù•ËØ¥ÔºåÁîªÈù¢Ë∂äÂ•ΩÁöÑ3AÂ§ß‰ΩúÔºåË∂ä‰ºöÁî®Êõ¥Âä†ËÄóË¥πÊÄßËÉΩÁöÑÊ∏≤ÊüìÊäÄÊúØÔºåÂÉèÁ¥†‰πüÂ∞±‰ºöÊõ¥Â§ßÁ®ãÂ∫¶ÁöÑÊàê‰∏∫Áì∂È¢àÔºåËÄåDLSSÂàô‰ºöÊèê‰æõÊõ¥Â§ßÁöÑÂä†ÈÄüÔºÅ\n\nÂú®ÁúÅÊéâÁöÑÊ∏≤ÊüìËÆ°ÁÆó‰πã‰∏äÔºåËøêË°åDLSS 2.0Ëøô‰∏™ÁÆóÊ≥ïÊú¨Ë∫´‰ºöÂºïÂÖ•‰∏ÄÂÆöÁöÑÂºÄÈîÄÔºåËøô‰∏™ÂºÄÈîÄÈÄöÂ∏∏ÊòØÂÆåÂÖ®ÂèñÂÜ≥‰∫éÂàÜËæ®ÁéáÂ§ßÂ∞èÁöÑÔºå‰∏çÈöèÂú∫ÊôØÂÜÖÂÆπËÄåÊîπÂèò„ÄÇ‰∏ãÈù¢Ëøô‰∏™Ë°®Ê†ºÂ±ïÁ§∫‰∫ÜDLSS 2.0Âú®‰∏çÂêåGPUÂíå‰∏çÂêåÂàÜËæ®Áéá‰∏ãÁöÑÂºÄÈîÄ„ÄÇÁõ∏ÊØî‰∫éDLSS 1.0ÔºåÊàë‰ª¨ÊääËøô‰∏™ÂºÄÈîÄÂáèÂ∞è‰∫Ü‰∏§ÂÄç‰ª•‰∏ä„ÄÇÂú®2080Ti‰∏äÔºå4KÂàÜËæ®Áéá‰∏ã‰πüÂè™Êúâ1.5ÊØ´ÁßíÔºåÂõ†‰∏∫ÊúâTensor CoreÁöÑÂä†ÈÄüÔºåËøôÂ∑≤ÁªèÂíåÊôÆÈÄöÁöÑTAAÈùûÂ∏∏Êé•Ëøë‰∫Ü„ÄÇ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/1a58dfc0348741b0861f2ebbec493c72.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_20,color_FFFFFF,t_70,g_se,x_16\">\n    <br><div style=\"color: #999;\">Âõæ 26 DLSS cost</div></center> \n\n# **4 DLSSÊåëÊàò‰∏éÊÄªÁªì**\n\n## 4.1 DLSSÊïàÊûúÂØπÊØî\n\nDLSS 2.0ÂèØ‰ª•Â∞Ü540pÁöÑÊ∏≤ÊüìÂõæÂÉèÁõ¥Êé•ÊîæÂ§ßÂà∞1080pÔºåÊàñËÄÖ720pÂà∞1440pÔºå1080pÂà∞4K„ÄÇÂπ∂‰∏îÊîæÂ§ßÁöÑÁîªÈù¢Âú®Ë¥®Èáè‰ª•ÂèäÁªÜËäÇÁ®ãÂ∫¶ÂÆåÂÖ®‰∏çËæìÂéüÁîüÂàÜËæ®ÁéáÊ∏≤ÊüìÔºåÁΩë‰∏äÁöÑËÆ∏Â§öÊµãËØÑ‰πüÈÉΩÂèçÊò†‰∫ÜËøô‰∏ÄÁÇπ„ÄÇ\n\n‰∏ãÈù¢ÊîæÂá†ÁªÑ‰æãÂ≠êÔºåÁ¨¨‰∏Ä‰∏™ÊòØ‰∏Ä‰∏™Âá†‰ΩïÈùûÂ∏∏ÂØÜÈõÜÁöÑÊ£ÆÊûóÂú∫ÊôØÔºåÂºÄÂêØÂÆûÊó∂ÂÖâÁ∫øËøΩË∏™Âêé540pÂéüÁîüÂàÜËæ®ÁéáÊ∏≤ÊüìÂ§ßÊ¶ÇÊúâ89fpsÔºå‰ΩÜÊòØÂõ†‰∏∫ÂàÜËæ®ÁéáÂ§™‰ΩéÔºåÁîªÈù¢ÈùûÂ∏∏Ê®°Á≥ä„ÄÇ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/b571906c1f2a4e6c895085427ef1cae0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_14,color_FFFFFF,t_70,g_se,x_16\">\n    <br><div style=\"color: #999;\"> Âõæ 27 540p - 89fpsÂéüÁîüÊ∏≤ÊüìÊïàÊûúÂõæ</div></center> \n\nÂ¶ÇÊûú1080pÊ∏≤ÊüìÔºåÁîªÈù¢ÂàôÊ∏ÖÊô∞‰∫ÜÂæàÂ§öÔºå‰ΩÜÊòØÂ∏ßÁéá‰πüÈôç‰ΩéÂà∞48fps\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/df3b877917694856b7f2ef7a16362116.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_14,color_FFFFFF,t_70,g_se,x_16\">\n    <br><div style=\"color: #999;\">Âõæ 28 1080p ‚Äì 48fpsÂéüÁîüÊ∏≤ÊüìÊïàÊûúÂõæ</div></center> \n\n‰ΩøÁî®DLSS2.0, Áî®540pÂàÜËæ®ÁéáÊ∏≤ÊüìÁöÑÁîªÈù¢‰Ωú‰∏∫ËæìÂÖ•ÔºåÈÄöËøáÊ∑±Â∫¶Â≠¶‰π†Ë∂ÖÈááÊ†∑Ëá≥1080pÔºåÂ∏ßÁéáÊèêÂçáÂà∞86fpsÔºåÂπ∂‰∏îÁîªË¥®ÂíåÂéüÁîüÂçÅÂàÜÊé•Ëøë„ÄÇ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/8b12156c24f64cd69ead4edacf8a299e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_14,color_FFFFFF,t_70,g_se,x_16\">\n    <br><div style=\"color: #999;\">Âõæ 29 DLSS 2.0Ôºå540pÊ∏≤ÊüìËæìÂÖ•Ë∂ÖÈááÊ†∑Ëá≥1080pÔºå86fps</div></center> \n\n‰ΩÜÂ¶ÇÊûúÊîæÂ§ßÁúãÁöÑËØùÔºåÂèØ‰ª•ÂèëÁé∞DLSS2.0ÁöÑÁªìÊûúÂíåÂéüÁîü1080pËøòÊòØÊúâ‰∏Ä‰∫õÂ∑ÆÂà´ÔºåÈÇ£‰πà‰∏∫‰∫ÜÈ™åËØÅÊ≠£Á°ÆÊÄßÔºå‰∏ãÈù¢Ëøô‰∏™ÂØπÊØîÁöÑÂ∑¶‰∏ãËßíÊòØÊØè‰∏™ÂÉèÁ¥†Áî®32‰∏™Ê†∑Êú¨Ê∏≤ÊüìÁöÑground truth„ÄÇÂæàÊòéÊòæDLSS 2.0Áî®Âú®540p‰∏ãÊ∏≤ÊüìÁöÑÁªìÊûúÔºåÊØî1080pÁöÑÂéüÁîüÊ∏≤ÊüìÊõ¥Êé•Ëøëground truthÔºÅ\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/b7e0d43a924e45fe91b6bbb6810a381c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_17,color_FFFFFF,t_70,g_se,x_16\">\n    <br><div style=\"color: #999;\">Âõæ 30 200%ÂØπÊØî</div></center> \n\n## 4.2 DLSS 2.0ÁöÑ‰ºòÁº∫ÁÇπ\n\n### 4.2.1  DLSS 2.0 ÂõõÂ§ßÁâπÊÄß\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/a743d2987f5f431e84c11123fceaf66a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_20,color_FFFFFF,t_70,g_se,x_16\">\n    <br><div style=\"color: #999;\">Âõæ 31 DLSS 2.0ÂõõÂ§ßÁâπÊÄß</div></center>\n\n1. ÁîªË¥®ÊûÅÂ§ßÊèêÂçáÔºåÁªÜËäÇÂíåÈîêÂ∫¶Â™≤Áæé„ÄÅÁîöËá≥Ë∂ÖË∂äÂéüÁîüÂàÜËæ®Áéá\n2. 4ÂÄçÂÉèÁ¥†Ë∂ÖÈááÊ†∑Ôºà540pÂà∞1080pÔºå1080pÂà∞4KÔºåÊØè4‰∏™ÂÉèÁ¥†‰∏≠Êúâ3‰∏™ÊòØÈÄöËøáË∂ÖÈááÊ†∑ÁîüÊàêÔºâ\n3. ÈÄöÁî®Ê®°ÂûãÔºå‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÈÄÇÁî®‰∫éÊâÄÊúâÊ∏∏ÊàèÔºà‰∏çÂêåÂºïÊìéÔºåÁùÄËâ≤È£éÊ†ºÔºåÂàÜËæ®ÁéáÈÉΩÊúâÂæàÂº∫ÁöÑÈÄöÁî®ÊÄßÔºâ\n4. InferenceÂºÄÈîÄÂáèÂçä\n\n### 4.2.2 DLSSÁº∫ÁÇπ\n\n1. DLSS‰ºº‰πé‰∏çËÉΩÂæàÂ•ΩÂú∞‰∏éÊüê‰∫õAAÊäÄÊúØ(Â¶ÇTSAA)‰∏ÄËµ∑Â∑•‰ΩúÔºåÂΩìÂêØÁî®Ëøô‰∫õÊäÄÊúØÊó∂ÔºåDLSSÊÄßËÉΩ‰ºöÂèóÂà∞‰∏•ÈáçÂΩ±Âìç„ÄÇ\n2. Ê≠§Â§ñÔºåÁî±‰∫éDLSSÂè™ËÉΩÂ∑•‰ΩúÂú®Âº†ÈáèÊ†∏ÁöÑGPU‰∏äÔºåÊâÄ‰ª•CUDA-onlyÂíåStreamÂ§ÑÁêÜÂô®ÁöÑgpu‰∏çËÉΩÂÆûÁé∞DLSS„ÄÇ\n\n## 4.2.3 DLSSÊäÄÊúØÁöÑÂ±ïÊúõ\n\n1. **Êõ¥ÁÆÄÂçïÁöÑ SR ÁΩëÁªúÊû∂ÊûÑ**\n\nËôΩÁÑ∂ DLSR Ê®°ÂûãÂú®ÂõæÂÉèÈáçÂª∫ÊñπÈù¢ÂèñÂæó‰∫ÜÂæàÈ´òÁöÑÂáÜÁ°ÆÁéáÂíå‰øùÁúüÂ∫¶Ôºå‰ΩÜÂú®Êú¨Âú∞ÈÉ®ÁΩ≤‰ªçÁÑ∂ÊòØÊûÅÂÖ∂Âõ∞Èöæ‰∏îËÄóÊó∂ÁöÑ„ÄÇÁî±‰∫éÊã•ÊúâÂ§ßÈáèÁöÑËÆ°ÁÆóÊàêÊú¨ÂíåÁΩëÁªúËÆ≠ÁªÉÁõ∏ÂÖ≥ÂèÇÊï∞ÔºåDLSRÈúÄË¶ÅÂ§ßÂûãÊï∞ÊçÆ‰∏≠ÂøÉÊàñË∂ÖÁ∫ßËÆ°ÁÆóÊú∫„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÈúÄË¶ÅÈôç‰ΩéÁ©∫Èó¥ÂíåÊó∂Èó¥Â§çÊùÇÂ∫¶ÔºåÈôç‰ΩéËÆ°ÁÆóÊàêÊú¨ÔºåÂáèÂ∞ëÂèÇÊï∞Êï∞ÈáèÔºåËøòÈúÄË¶ÅÂ∞ÜÂõæÂÉèË¥®Èáè‰øùÊåÅÂú®ÂèØÊé•ÂèóËåÉÂõ¥ÂÜÖ„ÄÇ\n\n2. **Êõ¥ÊúâÊïàÁöÑÁÆóÊ≥ïÊù•Ë°•ÂÅø‰ø°ÊÅØ‰∏¢Â§±**\n\nDLSR Ê®°ÂûãÁöÑ‰∏ªË¶ÅÂ∑•‰ΩúÂéüÁêÜÊòØ‰ªé‰ΩéÂàÜËæ®ÁéáËæìÂÖ•ÈáçÂª∫È´òÂàÜËæ®ÁéáÂõæÂÉè„ÄÇ‰ΩÜÊòØÔºå‰ª•ÈùûÂ∏∏‰ΩéÁöÑÂÜÖÈÉ®ÂàÜËæ®ÁéáÔºà‰æãÂ¶Ç 540pÔºâËøõË°åÊ∏≤ÊüìÔºåÊàñËÄÖËøêË°åÈùûÂ∏∏È´òÁöÑÊîæÂ§ßÊìç‰ΩúÊó∂Ôºà‰æãÂ¶Ç‰ªé 1080p Áº©ÊîæÂà∞ 8KÔºâÔºåÂØπ‰∫éÈáçÂª∫ËÄåË®ÄÔºåÊ≠§Êó∂ÁöÑÁº∫Â§±Êï∞ÊçÆÈáèÂèòÂæóÂ§™Â§ß„ÄÇËøôÈÄöÂ∏∏‰ºöÂØºËá¥ÈîôËØØË°®ËææÊàñ‰∏çÂáÜÁ°ÆÁöÑËßÜËßâÊï∞ÊçÆ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÈúÄË¶ÅÂä™Âäõ‰ΩøÈ¢ÑÊµãÁÆóÊ≥ï‰ªéÊõ¥Â∞ëÁöÑÂÉèÁ¥†‰∏≠Êõ¥ÊúâÊïàÂú∞ÊèêÂèñËßÜËßâ‰ø°ÊÅØ„ÄÇ\n\n3. **‰∏ìÊ≥®‰∫éÊõ¥ÂπøÊ≥õÁöÑÂÆûÊñΩÂíåÊîØÊåÅ**\n\nDLSR ÊòØ‰∏ÄÈ°πÈùûÂ∏∏Êñ∞ÁöÑÊäÄÊúØÔºå‰ªçÂ§Ñ‰∫éËµ∑Ê≠•Èò∂ÊÆµ„ÄÇÂõ†Ê≠§ÔºåÁõÆÂâçÂè™ÊúâÂ∞ëÊï∞Â∫îÁî®Á®ãÂ∫èÊèê‰æõÂØπ DLSR ÁöÑÂÆûÁé∞ÊîØÊåÅ„ÄÇÈúÄË¶ÅÂÆåÊàêÂ∑•‰ΩúÂπ∂ÈúÄË¶ÅÊûÑÂª∫Áõ∏ÂÖ≥ÁöÑ API ‰ª•Êâ©Â±ïÂØπÊõ¥Â§öÂ∫îÁî®Á®ãÂ∫èÁöÑÊîØÊåÅÔºåÂπ∂‰∏îÂøÖÈ°ª‰∏∫ÂºÄÂèë‰∫∫ÂëòÂàõÂª∫ËΩØ‰ª∂Â∑•ÂÖ∑‰ª•ÂÆûÁé∞Êõ¥Âø´ÁöÑÂ¢ûÈïø„ÄÇ\n\n# **PostscriptÔºöÊÄªÁªì**\n\nË∞ÉÊü•ÂíåÊî•ÂÜôÊä•ÂëäÂâçÂâçÂêéÂêéËä±‰∫Ü‰∏ÄÂë®Êó∂Èó¥„ÄÇÂâçÊúü‰πüÊòØÈöèÂøÉÊâÄÊ¨≤ÁöÑÊü•ÊñáÁåÆÁúãËµÑÊñôÂÜômdÔºåÂêéÊúü‰∏âÂ§©ÁãÇËÇùÂá∫Â∞è20È°µÁöÑÊä•ÂëäËøòÊòØÁõ∏ÂΩìÁóõËã¶ÁöÑ‰∏Ä‰ª∂‰∫ã‚Ä¶‚Ä¶Á°ÆÂÆûÊó∂Èó¥ÂÆâÊéíÁõ∏ÂΩì‰∏çÂêàÁêÜÔºàÊãñÂª∂Áóá‰Ω†ÂèàÊù•Âï¶ÔºâÔºå‰ΩÜÊõ¥Â§öÁöÑÊó∂Èó¥ÊàëËÆ§‰∏∫ÊòØËä±Ë¥πÂú®ÊçãÊÄùË∑Ø‰∏ä„ÄÇÂú®Êü•ÈòÖËµÑÊñôËøáÁ®ã‰∏≠ÔºåÊàë‰∏ÄÁõ¥Âú®Â∞ùËØïÊë∏Ê∏ÖÂÜÖÂú®ÁöÑÈÄªËæëÈìæ‚Äî‚ÄîÂèØÊÉúÊÄùË∑Ø‰∏ÄÁõ¥Ë¢´Êé®ÁøªÈáçÂª∫ÔºåÊñáÁ´†ÁªìÊûÑ‰πü‰∏ÄÊîπÂÜçÊîπÔºåÁõ¥Âà∞ddlÂâçÁöÑÊúÄÂêé‰∏ÄÂ§©ÁöÑÊàëÂü∫Êú¨Êª°ÊÑè„ÄÇ\n\nÊÄª‰ΩìÊù•ËØ¥ÔºåÊî∂Ëé∑ËøòÊòØÁõ∏ÂΩìÂ§ßÁöÑÔºåË∞ÉÁ†îË∞ÉÊü•Êú¨Ë∫´Â∞±ÊòØ‰∏Ä‰ª∂‰ª§‰∫∫ÂÖ¥Â•ãÁöÑ‰∫ã‚Äî‚ÄîÂèØ‰ª•Ëá™Â∑±ÊÄùËÄÉÂÜÖÂú®ËÅîÁ≥ªÔºåÊèêÂá∫ÈóÆÈ¢òÔºåÂÜçÂéªËß£ÂÜ≥‚Ä¶‚Ä¶Ëøô‰πüÊòØÊàëÁ¨¨‰∏ÄÊ¨°ÁúãËøô‰πàÂ§öÁöÑÂ§ñÊñáÊùêÊñôÔºàÂéüÂÖàÂØπËã±ÊñáÊñáÁåÆÊúâ‰∫õÁïèÊÉßÂøÉÁêÜÔºå‰∏ÄÁõ¥Ê≤°ÊúâËøàÂá∫Ëøô‰∏ÄÊ≠•ÔºåÊàñËÄÖËØ¥Ê≤°ËøàÂá†Ê≠•Ôºâ„ÄÇ\n\nÊàëÊúÄÊÑüÂÖ¥Ë∂£ÊàñËÄÖÊúÄÊÉ≥‰ªé‰∫ãÁöÑÊñπÂêë‰πã‰∏ÄÂ∞±ÊòØÊ∏∏ÊàèÂºÄÂèëÔºà‰∏Ä‰∏™Áà±Áé©Ê∏∏ÊàèÁöÑ‰∫∫‰πüÊÉ≥ÂéªÂÅöÊ∏∏ÊàèÔºâ„ÄÇÂéüÂÖàÊàëÂ§öÂ§öÂ∞ëÂ∞ë‰Ωé‰º∞‰∫ÜËøô‰∏™È¢ÜÂüüÁöÑÈöæÂ∫¶Ôºå‰ΩÜÁé∞Âú®Êõ¥Â§öÂú∞ÊàëÂØπËøô‰∏™ÊñπÂêë‰∫ßÁîü‰∫ÜÊï¨Áïè‰πãÊÉÖ„ÄÇÂΩìÁÑ∂ÊâìÂä®ÊàëÁöÑËøòÊúâÂæàÂ§öËøô‰∏™È¢ÜÂüüÁöÑÂâçËæà‰ª¨„ÄÇÂΩìÊàëÁ†îÁ©∂„ÄäReal time rendering„ÄãÔºåÁøªÁúãÊØõÊòü‰∫ëÁöÑÊÄªÁªìÊèêÁÇºÊó∂ÔºåÊàë‰Ω©ÊúçÁùÄ‰ªñÁöÑÁÉ≠Áà±Ôºå‰πüÊÉãÊÉúÁùÄ‰ªñÁöÑÁ¶ªÂºÄÔºõÂΩìÊàëÊµèËßàÊñáÂàÄÁßã‰∫åÁöÑ[Áü•‰πéÂõûÁ≠î](https://www.zhihu.com/question/29504480/answer/44764493)Êó∂ÔºåÊàë‰πüÊòØÊ∑±Ê∑±‰Ω©ÊúçÁöÑ‚Äî‚ÄîÊàëËÆ§‰∏∫ÊàëÂØπcodingÊòØÂæàÊÑüÂÖ¥Ë∂£ÁöÑÔºå‰ª•Ëá≥‰∫éÊØèÊ¨°ËØæËÆæÂíåÈ°πÁõÆÊàëÂæàÂ§öÊó∂Èó¥ÈÉΩËä±Âú®Â≠¶‰π†Êñ∞‰∏úË•øÂä†‰∏äÂéªÔºå‰ª•ÂÅöÂæóÂ•Ω‰∫õÔºåÊõ¥Â•Ω‰∫õ„ÄÇ‰ΩÜÂΩìÊàëÂèëÁé∞Â§ßÁ•ûÁöÑ\"ÂÖ¥Ë∂£\"ÂêéÔºåÊàë‰πüÊÑèËØÜÂà∞ÔºåÊàëËøòÊúâÂæàÈïøÁöÑ‰∏ÄÊÆµË∑ØË¶ÅËµ∞Ôºö\n\n <center>\n    <img style=\"border-radius: 0.3125em;\n    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n    src=\"https://img-blog.csdnimg.cn/41c45a32be944723964575606a6fb82d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_6bKr5piv5p2h5ZK46bG8,size_20,color_FFFFFF,t_70,g_se,x_16\"\n    width=\"50%\">\n</center>\n\nÊúÄÂêéÂÜçÊù•Ë∞àË∞àËøôÁØáÊñáÁ´†Ôºå‰∏™‰∫∫ÊÑüËßâÊõ¥Â§öÁöÑËøòÊòØÂú®Â≠¶‰π†ÊëòÊäÑÂÄüÈâ¥„ÄÇÂÜôÁª™ËÆ∫ÁöÑÊó∂ÂÄôËøòÂú®ÊâãÊï≤ÔºåÈôÑÂºïÁî®ÔºõÂÜôÊäóÈîØÈΩøÈÉ®ÂàÜÁöÑÊó∂ÂÄôËøòËÉΩÊï¥ÂêàÂ§ö‰ªΩËµÑÊñôÔºåÁøªËØëÁΩëÁ´ôÊñáÁåÆÔºåÂÜçÂÅöÊ†°ÂØπÔºõÁ≠âÂÜôÂà∞DLSSÊó∂Â∞±ÂºÄÂßãÂ§çÂà∂Á≤òË¥¥‰∫Ü‚Ä¶‚Ä¶ÊÄª‰ΩìËÄåË®ÄÔºåÊõ¥ÂÉèÊòØÂ§öÂÆ∂ËµÑÊñôÁöÑÂ§ßÂêàÈõÜÔºåÂãâÂãâÂº∫Âº∫‰∏Ä‰∏™‰ºòÁÇπÂ∞±ÊòØÊúâËá™Â∑±ÁöÑÊÄùËÄÉÂú®ÂÜÖ„ÄÇÂΩìÁÑ∂ÔºåÂ¶ÇÊúâÈîôËØØÂíåÈóÆÈ¢òÔºåÊ¨¢ËøéÊé¢ËÆ®„ÄÇÈÅìÈòª‰∏îÈïøÔºåËøôÊòØ‰∏ÄÊ¨°ÊääÊä•ÂëäÊï¥ÁêÜËá≥CSDN‰∏äÔºåÁõ∏‰ø°‰∏ç‰ºöÊòØÊúÄÂêé‰∏ÄÊ¨°ÔºÅ\n","tags":["DL","CG"],"categories":["Other"]}]